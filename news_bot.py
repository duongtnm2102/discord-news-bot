import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime
import time
import calendar
from urllib.parse import urljoin
import html
import chardet
import pytz
import json
from keep_alive import keep_alive
import google.generativeai as genai
from enum import Enum

# üÜï MULTI-AI ENGINE ARCHITECTURE
class AIProvider(Enum):
    GEMINI = "gemini"
    DEEPSEEK = "deepseek"
    CLAUDE = "claude"
    GROQ = "groq"  # Fallback

# ü§ñ AI CONFIGURATION
AI_CONFIGS = {
    AIProvider.GEMINI: {
        'api_key_env': 'GEMINI_API_KEY',
        'model': 'gemini-2.0-flash-exp',
        'endpoint': 'google_ai_studio',
        'free_tier': 'unlimited',
        'strengths': ['search_integration', 'instruction_following', 'multimodal']
    },
    AIProvider.DEEPSEEK: {
        'api_key_env': 'DEEPSEEK_API_KEY',
        'model': 'deepseek-v3',
        'endpoint': 'https://api.deepseek.com/v1/chat/completions',
        'free_tier': 'generous',
        'strengths': ['reasoning', 'cost_effective', 'math']
    },
    AIProvider.CLAUDE: {
        'api_key_env': 'ANTHROPIC_API_KEY',
        'model': 'claude-3-5-sonnet-20241022',
        'endpoint': 'https://api.anthropic.com/v1/messages',
        'free_tier': 'limited',
        'strengths': ['safety', 'analysis', 'structured_output']
    },
    AIProvider.GROQ: {
        'api_key_env': 'GROQ_API_KEY',
        'model': 'llama-3.3-70b-versatile',
        'endpoint': 'https://api.groq.com/openai/v1/chat/completions',
        'free_tier': 'rate_limited',
        'strengths': ['speed', 'compatibility']
    }
}

# C·∫•u h√¨nh bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# üîí B·∫¢O M·∫¨T: Environment Variables
TOKEN = os.getenv('DISCORD_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')

# AI API Keys
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
GROQ_API_KEY = os.getenv('GROQ_API_KEY')

if not TOKEN:
    print("‚ùå DISCORD_TOKEN kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y!")
    exit(1)

# üáªüá≥ TIMEZONE VI·ªÜT NAM
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# L∆∞u tr·ªØ tin t·ª©c theo t·ª´ng user
user_news_cache = {}

# üÜï AI ENGINE MANAGER
class AIEngineManager:
    def __init__(self):
        self.primary_ai = None
        self.fallback_ais = []
        self.initialize_engines()
    
    def initialize_engines(self):
        """Kh·ªüi t·∫°o c√°c AI engines theo th·ª© t·ª± ∆∞u ti√™n"""
        available_engines = []
        
        # Gemini - Highest priority
        if GEMINI_API_KEY:
            try:
                genai.configure(api_key=GEMINI_API_KEY)
                available_engines.append(AIProvider.GEMINI)
                print("‚úÖ Gemini AI initialized - PRIMARY ENGINE")
            except Exception as e:
                print(f"‚ö†Ô∏è Gemini initialization failed: {e}")
        
        # DeepSeek - Second priority  
        if DEEPSEEK_API_KEY:
            available_engines.append(AIProvider.DEEPSEEK)
            print("‚úÖ DeepSeek AI available - FALLBACK 1")
            
        # Claude - Third priority
        if ANTHROPIC_API_KEY:
            available_engines.append(AIProvider.CLAUDE)
            print("‚úÖ Claude AI available - FALLBACK 2")
            
        # Groq - Last fallback
        if GROQ_API_KEY:
            available_engines.append(AIProvider.GROQ)
            print("‚úÖ Groq AI available - LAST FALLBACK")
        
        if available_engines:
            self.primary_ai = available_engines[0]
            self.fallback_ais = available_engines[1:]
            print(f"üöÄ Primary AI: {self.primary_ai.value}")
            print(f"üõ°Ô∏è Fallback AIs: {[ai.value for ai in self.fallback_ais]}")
        else:
            print("‚ùå No AI engines available!")
            self.primary_ai = None

    async def call_ai_with_fallback(self, prompt, context="", require_specific_data=True):
        """G·ªçi AI v·ªõi fallback automatic"""
        
        # Th·ª≠ primary AI tr∆∞·ªõc
        if self.primary_ai:
            try:
                response = await self._call_specific_ai(self.primary_ai, prompt, context, require_specific_data)
                if self._validate_response(response, require_specific_data):
                    return response, self.primary_ai.value
            except Exception as e:
                print(f"‚ö†Ô∏è Primary AI {self.primary_ai.value} failed: {e}")
        
        # Th·ª≠ fallback AIs
        for fallback_ai in self.fallback_ais:
            try:
                response = await self._call_specific_ai(fallback_ai, prompt, context, require_specific_data)
                if self._validate_response(response, require_specific_data):
                    print(f"‚úÖ Fallback to {fallback_ai.value} successful")
                    return response, fallback_ai.value
            except Exception as e:
                print(f"‚ö†Ô∏è Fallback AI {fallback_ai.value} failed: {e}")
                continue
        
        # N·∫øu t·∫•t c·∫£ fail
        return "‚ùå T·∫•t c·∫£ AI engines ƒë·ªÅu kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau.", "error"

    async def _call_specific_ai(self, ai_provider, prompt, context, require_specific_data):
        """G·ªçi AI engine c·ª• th·ªÉ"""
        
        if ai_provider == AIProvider.GEMINI:
            return await self._call_gemini(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.DEEPSEEK:
            return await self._call_deepseek(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.CLAUDE:
            return await self._call_claude(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.GROQ:
            return await self._call_groq(prompt, context, require_specific_data)
        
        raise Exception(f"Unknown AI provider: {ai_provider}")

    async def _call_gemini(self, prompt, context, require_specific_data):
        """üöÄ Gemini 2.5 Flash - RECOMMENDED"""
        
        # T·∫°o prompt si√™u nghi√™m kh·∫Øc cho Gemini
        system_prompt = """B·∫†N L√Ä CHUY√äN GIA T√ÄI CH√çNH VI·ªÜT NAM. QUY T·∫ÆC NGHI√äM NG·∫∂T:

üî• B·∫ÆT BU·ªòC (VI PH·∫†M = TH·∫§T B·∫†I HO√ÄN TO√ÄN):
1. S·ª¨ D·ª§NG S·ªê LI·ªÜU C·ª§ TH·ªÇ t·ª´ n·ªôi dung tin t·ª©c ƒë∆∞·ª£c cung c·∫•p
2. N√äU TH·ªúI GIAN C·ª§ TH·ªÇ (ng√†y/th√°ng/nƒÉm, gi·ªù n·∫øu c√≥)  
3. TR√çCH D·∫™N CH√çNH X√ÅC t·ª´ ngu·ªìn tin
4. GI·∫¢I TH√çCH L√ù DO d·ª±a tr√™n s·ª± ki·ªán th·ª±c t·∫ø

‚ùå NGHI√äM C·∫§M:
- N√≥i chung chung: "th∆∞·ªùng", "c√≥ th·ªÉ", "n√≥i chung"
- D√πng d·ªØ li·ªáu c≈© kh√¥ng c√≥ trong tin t·ª©c
- ƒê∆∞a ra √Ω ki·∫øn c√° nh√¢n kh√¥ng d·ª±a tr√™n facts

‚úÖ ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:
[S·ªê LI·ªÜU HI·ªÜN T·∫†I] - [TH·ªúI GIAN] - [L√ù DO C·ª§ TH·ªÇ] - [NGU·ªíN]

üéØ N·∫æU KH√îNG C√ì ƒê·ª¶ TH√îNG TIN: Tr·∫£ l·ªùi "Kh√¥ng ƒë·ªß d·ªØ li·ªáu c·ª• th·ªÉ trong c√°c ngu·ªìn tin hi·ªán t·∫°i"""

        full_prompt = f"{system_prompt}\n\nüì∞ TH√îNG TIN T·ª™ NGU·ªíN TIN:\n{context}\n\n‚ùì C√ÇU H·ªéI: {prompt}\n\nüî• TH·ª∞C HI·ªÜN NGAY - TU√ÇN TH·ª¶ NGHI√äM NG·∫∂T:"
        
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Configure generation v·ªõi settings strict
        generation_config = genai.types.GenerationConfig(
            temperature=0.1,  # Th·∫•p ƒë·ªÉ factual
            top_p=0.8,
            top_k=20,
            max_output_tokens=1000,
        )
        
        response = model.generate_content(
            full_prompt,
            generation_config=generation_config
        )
        
        return response.text.strip()

    async def _call_deepseek(self, prompt, context, require_specific_data):
        """üí∞ DeepSeek V3 - Cost Effective"""
        
        headers = {
            'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        system_message = """B·∫°n l√† chuy√™n gia t√†i ch√≠nh. PH·∫¢I tu√¢n th·ªß nghi√™m ng·∫∑t:
1. S·ª≠ d·ª•ng ch√≠nh x√°c s·ªë li·ªáu t·ª´ tin t·ª©c ƒë∆∞·ª£c cung c·∫•p
2. N√™u th·ªùi gian c·ª• th·ªÉ  
3. Gi·∫£i th√≠ch l√Ω do d·ª±a tr√™n s·ª± ki·ªán th·ª±c t·∫ø
4. KH√îNG ƒë∆∞·ª£c n√≥i chung chung ho·∫∑c d√πng d·ªØ li·ªáu c≈©"""

        data = {
            'model': 'deepseek-v3',
            'messages': [
                {'role': 'system', 'content': system_message},
                {'role': 'user', 'content': f"TH√îNG TIN TIN T·ª®C:\n{context}\n\nC√ÇU H·ªéI: {prompt}"}
            ],
            'temperature': 0.1,
            'max_tokens': 1000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.deepseek.com/v1/chat/completions', 
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()

    async def _call_claude(self, prompt, context, require_specific_data):
        """üß† Claude 3.5 Sonnet - Reliable"""
        
        headers = {
            'x-api-key': ANTHROPIC_API_KEY,
            'Content-Type': 'application/json',
            'anthropic-version': '2023-06-01'
        }
        
        data = {
            'model': 'claude-3-5-sonnet-20241022',
            'max_tokens': 1000,
            'temperature': 0.1,
            'messages': [
                {
                    'role': 'user', 
                    'content': f"""B·∫°n l√† chuy√™n gia t√†i ch√≠nh. QUY T·∫ÆC B·∫ÆT BU·ªòC:
- S·ª≠ d·ª•ng s·ªë li·ªáu c·ª• th·ªÉ t·ª´ tin t·ª©c
- N√™u th·ªùi gian ch√≠nh x√°c  
- Gi·∫£i th√≠ch l√Ω do d·ª±a tr√™n facts
- Kh√¥ng n√≥i chung chung

TH√îNG TIN TIN T·ª®C:
{context}

C√ÇU H·ªéI: {prompt}"""
                }
            ]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.anthropic.com/v1/messages',
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['content'][0]['text'].strip()

    async def _call_groq(self, prompt, context, require_specific_data):
        """‚ö° Groq - Fast Fallback"""
        
        headers = {
            'Authorization': f'Bearer {GROQ_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'llama-3.3-70b-versatile',
            'messages': [
                {'role': 'system', 'content': 'B·∫°n l√† chuy√™n gia t√†i ch√≠nh. Ph·∫£i s·ª≠ d·ª•ng s·ªë li·ªáu c·ª• th·ªÉ t·ª´ tin t·ª©c v√† n√™u th·ªùi gian ch√≠nh x√°c. Kh√¥ng ƒë∆∞·ª£c n√≥i chung chung.'},
                {'role': 'user', 'content': f"TH√îNG TIN TIN T·ª®C:\n{context}\n\nC√ÇU H·ªéI: {prompt}"}
            ],
            'temperature': 0.1,
            'max_tokens': 1000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.groq.com/openai/v1/chat/completions',
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()

    def _validate_response(self, response, require_specific_data):
        """Validate AI response quality"""
        if not require_specific_data:
            return len(response.strip()) > 50
        
        # Check for specific data requirements
        has_numbers = re.search(r'\d+[.,]?\d*\s*%|\d+[.,]?\d*\s*(tri·ªáu|t·ª∑|USD|VND|ƒë·ªìng)', response)
        has_time = re.search(r'\d{1,2}[/\-\.]\d{1,2}[/\-\.]\d{4}|\d{1,2}\s*(th√°ng|thg)\s*\d{1,2}', response)
        
        # Check for forbidden generic terms
        forbidden_terms = ['th∆∞·ªùng', 'c√≥ th·ªÉ', 'n√≥i chung', 'th√¥ng th∆∞·ªùng', 'th·ªãnh n·ªôp']
        has_forbidden = any(term in response.lower() for term in forbidden_terms)
        
        if require_specific_data:
            return has_numbers and has_time and not has_forbidden
        
        return not has_forbidden and len(response.strip()) > 100

# Initialize AI Manager
ai_manager = AIEngineManager()

# üîç IMPROVED GOOGLE SEARCH v·ªõi Generic Query
async def search_reliable_sources_improved(query, max_results=5):
    """üÜï T√¨m ki·∫øm th√¥ng minh v·ªõi Generic Query + Time Context"""
    
    if not GOOGLE_API_KEY or not GOOGLE_CSE_ID:
        print("‚ö†Ô∏è Google Search API not configured")
        return []
    
    try:
        # Th√™m time context cho query
        current_date = datetime.now(VN_TIMEZONE).strftime("%Y")
        current_month = datetime.now(VN_TIMEZONE).strftime("%m/%Y")
        
        # Generic query v·ªõi time context - KH√îNG C·∫¶N specific keywords
        enhanced_query = f'{query} {current_date} m·ªõi nh·∫•t tin t·ª©c site:cafef.vn OR site:vneconomy.vn OR site:vnexpress.net OR site:tuoitre.vn OR site:thanhnien.vn OR site:baodautu.vn OR site:dantri.com.vn OR site:investing.com OR site:bloomberg.com OR site:reuters.com'
        
        print(f"üîç Enhanced search query: {enhanced_query}")
        
        from googleapiclient.discovery import build
        service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)
        
        result = service.cse().list(
            q=enhanced_query,
            cx=GOOGLE_CSE_ID,
            num=max_results,
            lr='lang_vi|lang_en',
            safe='active',
            sort='date'  # S·∫Øp x·∫øp theo ng√†y m·ªõi nh·∫•t
        ).execute()
        
        sources = []
        if 'items' in result:
            for item in result['items']:
                source = {
                    'title': item.get('title', ''),
                    'link': item.get('link', ''),
                    'snippet': item.get('snippet', ''),
                    'source_name': extract_source_name(item.get('link', '')),
                    'publishedDate': item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', '')
                }
                sources.append(source)
        
        print(f"‚úÖ Found {len(sources)} reliable sources")
        return sources
        
    except Exception as e:
        print(f"‚ùå Google Search error: {e}")
        return []

def extract_source_name(url):
    """Extract readable source name from URL"""
    domain_mapping = {
        'cafef.vn': 'CafeF',
        'vneconomy.vn': 'VnEconomy', 
        'vnexpress.net': 'VnExpress',
        'tuoitre.vn': 'Tu·ªïi Tr·∫ª',
        'thanhnien.vn': 'Thanh Ni√™n',
        'baodautu.vn': 'B√°o ƒê·∫ßu t∆∞',
        'dantri.com.vn': 'D√¢n tr√≠',
        'investing.com': 'Investing.com',
        'bloomberg.com': 'Bloomberg',
        'reuters.com': 'Reuters',
        'bbc.com': 'BBC'
    }
    
    for domain, name in domain_mapping.items():
        if domain in url:
            return name
    
    try:
        from urllib.parse import urlparse
        domain = urlparse(url).netloc.replace('www.', '')
        return domain.title()
    except:
        return 'Unknown Source'

# üÜï IMPROVED CONTENT EXTRACTION
async def get_full_content_from_sources_improved(sources):
    """L·∫•y n·ªôi dung ƒë·∫ßy ƒë·ªß v·ªõi fallback strategy"""
    
    full_contexts = []
    
    for i, source in enumerate(sources[:3], 1):  # Top 3 sources
        try:
            print(f"üìÑ Extracting content from source {i}: {source['source_name']}")
            
            # Try multiple extraction methods
            content = await fetch_full_content_improved(source['link'])
            
            if content and len(content) > 200:
                # L·∫•y 800 k√Ω t·ª± ƒë·∫ßu - ch·ª©a info quan tr·ªçng nh·∫•t
                summary_content = content[:800]
                
                full_contexts.append(f"""
üì∞ NGU·ªíN {i}: {source['source_name']}
üìÖ Th·ªùi gian: {source.get('publishedDate', 'Kh√¥ng x√°c ƒë·ªãnh')}
üîó Link: {source['link']}
üìÑ N·ªôi dung: {summary_content}
""")
            else:
                # Fallback to snippet
                full_contexts.append(f"""
üì∞ NGU·ªíN {i}: {source['source_name']} 
üìÑ T√≥m t·∫Øt: {source['snippet']}
üîó Link: {source['link']}
""")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Content extraction failed for {source['source_name']}: {e}")
            # Fallback to snippet
            full_contexts.append(f"""
üì∞ NGU·ªíN {i}: {source['source_name']}
üìÑ T√≥m t·∫Øt: {source['snippet']}
üîó Link: {source['link']}
""")
    
    return "\n".join(full_contexts)

# Existing RSS feeds and other functions remain the same...
RSS_FEEDS = {
    'domestic': {
        'cafef_main': 'https://cafef.vn/index.rss',
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'vneconomy_main': 'https://vneconomy.vn/rss/home.rss',
        'vnexpress_kinhdoanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'thanhnien_kinhtevimo': 'https://thanhnien.vn/rss/kinh-te/vi-mo.rss',
    },
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg_markets': 'https://feeds.bloomberg.com/markets/news.rss',
    }
}

# üÜï MAIN AI COMMAND - Completely Rewritten
@bot.command(name='hoi')
async def ask_economic_question_improved(ctx, *, question):
    """üÜï AI Q&A v·ªõi Multi-Engine Support v√† Validation"""
    
    try:
        if not ai_manager.primary_ai:
            embed = discord.Embed(
                title="‚ö†Ô∏è AI Services kh√¥ng kh·∫£ d·ª•ng",
                description="Ch∆∞a c·∫•u h√¨nh AI API keys. C·∫ßn √≠t nh·∫•t m·ªôt trong: GEMINI_API_KEY, DEEPSEEK_API_KEY, ANTHROPIC_API_KEY, GROQ_API_KEY",
                color=0xff6b6b
            )
            await ctx.send(embed=embed)
            return
        
        # Th√¥ng b√°o ƒëang x·ª≠ l√Ω
        processing_msg = await ctx.send("üîç ƒêang t√¨m ki·∫øm th√¥ng tin t·ª´ c√°c ngu·ªìn tin ƒë√°ng tin c·∫≠y...")
        
        # üîç Step 1: Generic Google Search (No specific keywords needed)
        sources = await search_reliable_sources_improved(question, max_results=5)
        
        if not sources:
            await processing_msg.edit(content="‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ngu·ªìn tin. ƒêang s·ª≠ d·ª•ng ki·∫øn th·ª©c t·ªïng qu√°t...")
        
        # üìÑ Step 2: Extract full content 
        await processing_msg.edit(content="üìÑ ƒêang ph√¢n t√≠ch n·ªôi dung t·ª´ c√°c ngu·ªìn tin...")
        full_context = await get_full_content_from_sources_improved(sources)
        
        # ü§ñ Step 3: AI Analysis v·ªõi Multi-Engine Fallback
        await processing_msg.edit(content="ü§ñ AI ƒëang ph√¢n t√≠ch v√† t·∫°o c√¢u tr·∫£ l·ªùi...")
        
        # Detect if question requires specific financial data
        requires_specific_data = any(keyword in question.lower() for keyword in 
                                   ['gi√°', 'bao nhi√™u', 'tƒÉng gi·∫£m', 'thay ƒë·ªïi', 'hi·ªán t·∫°i', 'h√¥m nay'])
        
        ai_response, used_engine = await ai_manager.call_ai_with_fallback(
            prompt=question,
            context=full_context,
            require_specific_data=requires_specific_data
        )
        
        # X√≥a th√¥ng b√°o processing
        await processing_msg.delete()
        
        # üìä Create beautiful embed response
        embed = discord.Embed(
            title=f"ü§ñ AI Tr·∫£ l·ªùi: {question.title()[:100]}...",
            description=ai_response,
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        # Add AI engine info
        engine_emoji = {
            'gemini': 'üíé',
            'deepseek': 'üí∞', 
            'claude': 'üß†',
            'groq': '‚ö°'
        }
        
        embed.add_field(
            name="ü§ñ AI Engine s·ª≠ d·ª•ng",
            value=f"{engine_emoji.get(used_engine, 'ü§ñ')} {used_engine.upper()}",
            inline=True
        )
        
        if sources:
            embed.add_field(
                name="üìä S·ªë ngu·ªìn tin",
                value=f"üì∞ {len(sources)} ngu·ªìn ƒë√°ng tin c·∫≠y",
                inline=True
            )
        
        # Add source references
        if sources:
            sources_text = ""
            for i, source in enumerate(sources[:3], 1):
                sources_text += f"{i}. **{source['source_name']}**: [{source['title'][:50]}...]({source['link']})\n"
            
            embed.add_field(
                name="üì∞ Ngu·ªìn tin tham kh·∫£o",
                value=sources_text,
                inline=False
            )
        
        # Footer
        embed.set_footer(
            text=f"üöÄ Multi-AI Engine ‚Ä¢ D·ªØ li·ªáu th·ªùi gian th·ª±c ‚Ä¢ !menu ƒë·ªÉ xem th√™m l·ªánh",
            icon_url=ctx.bot.user.avatar.url if ctx.bot.user.avatar else None
        )
        
        await ctx.send(embed=embed)
        
        # Log cho debug
        print(f"‚úÖ Question answered: '{question}' using {used_engine}")
        
    except Exception as e:
        await ctx.send(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {str(e)}")
        print(f"‚ùå Error in !hoi command: {e}")

# üìä Updated Menu Command
@bot.command(name='menu')
async def help_command_improved(ctx):
    """Menu v·ªõi Multi-AI Engine info"""
    
    embed = discord.Embed(
        title="ü§ñüöÄ Menu News Bot - Multi-AI Engine",
        description="Bot tin t·ª©c kinh t·∫ø v·ªõi AI th√¥ng minh ƒëa engine",
        color=0xff9900
    )
    
    # AI Engine status
    ai_status = ""
    if ai_manager.primary_ai:
        engine_name = ai_manager.primary_ai.value.upper()
        ai_status += f"üöÄ **Primary**: {engine_name} ‚úÖ\n"
        
        for fallback in ai_manager.fallback_ais:
            ai_status += f"üõ°Ô∏è **Fallback**: {fallback.value.upper()} ‚úÖ\n"
    else:
        ai_status = "‚ùå Ch∆∞a c·∫•u h√¨nh AI engines"
    
    embed.add_field(
        name="ü§ñ AI Engines ho·∫°t ƒë·ªông",
        value=ai_status,
        inline=False
    )
    
    embed.add_field(
        name="üì∞ L·ªánh tin t·ª©c",
        value="""
**!all [trang]** - Tin t·ª´ t·∫•t c·∫£ ngu·ªìn
**!in [trang]** - Tin trong n∆∞·ªõc  
**!out [trang]** - Tin qu·ªëc t·∫ø
**!chitiet [s·ªë]** - Xem n·ªôi dung chi ti·∫øt
        """,
        inline=True
    )
    
    embed.add_field(
        name="ü§ñ L·ªánh AI th√¥ng minh",
        value="""
**!hoi [c√¢u h·ªèi]** - AI tr·∫£ l·ªùi v·ªõi Multi-Engine
*V√≠ d·ª•: !hoi gi√° v√†ng h√¥m nay nh∆∞ th·∫ø n√†o*
        """,
        inline=True
    )
    
    embed.add_field(
        name="üéØ T√≠nh nƒÉng m·ªõi",
        value="""
‚úÖ **Multi-AI Engine** - T·ª± ƒë·ªông fallback
‚úÖ **Generic Search** - Kh√¥ng c·∫ßn config t·ª´ng keyword  
‚úÖ **Real-time Data** - D·ªØ li·ªáu c·∫≠p nh·∫≠t li√™n t·ª•c
‚úÖ **Response Validation** - ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng
‚úÖ **Full Content Extract** - Ph√¢n t√≠ch s√¢u
        """,
        inline=False
    )
    
    embed.set_footer(text="üöÄ Multi-AI Engine ‚Ä¢ Generic Search ‚Ä¢ Real-time Analysis")
    await ctx.send(embed=embed)

@bot.event
async def on_ready():
    print(f'‚úÖ {bot.user} ƒë√£ online!')
    print(f'üìä K·∫øt n·ªëi v·ªõi {len(bot.guilds)} server(s)')
    
    # AI Engine status
    if ai_manager.primary_ai:
        print(f'ü§ñ Primary AI: {ai_manager.primary_ai.value.upper()}')
        print(f'üõ°Ô∏è Fallback AIs: {[ai.value.upper() for ai in ai_manager.fallback_ais]}')
    else:
        print('‚ö†Ô∏è No AI engines configured')
    
    print('üéØ G√µ !menu ƒë·ªÉ xem h∆∞·ªõng d·∫´n')
    
    # Set bot status
    status_text = f"Multi-AI Engine ‚Ä¢ {ai_manager.primary_ai.value.upper() if ai_manager.primary_ai else 'No AI'} ‚Ä¢ !menu"
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching,
            name=status_text
        )
    )

# Placeholder functions (implement based on existing code)
async def fetch_full_content_improved(url):
    """Implement existing fetch_full_content_improved function"""
    # Use existing implementation from your code
    pass

# Additional RSS and content functions remain the same...
# [Include all other existing functions like collect_news_from_sources, etc.]

# Main execution
if __name__ == "__main__":
    try:
        keep_alive()
        print("üöÄ Starting Multi-AI Discord News Bot...")
        
        if not TOKEN:
            print("‚ùå DISCORD_TOKEN required!")
            exit(1)
        
        print("‚úÖ Bot ready with Multi-AI Engine support!")
        bot.run(TOKEN)
        
    except Exception as e:
        print(f"‚ùå Bot startup error: {e}")
        input("Press Enter to exit...")
