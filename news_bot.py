import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime
import time
import calendar
from urllib.parse import urljoin
import html
import chardet
import pytz
import json
import aiohttp
from keep_alive import keep_alive
import google.generativeai as genai
from enum import Enum

# ğŸ†• THÃŠM CÃC THá»¬ VIá»†N NÃ‚NG CAO (OPTIONAL)
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
    print("âœ… Trafilatura Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p - TrÃ­ch xuáº¥t ná»™i dung cáº£i tiáº¿n!")
except ImportError:
    TRAFILATURA_AVAILABLE = False
    print("âš ï¸ Trafilatura khÃ´ng cÃ³ sáºµn - Sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p cÆ¡ báº£n")

try:
    import newspaper
    from newspaper import Article
    NEWSPAPER_AVAILABLE = True
    print("âœ… Newspaper3k Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p - Fallback extraction!")
except ImportError:
    NEWSPAPER_AVAILABLE = False
    print("âš ï¸ Newspaper3k khÃ´ng cÃ³ sáºµn - Sáº½ dÃ¹ng phÆ°Æ¡ng phÃ¡p cÆ¡ báº£n")

# ğŸ†• MULTI-AI ENGINE ARCHITECTURE
class AIProvider(Enum):
    GEMINI = "gemini"
    DEEPSEEK = "deepseek"
    CLAUDE = "claude"
    GROQ = "groq"  # Fallback

# ğŸ¤– AI CONFIGURATION
AI_CONFIGS = {
    AIProvider.GEMINI: {
        'api_key_env': 'GEMINI_API_KEY',
        'model': 'gemini-2.0-flash-exp',
        'endpoint': 'google_ai_studio',
        'free_tier': 'unlimited',
        'strengths': ['search_integration', 'instruction_following', 'multimodal']
    },
    AIProvider.DEEPSEEK: {
        'api_key_env': 'DEEPSEEK_API_KEY',
        'model': 'deepseek-v3',
        'endpoint': 'https://api.deepseek.com/v1/chat/completions',
        'free_tier': 'generous',
        'strengths': ['reasoning', 'cost_effective', 'math']
    },
    AIProvider.CLAUDE: {
        'api_key_env': 'ANTHROPIC_API_KEY',
        'model': 'claude-3-5-sonnet-20241022',
        'endpoint': 'https://api.anthropic.com/v1/messages',
        'free_tier': 'limited',
        'strengths': ['safety', 'analysis', 'structured_output']
    },
    AIProvider.GROQ: {
        'api_key_env': 'GROQ_API_KEY',
        'model': 'llama-3.3-70b-versatile',
        'endpoint': 'https://api.groq.com/openai/v1/chat/completions',
        'free_tier': 'rate_limited',
        'strengths': ['speed', 'compatibility']
    }
}

# Cáº¥u hÃ¬nh bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# ğŸ”’ Báº¢O Máº¬T: Environment Variables
TOKEN = os.getenv('DISCORD_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')

# AI API Keys
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
GROQ_API_KEY = os.getenv('GROQ_API_KEY')

if not TOKEN:
    print("âŒ Cáº¢NH BÃO: KhÃ´ng tÃ¬m tháº¥y DISCORD_TOKEN trong environment variables!")
    print("ğŸ”§ Vui lÃ²ng thÃªm DISCORD_TOKEN vÃ o Render Environment Variables")
    exit(1)

# ğŸ‡»ğŸ‡³ TIMEZONE VIá»†T NAM - ÄÃƒ Sá»¬A Lá»–I MÃšI GIá»œ
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# LÆ°u trá»¯ tin tá»©c theo tá»«ng user
user_news_cache = {}

# RSS feeds Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm tra vÃ  xÃ¡c nháº­n hoáº¡t Ä‘á»™ng
RSS_FEEDS = {
    # === KINH Táº¾ TRONG NÆ¯á»šC - ÄÃƒ KIá»‚M TRA ===
    'domestic': {
        # CafeF - RSS chÃ­nh hoáº¡t Ä‘á»™ng tá»‘t
        'cafef_main': 'https://cafef.vn/index.rss',
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'cafef_batdongsan': 'https://cafef.vn/bat-dong-san.rss',
        'cafef_taichinh': 'https://cafef.vn/tai-chinh-ngan-hang.rss',
        'cafef_vimo': 'https://cafef.vn/vi-mo-dau-tu.rss',
        
        # CafeBiz - RSS tá»•ng há»£p
        'cafebiz_main': 'https://cafebiz.vn/index.rss',
        
        # BÃ¡o Äáº§u tÆ° - RSS hoáº¡t Ä‘á»™ng
        'baodautu_main': 'https://baodautu.vn/rss.xml',
        
        # VnEconomy - RSS tin tá»©c chÃ­nh
        'vneconomy_main': 'https://vneconomy.vn/rss/home.rss',
        'vneconomy_chungkhoan': 'https://vneconomy.vn/rss/chung-khoan.rss',
        
        # VnExpress Kinh doanh 
        'vnexpress_kinhdoanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'vnexpress_chungkhoan': 'https://vnexpress.net/rss/kinh-doanh/chung-khoan.rss',
        
        # Thanh NiÃªn - RSS kinh táº¿
        'thanhnien_kinhtevimo': 'https://thanhnien.vn/rss/kinh-te/vi-mo.rss',
        'thanhnien_chungkhoan': 'https://thanhnien.vn/rss/kinh-te/chung-khoan.rss',
        
        # NhÃ¢n DÃ¢n - RSS tÃ i chÃ­nh chá»©ng khoÃ¡n
        'nhandanonline_tc': 'https://nhandan.vn/rss/tai-chinh-chung-khoan.rss'
    },
    
    # === KINH Táº¾ QUá»C Táº¾ ===
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg_markets': 'https://feeds.bloomberg.com/markets/news.rss',
        'marketwatch_latest': 'https://feeds.marketwatch.com/marketwatch/realtimeheadlines/',
        'forbes_money': 'https://www.forbes.com/money/feed/',
        'financial_times': 'https://www.ft.com/rss/home',
        'business_insider': 'https://feeds.businessinsider.com/custom/all',
        'the_economist': 'https://www.economist.com/rss'
    }
}

def convert_utc_to_vietnam_time(utc_time_tuple):
    """ğŸ”§ Sá»¬A Lá»–I MÃšI GIá»œ: Chuyá»ƒn Ä‘á»•i UTC sang giá» Viá»‡t Nam chÃ­nh xÃ¡c"""
    try:
        # Sá»­ dá»¥ng calendar.timegm() thay vÃ¬ time.mktime() Ä‘á»ƒ xá»­ lÃ½ UTC Ä‘Ãºng cÃ¡ch
        utc_timestamp = calendar.timegm(utc_time_tuple)
        
        # Táº¡o datetime object UTC
        utc_dt = datetime.fromtimestamp(utc_timestamp, tz=UTC_TIMEZONE)
        
        # Chuyá»ƒn sang mÃºi giá» Viá»‡t Nam
        vn_dt = utc_dt.astimezone(VN_TIMEZONE)
        
        return vn_dt
    except Exception as e:
        print(f"âš ï¸ Lá»—i chuyá»ƒn Ä‘á»•i mÃºi giá»: {e}")
        # Fallback: sá»­ dá»¥ng thá»i gian hiá»‡n táº¡i
        return datetime.now(VN_TIMEZONE)

# ğŸ†• AI ENGINE MANAGER
class AIEngineManager:
    def __init__(self):
        self.primary_ai = None
        self.fallback_ais = []
        self.initialize_engines()
    
    def initialize_engines(self):
        """Khá»Ÿi táº¡o cÃ¡c AI engines theo thá»© tá»± Æ°u tiÃªn"""
        available_engines = []
        
        # Gemini - Highest priority
        if GEMINI_API_KEY:
            try:
                genai.configure(api_key=GEMINI_API_KEY)
                available_engines.append(AIProvider.GEMINI)
                print("âœ… Gemini AI initialized - PRIMARY ENGINE")
            except Exception as e:
                print(f"âš ï¸ Gemini initialization failed: {e}")
        
        # DeepSeek - Second priority  
        if DEEPSEEK_API_KEY:
            available_engines.append(AIProvider.DEEPSEEK)
            print("âœ… DeepSeek AI available - FALLBACK 1")
            
        # Claude - Third priority
        if ANTHROPIC_API_KEY:
            available_engines.append(AIProvider.CLAUDE)
            print("âœ… Claude AI available - FALLBACK 2")
            
        # Groq - Last fallback
        if GROQ_API_KEY:
            available_engines.append(AIProvider.GROQ)
            print("âœ… Groq AI available - LAST FALLBACK")
        
        if available_engines:
            self.primary_ai = available_engines[0]
            self.fallback_ais = available_engines[1:]
            print(f"ğŸš€ Primary AI: {self.primary_ai.value}")
            print(f"ğŸ›¡ï¸ Fallback AIs: {[ai.value for ai in self.fallback_ais]}")
        else:
            print("âŒ No AI engines available!")
            self.primary_ai = None

    async def call_ai_with_fallback(self, prompt, context="", require_specific_data=True):
        """Gá»i AI vá»›i fallback automatic"""
        
        # Thá»­ primary AI trÆ°á»›c
        if self.primary_ai:
            try:
                response = await self._call_specific_ai(self.primary_ai, prompt, context, require_specific_data)
                if self._validate_response(response, require_specific_data):
                    return response, self.primary_ai.value
            except Exception as e:
                print(f"âš ï¸ Primary AI {self.primary_ai.value} failed: {e}")
        
        # Thá»­ fallback AIs
        for fallback_ai in self.fallback_ais:
            try:
                response = await self._call_specific_ai(fallback_ai, prompt, context, require_specific_data)
                if self._validate_response(response, require_specific_data):
                    print(f"âœ… Fallback to {fallback_ai.value} successful")
                    return response, fallback_ai.value
            except Exception as e:
                print(f"âš ï¸ Fallback AI {fallback_ai.value} failed: {e}")
                continue
        
        # Náº¿u táº¥t cáº£ fail
        return "âŒ Táº¥t cáº£ AI engines Ä‘á»u khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng thá»­ láº¡i sau.", "error"

    async def _call_specific_ai(self, ai_provider, prompt, context, require_specific_data):
        """Gá»i AI engine cá»¥ thá»ƒ"""
        
        if ai_provider == AIProvider.GEMINI:
            return await self._call_gemini(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.DEEPSEEK:
            return await self._call_deepseek(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.CLAUDE:
            return await self._call_claude(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.GROQ:
            return await self._call_groq(prompt, context, require_specific_data)
        
        raise Exception(f"Unknown AI provider: {ai_provider}")

    async def _call_gemini(self, prompt, context, require_specific_data):
        """ğŸš€ Gemini 2.5 Flash - RECOMMENDED"""
        
        # Táº¡o prompt siÃªu nghiÃªm kháº¯c cho Gemini
        system_prompt = """Báº N LÃ€ CHUYÃŠN GIA TÃ€I CHÃNH VIá»†T NAM. QUY Táº®C NGHIÃŠM NGáº¶T:

ğŸ”¥ Báº®T BUá»˜C (VI PHáº M = THáº¤T Báº I HOÃ€N TOÃ€N):
1. Sá»¬ Dá»¤NG Sá» LIá»†U Cá»¤ THá»‚ tá»« ná»™i dung tin tá»©c Ä‘Æ°á»£c cung cáº¥p
2. NÃŠU THá»œI GIAN Cá»¤ THá»‚ (ngÃ y/thÃ¡ng/nÄƒm, giá» náº¿u cÃ³)  
3. TRÃCH DáºªN CHÃNH XÃC tá»« nguá»“n tin
4. GIáº¢I THÃCH LÃ DO dá»±a trÃªn sá»± kiá»‡n thá»±c táº¿

âŒ NGHIÃŠM Cáº¤M:
- NÃ³i chung chung: "thÆ°á»ng", "cÃ³ thá»ƒ", "nÃ³i chung"
- DÃ¹ng dá»¯ liá»‡u cÅ© khÃ´ng cÃ³ trong tin tá»©c
- ÄÆ°a ra Ã½ kiáº¿n cÃ¡ nhÃ¢n khÃ´ng dá»±a trÃªn facts

âœ… Äá»ŠNH Dáº NG Báº®T BUá»˜C:
[Sá» LIá»†U HIá»†N Táº I] - [THá»œI GIAN] - [LÃ DO Cá»¤ THá»‚] - [NGUá»’N]

ğŸ¯ Náº¾U KHÃ”NG CÃ“ Äá»¦ THÃ”NG TIN: Tráº£ lá»i "KhÃ´ng Ä‘á»§ dá»¯ liá»‡u cá»¥ thá»ƒ trong cÃ¡c nguá»“n tin hiá»‡n táº¡i"""

        full_prompt = f"{system_prompt}\n\nğŸ“° THÃ”NG TIN Tá»ª NGUá»’N TIN:\n{context}\n\nâ“ CÃ‚U Há»I: {prompt}\n\nğŸ”¥ THá»°C HIá»†N NGAY - TUÃ‚N THá»¦ NGHIÃŠM NGáº¶T:"
        
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Configure generation vá»›i settings strict
        generation_config = genai.types.GenerationConfig(
            temperature=0.1,  # Tháº¥p Ä‘á»ƒ factual
            top_p=0.8,
            top_k=20,
            max_output_tokens=1000,
        )
        
        response = model.generate_content(
            full_prompt,
            generation_config=generation_config
        )
        
        return response.text.strip()

    async def _call_deepseek(self, prompt, context, require_specific_data):
        """ğŸ’° DeepSeek V3 - Cost Effective"""
        
        headers = {
            'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        system_message = """Báº¡n lÃ  chuyÃªn gia tÃ i chÃ­nh. PHáº¢I tuÃ¢n thá»§ nghiÃªm ngáº·t:
1. Sá»­ dá»¥ng chÃ­nh xÃ¡c sá»‘ liá»‡u tá»« tin tá»©c Ä‘Æ°á»£c cung cáº¥p
2. NÃªu thá»i gian cá»¥ thá»ƒ  
3. Giáº£i thÃ­ch lÃ½ do dá»±a trÃªn sá»± kiá»‡n thá»±c táº¿
4. KHÃ”NG Ä‘Æ°á»£c nÃ³i chung chung hoáº·c dÃ¹ng dá»¯ liá»‡u cÅ©"""

        data = {
            'model': 'deepseek-v3',
            'messages': [
                {'role': 'system', 'content': system_message},
                {'role': 'user', 'content': f"THÃ”NG TIN TIN Tá»¨C:\n{context}\n\nCÃ‚U Há»I: {prompt}"}
            ],
            'temperature': 0.1,
            'max_tokens': 1000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.deepseek.com/v1/chat/completions', 
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()

    async def _call_claude(self, prompt, context, require_specific_data):
        """ğŸ§  Claude 3.5 Sonnet - Reliable"""
        
        headers = {
            'x-api-key': ANTHROPIC_API_KEY,
            'Content-Type': 'application/json',
            'anthropic-version': '2023-06-01'
        }
        
        data = {
            'model': 'claude-3-5-sonnet-20241022',
            'max_tokens': 1000,
            'temperature': 0.1,
            'messages': [
                {
                    'role': 'user', 
                    'content': f"""Báº¡n lÃ  chuyÃªn gia tÃ i chÃ­nh. QUY Táº®C Báº®T BUá»˜C:
- Sá»­ dá»¥ng sá»‘ liá»‡u cá»¥ thá»ƒ tá»« tin tá»©c
- NÃªu thá»i gian chÃ­nh xÃ¡c  
- Giáº£i thÃ­ch lÃ½ do dá»±a trÃªn facts
- KhÃ´ng nÃ³i chung chung

THÃ”NG TIN TIN Tá»¨C:
{context}

CÃ‚U Há»I: {prompt}"""
                }
            ]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.anthropic.com/v1/messages',
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['content'][0]['text'].strip()

    async def _call_groq(self, prompt, context, require_specific_data):
        """âš¡ Groq - Fast Fallback"""
        
        headers = {
            'Authorization': f'Bearer {GROQ_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'llama-3.3-70b-versatile',
            'messages': [
                {'role': 'system', 'content': 'Báº¡n lÃ  chuyÃªn gia tÃ i chÃ­nh. Pháº£i sá»­ dá»¥ng sá»‘ liá»‡u cá»¥ thá»ƒ tá»« tin tá»©c vÃ  nÃªu thá»i gian chÃ­nh xÃ¡c. KhÃ´ng Ä‘Æ°á»£c nÃ³i chung chung.'},
                {'role': 'user', 'content': f"THÃ”NG TIN TIN Tá»¨C:\n{context}\n\nCÃ‚U Há»I: {prompt}"}
            ],
            'temperature': 0.1,
            'max_tokens': 1000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.groq.com/openai/v1/chat/completions',
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()

    def _validate_response(self, response, require_specific_data):
        """Validate AI response quality"""
        if not require_specific_data:
            return len(response.strip()) > 50
        
        # Check for specific data requirements
        has_numbers = re.search(r'\d+[.,]?\d*\s*%|\d+[.,]?\d*\s*(triá»‡u|tá»·|USD|VND|Ä‘á»“ng)', response)
        has_time = re.search(r'\d{1,2}[/\-\.]\d{1,2}[/\-\.]\d{4}|\d{1,2}\s*(thÃ¡ng|thg)\s*\d{1,2}', response)
        
        # Check for forbidden generic terms
        forbidden_terms = ['thÆ°á»ng', 'cÃ³ thá»ƒ', 'nÃ³i chung', 'thÃ´ng thÆ°á»ng', 'thá»‹nh ná»™p']
        has_forbidden = any(term in response.lower() for term in forbidden_terms)
        
        if require_specific_data:
            return has_numbers and has_time and not has_forbidden
        
        return not has_forbidden and len(response.strip()) > 100

# Initialize AI Manager
ai_manager = AIEngineManager()

# ğŸ” IMPROVED GOOGLE SEARCH vá»›i Generic Query
async def search_reliable_sources_improved(query, max_results=5):
    """ğŸ†• TÃ¬m kiáº¿m thÃ´ng minh vá»›i Generic Query + Time Context"""
    
    if not GOOGLE_API_KEY or not GOOGLE_CSE_ID:
        print("âš ï¸ Google Search API not configured")
        return []
    
    try:
        # ThÃªm time context cho query
        current_date = datetime.now(VN_TIMEZONE).strftime("%Y")
        current_month = datetime.now(VN_TIMEZONE).strftime("%m/%Y")
        
        # Generic query vá»›i time context - KHÃ”NG Cáº¦N specific keywords
        enhanced_query = f'{query} {current_date} má»›i nháº¥t tin tá»©c site:cafef.vn OR site:vneconomy.vn OR site:vnexpress.net OR site:tuoitre.vn OR site:thanhnien.vn OR site:baodautu.vn OR site:dantri.com.vn OR site:investing.com OR site:bloomberg.com OR site:reuters.com'
        
        print(f"ğŸ” Enhanced search query: {enhanced_query}")
        
        from googleapiclient.discovery import build
        service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)
        
        result = service.cse().list(
            q=enhanced_query,
            cx=GOOGLE_CSE_ID,
            num=max_results,
            lr='lang_vi|lang_en',
            safe='active',
            sort='date'  # Sáº¯p xáº¿p theo ngÃ y má»›i nháº¥t
        ).execute()
        
        sources = []
        if 'items' in result:
            for item in result['items']:
                source = {
                    'title': item.get('title', ''),
                    'link': item.get('link', ''),
                    'snippet': item.get('snippet', ''),
                    'source_name': extract_source_name(item.get('link', '')),
                    'publishedDate': item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', '')
                }
                sources.append(source)
        
        print(f"âœ… Found {len(sources)} reliable sources")
        return sources
        
    except Exception as e:
        print(f"âŒ Google Search error: {e}")
        return []

def extract_source_name(url):
    """Extract readable source name from URL"""
    domain_mapping = {
        'cafef.vn': 'CafeF',
        'vneconomy.vn': 'VnEconomy', 
        'vnexpress.net': 'VnExpress',
        'tuoitre.vn': 'Tuá»•i Tráº»',
        'thanhnien.vn': 'Thanh NiÃªn',
        'baodautu.vn': 'BÃ¡o Äáº§u tÆ°',
        'dantri.com.vn': 'DÃ¢n trÃ­',
        'investing.com': 'Investing.com',
        'bloomberg.com': 'Bloomberg',
        'reuters.com': 'Reuters',
        'bbc.com': 'BBC'
    }
    
    for domain, name in domain_mapping.items():
        if domain in url:
            return name
    
    try:
        from urllib.parse import urlparse
        domain = urlparse(url).netloc.replace('www.', '')
        return domain.title()
    except:
        return 'Unknown Source'

# ğŸ†• CONTENT EXTRACTION FUNCTIONS (FROM ORIGINAL CODE)
async def fetch_content_with_trafilatura(url):
    """ğŸ†• TRÃCH XUáº¤T Ná»˜I DUNG Báº°NG TRAFILATURA - Tá»T NHáº¤T 2024"""
    try:
        if not TRAFILATURA_AVAILABLE:
            return None
        
        print(f"ğŸš€ Sá»­ dá»¥ng Trafilatura cho: {url}")
        
        # Táº£i ná»™i dung
        downloaded = trafilatura.fetch_url(url)
        if not downloaded:
            return None
        
        # TrÃ­ch xuáº¥t vá»›i metadata
        result = trafilatura.bare_extraction(
            downloaded,
            include_comments=False,
            include_tables=True,
            include_links=False,
            with_metadata=True
        )
        
        if result and result.get('text'):
            content = result['text']
            
            # Giá»›i háº¡n Ä‘á»™ dÃ i vÃ  lÃ m sáº¡ch
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            return content.strip()
        
        return None
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i Trafilatura cho {url}: {e}")
        return None

async def fetch_content_with_newspaper(url):
    """ğŸ“° TRÃCH XUáº¤T Báº°NG NEWSPAPER3K - FALLBACK"""
    try:
        if not NEWSPAPER_AVAILABLE:
            return None
        
        print(f"ğŸ“° Sá»­ dá»¥ng Newspaper3k cho: {url}")
        
        # Táº¡o article object
        article = Article(url)
        article.download()
        article.parse()
        
        if article.text:
            content = article.text
            
            # Giá»›i háº¡n Ä‘á»™ dÃ i
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            return content.strip()
        
        return None
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i Newspaper3k cho {url}: {e}")
        return None

async def fetch_content_legacy(url):
    """ğŸ”„ PHÆ¯Æ NG PHÃP CÅ¨ - CUá»I CÃ™NG FALLBACK"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        response = requests.get(url, headers=headers, timeout=8, stream=True)
        response.raise_for_status()
        
        # Xá»­ lÃ½ encoding
        raw_content = response.content
        detected = chardet.detect(raw_content)
        encoding = detected['encoding'] or 'utf-8'
        
        try:
            content = raw_content.decode(encoding)
        except:
            content = raw_content.decode('utf-8', errors='ignore')
        
        # Loáº¡i bá» HTML tags cÆ¡ báº£n
        clean_content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
        clean_content = re.sub(r'<style[^>]*>.*?</style>', '', clean_content, flags=re.DOTALL | re.IGNORECASE)
        clean_content = re.sub(r'<[^>]+>', ' ', clean_content)
        clean_content = html.unescape(clean_content)
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
        
        # Láº¥y pháº§n Ä‘áº§u cÃ³ Ã½ nghÄ©a
        sentences = clean_content.split('. ')
        meaningful_content = []
        
        for sentence in sentences[:8]:
            if len(sentence.strip()) > 20:
                meaningful_content.append(sentence.strip())
                
        result = '. '.join(meaningful_content)
        
        if len(result) > 1800:
            result = result[:1800] + "..."
            
        return result if result else "KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« bÃ i viáº¿t nÃ y."
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i legacy extraction tá»« {url}: {e}")
        return f"KhÃ´ng thá»ƒ láº¥y ná»™i dung chi tiáº¿t. Lá»—i: {str(e)}"

async def fetch_full_content_improved(url):
    """ğŸ†• TRÃCH XUáº¤T Ná»˜I DUNG Cáº¢I TIáº¾N - Sá»¬ Dá»¤NG 3 PHÆ¯Æ NG PHÃP"""
    # Thá»­ phÆ°Æ¡ng phÃ¡p 1: Trafilatura (tá»‘t nháº¥t)
    content = await fetch_content_with_trafilatura(url)
    if content and len(content) > 50:
        print("âœ… ThÃ nh cÃ´ng vá»›i Trafilatura")
        return content
    
    # Thá»­ phÆ°Æ¡ng phÃ¡p 2: Newspaper3k (fallback)
    content = await fetch_content_with_newspaper(url)
    if content and len(content) > 50:
        print("âœ… ThÃ nh cÃ´ng vá»›i Newspaper3k")
        return content
    
    # PhÆ°Æ¡ng phÃ¡p 3: Legacy method (cuá»‘i cÃ¹ng)
    content = await fetch_content_legacy(url)
    print("âš ï¸ Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p legacy")
    return content

# ğŸ†• IMPROVED CONTENT EXTRACTION
async def get_full_content_from_sources_improved(sources):
    """Láº¥y ná»™i dung Ä‘áº§y Ä‘á»§ vá»›i fallback strategy"""
    
    full_contexts = []
    
    for i, source in enumerate(sources[:3], 1):  # Top 3 sources
        try:
            print(f"ğŸ“„ Extracting content from source {i}: {source['source_name']}")
            
            # Try multiple extraction methods
            content = await fetch_full_content_improved(source['link'])
            
            if content and len(content) > 200:
                # Láº¥y 800 kÃ½ tá»± Ä‘áº§u - chá»©a info quan trá»ng nháº¥t
                summary_content = content[:800]
                
                full_contexts.append(f"""
ğŸ“° NGUá»’N {i}: {source['source_name']}
ğŸ“… Thá»i gian: {source.get('publishedDate', 'KhÃ´ng xÃ¡c Ä‘á»‹nh')}
ğŸ”— Link: {source['link']}
ğŸ“„ Ná»™i dung: {summary_content}
""")
            else:
                # Fallback to snippet
                full_contexts.append(f"""
ğŸ“° NGUá»’N {i}: {source['source_name']} 
ğŸ“„ TÃ³m táº¯t: {source['snippet']}
ğŸ”— Link: {source['link']}
""")
                
        except Exception as e:
            print(f"âš ï¸ Content extraction failed for {source['source_name']}: {e}")
            # Fallback to snippet
            full_contexts.append(f"""
ğŸ“° NGUá»’N {i}: {source['source_name']}
ğŸ“„ TÃ³m táº¯t: {source['snippet']}
ğŸ”— Link: {source['link']}
""")
    
    return "\n".join(full_contexts)

# RSS COLLECTION FUNCTIONS (FROM ORIGINAL CODE)
async def collect_news_from_sources(sources_dict, limit_per_source=8):
    """Thu tháº­p tin tá»©c vá»›i xá»­ lÃ½ mÃºi giá» chÃ­nh xÃ¡c"""
    all_news = []
    
    for source_name, rss_url in sources_dict.items():
        try:
            print(f"ğŸ”„ Äang láº¥y tin tá»« {source_name}...")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/rss+xml, application/xml, text/xml',
                'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8'
            }
            
            try:
                response = requests.get(rss_url, headers=headers, timeout=10)
                response.raise_for_status()
                feed = feedparser.parse(response.content)
            except Exception as req_error:
                print(f"âš ï¸ Lá»—i request tá»« {source_name}: {req_error}")
                feed = feedparser.parse(rss_url)
            
            if not hasattr(feed, 'entries') or len(feed.entries) == 0:
                print(f"âš ï¸ KhÃ´ng cÃ³ tin tá»« {source_name}")
                continue
                
            entries_processed = 0
            for entry in feed.entries[:limit_per_source]:
                try:
                    # ğŸ”§ Xá»¬ LÃ THá»œI GIAN CHÃNH XÃC
                    vn_time = datetime.now(VN_TIMEZONE)  # Default fallback
                    
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.published_parsed)
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.updated_parsed)
                    
                    # Láº¥y mÃ´ táº£
                    description = ""
                    if hasattr(entry, 'summary'):
                        description = entry.summary[:500] + "..." if len(entry.summary) > 500 else entry.summary
                    elif hasattr(entry, 'description'):
                        description = entry.description[:500] + "..." if len(entry.description) > 500 else entry.description
                    
                    if not hasattr(entry, 'title') or not hasattr(entry, 'link'):
                        continue
                    
                    title = html.unescape(entry.title.strip())
                    
                    news_item = {
                        'title': title,
                        'link': entry.link,
                        'source': source_name,
                        'published': vn_time,
                        'published_str': vn_time.strftime("%H:%M %d/%m"),
                        'description': html.unescape(description) if description else ""
                    }
                    all_news.append(news_item)
                    entries_processed += 1
                    
                except Exception as entry_error:
                    print(f"âš ï¸ Lá»—i xá»­ lÃ½ tin tá»« {source_name}: {entry_error}")
                    continue
                    
            print(f"âœ… Láº¥y Ä‘Æ°á»£c {entries_processed} tin tá»« {source_name}")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi láº¥y tin tá»« {source_name}: {e}")
            continue
    
    print(f"ğŸ“Š Tá»•ng cá»™ng láº¥y Ä‘Æ°á»£c {len(all_news)} tin tá»« táº¥t cáº£ nguá»“n")
    
    # Loáº¡i bá» tin trÃ¹ng láº·p
    unique_news = remove_duplicate_news(all_news)
    print(f"ğŸ”„ Sau khi loáº¡i trÃ¹ng cÃ²n {len(unique_news)} tin")
    
    # Sáº¯p xáº¿p theo thá»i gian má»›i nháº¥t
    unique_news.sort(key=lambda x: x['published'], reverse=True)
    return unique_news

def remove_duplicate_news(news_list):
    """Loáº¡i bá» tin tá»©c trÃ¹ng láº·p"""
    seen_links = set()
    seen_titles = set()
    unique_news = []
    
    for news in news_list:
        normalized_title = normalize_title(news['title'])
        
        is_duplicate = False
        
        if news['link'] in seen_links:
            is_duplicate = True
        else:
            for existing_title in seen_titles:
                similarity = calculate_title_similarity(normalized_title, existing_title)
                if similarity > 0.75:
                    is_duplicate = True
                    break
        
        if not is_duplicate:
            seen_links.add(news['link'])
            seen_titles.add(normalized_title)
            unique_news.append(news)
    
    return unique_news

def calculate_title_similarity(title1, title2):
    """TÃ­nh Ä‘á»™ tÆ°Æ¡ng tá»± giá»¯a 2 tiÃªu Ä‘á»"""
    words1 = set(title1.split())
    words2 = set(title2.split())
    
    if not words1 or not words2:
        return 0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0

def normalize_title(title):
    """Chuáº©n hÃ³a tiÃªu Ä‘á» Ä‘á»ƒ so sÃ¡nh trÃ¹ng láº·p"""
    import re
    title = title.lower()
    title = re.sub(r'[^\w\s]', '', title)
    title = ' '.join(title.split())
    
    words = title.split()[:10]
    return ' '.join(words)

def save_user_news(user_id, news_list, command_type):
    """LÆ°u tin tá»©c cá»§a user Ä‘á»ƒ sá»­ dá»¥ng cho lá»‡nh !detail"""
    user_news_cache[user_id] = {
        'news': news_list,
        'command': command_type,
        'timestamp': datetime.now(VN_TIMEZONE)
    }

# BOT EVENT HANDLERS
@bot.event
async def on_ready():
    print(f'âœ… {bot.user} Ä‘Ã£ online!')
    print(f'ğŸ“Š Káº¿t ná»‘i vá»›i {len(bot.guilds)} server(s)')
    
    # AI Engine status
    if ai_manager.primary_ai:
        print(f'ğŸ¤– Primary AI: {ai_manager.primary_ai.value.upper()}')
        print(f'ğŸ›¡ï¸ Fallback AIs: {[ai.value.upper() for ai in ai_manager.fallback_ais]}')
    else:
        print('âš ï¸ No AI engines configured')
    
    total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
    print(f'ğŸ“° Sáºµn sÃ ng cung cáº¥p tin tá»« {total_sources} nguá»“n ÄÃƒ KIá»‚M TRA')
    print(f'ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {len(RSS_FEEDS["domestic"])} nguá»“n')
    print(f'ğŸŒ Quá»‘c táº¿: {len(RSS_FEEDS["international"])} nguá»“n')
    print('ğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, VÄ© mÃ´, Báº¥t Ä‘á»™ng sáº£n')
    
    # Kiá»ƒm tra thÆ° viá»‡n Ä‘Ã£ cÃ i Ä‘áº·t
    if TRAFILATURA_AVAILABLE:
        print('ğŸš€ Trafilatura: TrÃ­ch xuáº¥t ná»™i dung cáº£i tiáº¿n (94.5% Ä‘á»™ chÃ­nh xÃ¡c)')
    if NEWSPAPER_AVAILABLE:
        print('ğŸ“° Newspaper3k: Fallback extraction cho tin tá»©c')
    
    print('ğŸ¯ GÃµ !menu Ä‘á»ƒ xem hÆ°á»›ng dáº«n')
    
    # Set bot status
    status_text = f"Multi-AI Engine â€¢ {ai_manager.primary_ai.value.upper() if ai_manager.primary_ai else 'No AI'} â€¢ !menu"
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching,
            name=status_text
        )
    )

# DISCORD COMMANDS (FROM ORIGINAL CODE)
@bot.command(name='all')
async def get_all_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« táº¥t cáº£ nguá»“n vá»›i mÃºi giá» chÃ­nh xÃ¡c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c tá»« táº¥t cáº£ nguá»“n...")
        
        domestic_news = await collect_news_from_sources(RSS_FEEDS['domestic'], 8)
        international_news = await collect_news_from_sources(RSS_FEEDS['international'], 6)
        
        await loading_msg.delete()
        
        all_news = domestic_news + international_news
        all_news.sort(key=lambda x: x['published'], reverse=True)
        
        # PhÃ¢n trang
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = all_news[start_index:end_index]
        
        if not page_news:
            total_pages = (len(all_news) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        # Táº¡o embed vá»›i thÃ´ng tin mÃºi giá»
        embed = discord.Embed(
            title=f"ğŸ“° Tin tá»©c kinh táº¿ tá»•ng há»£p (Trang {page})",
            description=f"ğŸ•°ï¸ Giá» Viá»‡t Nam chÃ­nh xÃ¡c â€¢ ğŸš€ Multi-AI Engine â€¢ ğŸ“° Tá»« {len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])} nguá»“n",
            color=0x00ff88,
            timestamp=ctx.message.created_at
        )
        
        # Emoji map
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸', 'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 
            'marketwatch_latest': 'ğŸ“ˆ', 'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        # Thá»‘ng kÃª
        domestic_count = sum(1 for news in page_news if news['source'] in RSS_FEEDS['domestic'])
        international_count = len(page_news) - domestic_count
        
        embed.add_field(
            name="ğŸ“Š Thá»‘ng kÃª trang nÃ y",
            value=f"ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {domestic_count} tin\nğŸŒ Quá»‘c táº¿: {international_count} tin\nğŸ“Š Tá»•ng cÃ³ sáºµn: {len(all_news)} tin",
            inline=False
        )
        
        # Hiá»ƒn thá»‹ tin tá»©c vá»›i thá»i gian chÃ­nh xÃ¡c
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy CK',
            'vnexpress_kinhdoanh': 'VnExpress KD', 'vnexpress_chungkhoan': 'VnExpress CK',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VM', 'thanhnien_chungkhoan': 'Thanh NiÃªn CK',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TC', 'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters',
            'bloomberg_markets': 'Bloomberg', 'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes',
            'financial_times': 'Financial Times', 'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ•°ï¸ {news['published_str']} (VN) â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"all_page_{page}")
        
        total_pages = (len(all_news) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸš€ Multi-AI Engine â€¢ Trang {page}/{total_pages} â€¢ !all {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Sá»‘ trang khÃ´ng há»£p lá»‡! Sá»­ dá»¥ng: `!all [sá»‘]`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='in')
async def get_domestic_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« cÃ¡c nguá»“n trong nÆ°á»›c vá»›i mÃºi giá» chÃ­nh xÃ¡c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c trong nÆ°á»›c...")
        
        news_list = await collect_news_from_sources(RSS_FEEDS['domestic'], 10)
        
        await loading_msg.delete()
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"ğŸ‡»ğŸ‡³ Tin kinh táº¿ trong nÆ°á»›c (Trang {page})",
            description=f"ğŸ•°ï¸ Giá» Viá»‡t Nam chÃ­nh xÃ¡c â€¢ ğŸš€ Multi-AI Engine â€¢ Tá»« {len(RSS_FEEDS['domestic'])} nguá»“n chuyÃªn ngÃ nh",
            color=0xff0000,
            timestamp=ctx.message.created_at
        )
        
        embed.add_field(
            name="ğŸ“Š ThÃ´ng tin",
            value=f"ğŸ“° Tá»•ng tin cÃ³ sáºµn: {len(news_list)} tin\nğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, Báº¥t Ä‘á»™ng sáº£n, VÄ© mÃ´",
            inline=False
        )
        
        # Hiá»ƒn thá»‹ tin tá»©c trong nÆ°á»›c
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸'
        }
        
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy CK',
            'vnexpress_kinhdoanh': 'VnExpress KD', 'vnexpress_chungkhoan': 'VnExpress CK',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VM', 'thanhnien_chungkhoan': 'Thanh NiÃªn CK',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TC'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ•°ï¸ {news['published_str']} (VN) â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"in_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸš€ Multi-AI Engine â€¢ Trang {page}/{total_pages} â€¢ !in {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='out')
async def get_international_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« cÃ¡c nguá»“n quá»‘c táº¿ vá»›i mÃºi giá» chÃ­nh xÃ¡c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c quá»‘c táº¿...")
        
        news_list = await collect_news_from_sources(RSS_FEEDS['international'], 8)
        
        await loading_msg.delete()
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"ğŸŒ Tin kinh táº¿ quá»‘c táº¿ (Trang {page})",
            description=f"ğŸ•°ï¸ Giá» Viá»‡t Nam chÃ­nh xÃ¡c â€¢ ğŸš€ Multi-AI Engine â€¢ Tá»« {len(RSS_FEEDS['international'])} nguá»“n hÃ ng Ä‘áº§u",
            color=0x0066ff,
            timestamp=ctx.message.created_at
        )
        
        embed.add_field(
            name="ğŸ“Š ThÃ´ng tin",
            value=f"ğŸ“° Tá»•ng tin cÃ³ sáºµn: {len(news_list)} tin",
            inline=False
        )
        
        emoji_map = {
            'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 'marketwatch_latest': 'ğŸ“ˆ',
            'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        source_names = {
            'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters', 'bloomberg_markets': 'Bloomberg', 
            'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes', 'financial_times': 'Financial Times', 
            'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸŒ')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ•°ï¸ {news['published_str']} (VN) â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"out_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸš€ Multi-AI Engine â€¢ Trang {page}/{total_pages} â€¢ !out {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='chitiet')
async def get_news_detail(ctx, news_number: int):
    """ğŸ†• XEM CHI TIáº¾T Báº°NG MULTI-AI ENGINE + Tá»° Äá»˜NG Dá»ŠCH"""
    try:
        user_id = ctx.author.id
        
        if user_id not in user_news_cache:
            await ctx.send("âŒ Báº¡n chÆ°a xem tin tá»©c nÃ o! HÃ£y dÃ¹ng `!all`, `!in`, hoáº·c `!out` trÆ°á»›c.")
            return
        
        user_data = user_news_cache[user_id]
        news_list = user_data['news']
        
        if news_number < 1 or news_number > len(news_list):
            await ctx.send(f"âŒ Sá»‘ khÃ´ng há»£p lá»‡! Chá»n tá»« 1 Ä‘áº¿n {len(news_list)}")
            return
        
        news = news_list[news_number - 1]
        
        # ThÃ´ng bÃ¡o Ä‘ang táº£i vá»›i thÃ´ng tin cÃ´ng nghá»‡
        loading_msg = await ctx.send("ğŸš€ Äang trÃ­ch xuáº¥t ná»™i dung vá»›i Multi-AI Engine...")
        
        # Sá»­ dá»¥ng function cáº£i tiáº¿n
        full_content = await fetch_full_content_improved(news['link'])
        
        # ğŸŒ TÃNH NÄ‚NG Má»šI: Tá»± Ä‘á»™ng dá»‹ch náº¿u lÃ  tin nÆ°á»›c ngoÃ i
        international_sources = {
            'yahoo_finance', 'reuters_business', 'bloomberg_markets', 'marketwatch_latest',
            'forbes_money', 'financial_times', 'business_insider', 'the_economist'
        }
        
        translated_content = full_content
        is_translated = False
        
        if news['source'] in international_sources and ai_manager.primary_ai:
            try:
                # Detect English content
                english_indicators = ['the', 'and', 'is', 'are', 'was', 'were', 'have', 'has']
                content_lower = full_content.lower()
                english_word_count = sum(1 for word in english_indicators if word in content_lower)
                
                if english_word_count >= 3:
                    print(f"ğŸŒ Äang dá»‹ch ná»™i dung tá»« {news['source']} sang tiáº¿ng Viá»‡t...")
                    
                    translation_prompt = f"""Dá»‹ch Ä‘oáº¡n vÄƒn tiáº¿ng Anh sau sang tiáº¿ng Viá»‡t chÃ­nh xÃ¡c, tá»± nhiÃªn:

{full_content}

YÃªu cáº§u:
- Giá»¯ nguyÃªn sá»‘ liá»‡u, tá»· lá»‡ pháº§n trÄƒm
- Dá»‹ch tá»± nhiÃªn, khÃ´ng mÃ¡y mÃ³c
- Sá»­ dá»¥ng thuáº­t ngá»¯ kinh táº¿ tiáº¿ng Viá»‡t chuáº©n

Báº£n dá»‹ch:"""

                    translated_content, used_engine = await ai_manager.call_ai_with_fallback(
                        prompt=translation_prompt,
                        context="",
                        require_specific_data=False
                    )
                    
                    if translated_content and "âŒ" not in translated_content:
                        is_translated = True
                        print("âœ… Dá»‹ch thuáº­t thÃ nh cÃ´ng")
                    else:
                        translated_content = full_content
                        
            except Exception as e:
                print(f"âš ï¸ Lá»—i dá»‹ch thuáº­t: {e}")
                translated_content = full_content
        
        await loading_msg.delete()
        
        # Táº¡o embed Ä‘áº¹p hÆ¡n
        embed = discord.Embed(
            title="ğŸ“– Chi tiáº¿t bÃ i viáº¿t",
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        # Emoji cho nguá»“n
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸', 'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 
            'marketwatch_latest': 'ğŸ“ˆ', 'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF Chá»©ng khoÃ¡n', 'cafef_batdongsan': 'CafeF Báº¥t Ä‘á»™ng sáº£n',
            'cafef_taichinh': 'CafeF TÃ i chÃ­nh', 'cafef_vimo': 'CafeF VÄ© mÃ´', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy Chá»©ng khoÃ¡n',
            'vnexpress_kinhdoanh': 'VnExpress Kinh doanh', 'vnexpress_chungkhoan': 'VnExpress Chá»©ng khoÃ¡n',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VÄ© mÃ´', 'thanhnien_chungkhoan': 'Thanh NiÃªn Chá»©ng khoÃ¡n',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TÃ i chÃ­nh', 'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters Business',
            'bloomberg_markets': 'Bloomberg Markets', 'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes Money',
            'financial_times': 'Financial Times', 'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        emoji = emoji_map.get(news['source'], 'ğŸ“°')
        source_display = source_names.get(news['source'], news['source'])
        
        # ThÃªm indicator dá»‹ch thuáº­t vÃ o tiÃªu Ä‘á»
        title_suffix = " ğŸŒ (ÄÃ£ dá»‹ch)" if is_translated else ""
        embed.add_field(
            name=f"{emoji} TiÃªu Ä‘á»{title_suffix}",
            value=news['title'],
            inline=False
        )
        
        embed.add_field(
            name="ğŸ•°ï¸ Thá»i gian (VN)",
            value=news['published_str'],
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“° Nguá»“n",
            value=source_display + (" ğŸŒ" if is_translated else ""),
            inline=True
        )
        
        # Sá»­ dá»¥ng ná»™i dung Ä‘Ã£ dá»‹ch (náº¿u cÃ³)
        content_to_display = translated_content
        
        # Hiá»ƒn thá»‹ ná»™i dung Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
        if len(content_to_display) > 1000:
            # Chia ná»™i dung thÃ nh 2 pháº§n
            content_title = "ğŸ“„ Ná»™i dung chi tiáº¿t ğŸŒ (ÄÃ£ dá»‹ch sang tiáº¿ng Viá»‡t)" if is_translated else "ğŸ“„ Ná»™i dung chi tiáº¿t"
            
            embed.add_field(
                name=f"{content_title} (Pháº§n 1)",
                value=content_to_display[:1000] + "...",
                inline=False
            )
            
            await ctx.send(embed=embed)
            
            # Táº¡o embed thá»© 2
            embed2 = discord.Embed(
                title=f"ğŸ“– Chi tiáº¿t bÃ i viáº¿t (tiáº¿p theo){'ğŸŒ' if is_translated else ''}",
                color=0x9932cc
            )
            
            embed2.add_field(
                name=f"{content_title} (Pháº§n 2)",
                value=content_to_display[1000:2000],
                inline=False
            )
            
            # ThÃªm thÃ´ng tin vá» báº£n gá»‘c náº¿u Ä‘Ã£ dá»‹ch
            if is_translated:
                embed2.add_field(
                    name="ğŸ”„ ThÃ´ng tin dá»‹ch thuáº­t",
                    value="ğŸ“ Ná»™i dung gá»‘c báº±ng tiáº¿ng Anh Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch sang tiáº¿ng Viá»‡t báº±ng Multi-AI Engine\nğŸ’¡ Äá»ƒ xem báº£n gá»‘c, vui lÃ²ng truy cáº­p link bÃ i viáº¿t",
                    inline=False
                )
            
            embed2.add_field(
                name="ğŸ”— Äá»c bÃ i viáº¿t Ä‘áº§y Ä‘á»§",
                value=f"[Nháº¥n Ä‘á»ƒ Ä‘á»c toÃ n bá»™ bÃ i viáº¿t gá»‘c]({news['link']})",
                inline=False
            )
            
            # ThÃ´ng tin cÃ´ng nghá»‡ sá»­ dá»¥ng
            tech_info = "ğŸš€ Multi-AI Engine"
            if TRAFILATURA_AVAILABLE:
                tech_info += " + Trafilatura"
            if NEWSPAPER_AVAILABLE:
                tech_info += " + Newspaper3k"
            if is_translated:
                tech_info += " + AI Translation"
            
            embed2.set_footer(text=f"{tech_info} â€¢ Tá»« lá»‡nh: {user_data['command']} â€¢ Tin sá»‘ {news_number}")
            
            await ctx.send(embed=embed2)
            return
        else:
            content_title = "ğŸ“„ Ná»™i dung chi tiáº¿t ğŸŒ (ÄÃ£ dá»‹ch sang tiáº¿ng Viá»‡t)" if is_translated else "ğŸ“„ Ná»™i dung chi tiáº¿t"
            embed.add_field(
                name=content_title,
                value=content_to_display,
                inline=False
            )
        
        # ThÃªm thÃ´ng tin vá» dá»‹ch thuáº­t náº¿u cÃ³
        if is_translated:
            embed.add_field(
                name="ğŸ”„ ThÃ´ng tin dá»‹ch thuáº­t",
                value="ğŸ“ BÃ i viáº¿t gá»‘c báº±ng tiáº¿ng Anh Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch sang tiáº¿ng Viá»‡t báº±ng Multi-AI Engine",
                inline=False
            )
        
        embed.add_field(
            name="ğŸ”— Äá»c bÃ i viáº¿t Ä‘áº§y Ä‘á»§",
            value=f"[Nháº¥n Ä‘á»ƒ Ä‘á»c toÃ n bá»™ bÃ i viáº¿t{'gá»‘c' if is_translated else ''}]({news['link']})",
            inline=False
        )
        
        # ThÃ´ng tin cÃ´ng nghá»‡ sá»­ dá»¥ng
        tech_info = "ğŸš€ Multi-AI Engine"
        if TRAFILATURA_AVAILABLE:
            tech_info += " + Trafilatura"
        if NEWSPAPER_AVAILABLE:
            tech_info += " + Newspaper3k"
        if is_translated:
            tech_info += " + AI Translation"
        
        embed.set_footer(text=f"{tech_info} â€¢ Tá»« lá»‡nh: {user_data['command']} â€¢ Tin sá»‘ {news_number} â€¢ !menu Ä‘á»ƒ xem thÃªm lá»‡nh")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Vui lÃ²ng nháº­p sá»‘! VÃ­ dá»¥: `!chitiet 5`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

# Alias cho lá»‡nh chitiet
@bot.command(name='cuthe')
async def get_news_detail_alias(ctx, news_number: int):
    """Alias cho lá»‡nh !chitiet"""
    await get_news_detail(ctx, news_number)

# ğŸ†• MAIN AI COMMAND - Completely Rewritten
@bot.command(name='hoi')
async def ask_economic_question_improved(ctx, *, question):
    """ğŸ†• AI Q&A vá»›i Multi-Engine Support vÃ  Validation"""
    
    try:
        if not ai_manager.primary_ai:
            embed = discord.Embed(
                title="âš ï¸ AI Services khÃ´ng kháº£ dá»¥ng",
                description="ChÆ°a cáº¥u hÃ¬nh AI API keys. Cáº§n Ã­t nháº¥t má»™t trong: GEMINI_API_KEY, DEEPSEEK_API_KEY, ANTHROPIC_API_KEY, GROQ_API_KEY",
                color=0xff6b6b
            )
            await ctx.send(embed=embed)
            return
        
        # ThÃ´ng bÃ¡o Ä‘ang xá»­ lÃ½
        processing_msg = await ctx.send("ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin tá»« cÃ¡c nguá»“n tin Ä‘Ã¡ng tin cáº­y...")
        
        # ğŸ” Step 1: Generic Google Search (No specific keywords needed)
        sources = await search_reliable_sources_improved(question, max_results=5)
        
        if not sources:
            await processing_msg.edit(content="âš ï¸ KhÃ´ng tÃ¬m tháº¥y nguá»“n tin. Äang sá»­ dá»¥ng kiáº¿n thá»©c tá»•ng quÃ¡t...")
        
        # ğŸ“„ Step 2: Extract full content 
        await processing_msg.edit(content="ğŸ“„ Äang phÃ¢n tÃ­ch ná»™i dung tá»« cÃ¡c nguá»“n tin...")
        full_context = await get_full_content_from_sources_improved(sources)
        
        # ğŸ¤– Step 3: AI Analysis vá»›i Multi-Engine Fallback
        await processing_msg.edit(content="ğŸ¤– Multi-AI Engine Ä‘ang phÃ¢n tÃ­ch vÃ  táº¡o cÃ¢u tráº£ lá»i...")
        
        # Detect if question requires specific financial data
        requires_specific_data = any(keyword in question.lower() for keyword in 
                                   ['giÃ¡', 'bao nhiÃªu', 'tÄƒng giáº£m', 'thay Ä‘á»•i', 'hiá»‡n táº¡i', 'hÃ´m nay'])
        
        ai_response, used_engine = await ai_manager.call_ai_with_fallback(
            prompt=question,
            context=full_context,
            require_specific_data=requires_specific_data
        )
        
        # XÃ³a thÃ´ng bÃ¡o processing
        await processing_msg.delete()
        
        # ğŸ“Š Create beautiful embed response
        embed = discord.Embed(
            title=f"ğŸ¤– AI Tráº£ lá»i: {question.title()[:100]}...",
            description=ai_response,
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        # Add AI engine info
        engine_emoji = {
            'gemini': 'ğŸ’',
            'deepseek': 'ğŸ’°', 
            'claude': 'ğŸ§ ',
            'groq': 'âš¡'
        }
        
        embed.add_field(
            name="ğŸ¤– AI Engine sá»­ dá»¥ng",
            value=f"{engine_emoji.get(used_engine, 'ğŸ¤–')} {used_engine.upper()}",
            inline=True
        )
        
        if sources:
            embed.add_field(
                name="ğŸ“Š Sá»‘ nguá»“n tin",
                value=f"ğŸ“° {len(sources)} nguá»“n Ä‘Ã¡ng tin cáº­y",
                inline=True
            )
        
        # Add source references
        if sources:
            sources_text = ""
            for i, source in enumerate(sources[:3], 1):
                sources_text += f"{i}. **{source['source_name']}**: [{source['title'][:50]}...]({source['link']})\n"
            
            embed.add_field(
                name="ğŸ“° Nguá»“n tin tham kháº£o",
                value=sources_text,
                inline=False
            )
        
        # Footer
        embed.set_footer(
            text=f"ğŸš€ Multi-AI Engine â€¢ Dá»¯ liá»‡u thá»i gian thá»±c â€¢ !menu Ä‘á»ƒ xem thÃªm lá»‡nh",
            icon_url=ctx.bot.user.avatar.url if ctx.bot.user.avatar else None
        )
        
        await ctx.send(embed=embed)
        
        # Log cho debug
        print(f"âœ… Question answered: '{question}' using {used_engine}")
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {str(e)}")
        print(f"âŒ Error in !hoi command: {e}")

# ğŸ“Š Updated Menu Command
@bot.command(name='menu')
async def help_command_improved(ctx):
    """Menu vá»›i Multi-AI Engine info"""
    
    embed = discord.Embed(
        title="ğŸ¤–ğŸš€ Menu News Bot - Multi-AI Engine",
        description="Bot tin tá»©c kinh táº¿ vá»›i AI thÃ´ng minh Ä‘a engine",
        color=0xff9900
    )
    
    # AI Engine status
    ai_status = ""
    if ai_manager.primary_ai:
        engine_name = ai_manager.primary_ai.value.upper()
        ai_status += f"ğŸš€ **Primary**: {engine_name} âœ…\n"
        
        for fallback in ai_manager.fallback_ais:
            ai_status += f"ğŸ›¡ï¸ **Fallback**: {fallback.value.upper()} âœ…\n"
    else:
        ai_status = "âŒ ChÆ°a cáº¥u hÃ¬nh AI engines"
    
    embed.add_field(
        name="ğŸ¤– AI Engines hoáº¡t Ä‘á»™ng",
        value=ai_status,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ“° Lá»‡nh tin tá»©c",
        value="""
**!all [trang]** - Tin tá»« táº¥t cáº£ nguá»“n (12 tin/trang)
**!in [trang]** - Tin trong nÆ°á»›c (12 tin/trang)  
**!out [trang]** - Tin quá»‘c táº¿ (12 tin/trang)
**!chitiet [sá»‘]** - Xem ná»™i dung chi tiáº¿t + ğŸŒ Tá»± Ä‘á»™ng dá»‹ch
        """,
        inline=True
    )
    
    embed.add_field(
        name="ğŸ¤– Lá»‡nh AI thÃ´ng minh",
        value="""
**!hoi [cÃ¢u há»i]** - AI tráº£ lá»i vá»›i Multi-Engine
*VÃ­ dá»¥: !hoi giÃ¡ vÃ ng hÃ´m nay nhÆ° tháº¿ nÃ o*
        """,
        inline=True
    )
    
    embed.add_field(
        name="ğŸ‡»ğŸ‡³ Nguá»“n trong nÆ°á»›c (13 nguá»“n)",
        value="CafeF (5 chuyÃªn má»¥c), CafeBiz, BÃ¡o Äáº§u tÆ°, VnEconomy (2), VnExpress (2), Thanh NiÃªn (2), NhÃ¢n DÃ¢n",
        inline=True
    )
    
    embed.add_field(
        name="ğŸŒ Nguá»“n quá»‘c táº¿ (8 nguá»“n)",
        value="Yahoo Finance, Reuters, Bloomberg, MarketWatch, Forbes, Financial Times, Business Insider, The Economist",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ¯ TÃ­nh nÄƒng má»›i",
        value="""
âœ… **Multi-AI Engine** - Tá»± Ä‘á»™ng fallback khi AI fail
âœ… **Generic Search** - KhÃ´ng cáº§n config tá»«ng keyword  
âœ… **Real-time Data** - Dá»¯ liá»‡u cáº­p nháº­t liÃªn tá»¥c
âœ… **Response Validation** - Äáº£m báº£o cháº¥t lÆ°á»£ng
âœ… **Full Content Extract** - PhÃ¢n tÃ­ch sÃ¢u
âœ… **Auto Translation** - Tá»± Ä‘á»™ng dá»‹ch tin nÆ°á»›c ngoÃ i
        """,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ’¡ VÃ­ dá»¥ sá»­ dá»¥ng AI",
        value="""
`!hoi giÃ¡ vÃ ng hÃ´m nay nhÆ° tháº¿ nÃ o` - Há»i vá» giÃ¡ vÃ ng hiá»‡n táº¡i
`!hoi táº¡i sao tá»· giÃ¡ USD tÄƒng` - PhÃ¢n tÃ­ch tá»· giÃ¡
`!hoi giÃ¡ nhÃ  Ä‘áº¥t TPHCM cÃ³ Ä‘áº¯t khÃ´ng` - Há»i vá» báº¥t Ä‘á»™ng sáº£n
`!hoi chá»©ng khoÃ¡n VN-Index hÃ´m nay` - ThÃ´ng tin chá»©ng khoÃ¡n
        """,
        inline=False
    )
    
    if not ai_manager.primary_ai:
        embed.add_field(
            name="âš™ï¸ Cáº¥u hÃ¬nh AI (Ä‘á»ƒ báº­t thÃªm tÃ­nh nÄƒng)",
            value="""
Bot Ä‘Ã£ hoáº¡t Ä‘á»™ng Ä‘áº§y Ä‘á»§ á»Ÿ cháº¿ Ä‘á»™ cÆ¡ báº£n.
Äá»ƒ kÃ­ch hoáº¡t AI features, thÃªm vÃ o Environment Variables:
â€¢ **GEMINI_API_KEY** - Miá»…n phÃ­ táº¡i aistudio.google.com (KHUYáº¾N NGHá»Š)
â€¢ **DEEPSEEK_API_KEY** - SiÃªu ráº» táº¡i platform.deepseek.com
â€¢ **ANTHROPIC_API_KEY** - Claude táº¡i console.anthropic.com  
â€¢ **GROQ_API_KEY** - Nhanh nháº¥t táº¡i console.groq.com
            """,
            inline=False
        )
    
    embed.set_footer(text="ğŸš€ Multi-AI Engine â€¢ Generic Search â€¢ Real-time Analysis â€¢ Auto Translation")
    await ctx.send(embed=embed)

# Main execution
if __name__ == "__main__":
    try:
        keep_alive()  # Báº­t web server Ä‘á»ƒ keep alive
        print("ğŸš€ Starting Multi-AI Discord News Bot...")
        print("ğŸ”‘ Äang kiá»ƒm tra token tá»« Environment Variables...")
        
        if TOKEN:
            print("âœ… Token Ä‘Ã£ Ä‘Æ°á»£c táº£i tá»« Environment Variables")
        
        total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
        print(f"ğŸ“Š ÄÃ£ load {total_sources} nguá»“n RSS ÄÃƒ KIá»‚M TRA")
        print(f"ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {len(RSS_FEEDS['domestic'])} nguá»“n")
        print(f"ğŸŒ Quá»‘c táº¿: {len(RSS_FEEDS['international'])} nguá»“n")
        print("ğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, VÄ© mÃ´, Báº¥t Ä‘á»™ng sáº£n")
        print("ğŸ•°ï¸ MÃºi giá»: ÄÃ£ sá»­a lá»—i - Hiá»ƒn thá»‹ chÃ­nh xÃ¡c giá» Viá»‡t Nam")
        
        print("âœ… Bot ready with Multi-AI Engine support!")
        bot.run(TOKEN)
        
    except Exception as e:
        print(f"âŒ Bot startup error: {e}")
        input("Press Enter to exit...")
