import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime, timedelta
import time
import calendar
from urllib.parse import urljoin, urlparse, quote
import html
import chardet
import pytz
import json
import aiohttp
from keep_alive import keep_alive
from enum import Enum
from typing import List, Dict, Tuple, Optional
import random

# ğŸš€ OPTIMIZED LIBRARIES - CafeF Focus
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
except ImportError:
    TRAFILATURA_AVAILABLE = False

try:
    import newspaper
    from newspaper import Article
    NEWSPAPER_AVAILABLE = True
except ImportError:
    NEWSPAPER_AVAILABLE = False

try:
    from bs4 import BeautifulSoup
    BEAUTIFULSOUP_AVAILABLE = True
except ImportError:
    BEAUTIFULSOUP_AVAILABLE = False

try:
    import wikipedia
    WIKIPEDIA_AVAILABLE = True
except ImportError:
    WIKIPEDIA_AVAILABLE = False

# ğŸ†• GEMINI ONLY - Enhanced AI System
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

# Bot configuration
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# ğŸ”’ ENVIRONMENT VARIABLES
TOKEN = os.getenv('DISCORD_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')

# ğŸ”§ TIMEZONE - Vietnam
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# ğŸ”§ DISCORD LIMITS
DISCORD_EMBED_FIELD_VALUE_LIMIT = 1000
DISCORD_EMBED_DESCRIPTION_LIMIT = 4000
DISCORD_EMBED_TITLE_LIMIT = 250
DISCORD_EMBED_TOTAL_EMBED_LIMIT = 5800

# User cache
user_news_cache = {}
user_last_detail_cache = {}  # New: Track last !chitiet article
MAX_CACHE_ENTRIES = 25

# ğŸ”§ Enhanced User Agents for CafeF + Yahoo Finance
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'curl/7.68.0'
]

def get_current_vietnam_datetime():
    """Get current Vietnam date and time"""
    return datetime.now(VN_TIMEZONE)

def get_current_date_str():
    """Get current date string in Vietnam format"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%d/%m/%Y")

def get_current_time_str():
    """Get current time string in Vietnam format"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%H:%M")

def get_current_datetime_str():
    """Get current datetime string for display"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%H:%M %d/%m/%Y")

print("ğŸš€ OPTIMIZED NEWS BOT - CAFEF + YAHOO FINANCE:")
print(f"DISCORD_TOKEN: {'âœ… Found' if TOKEN else 'âŒ Missing'}")
print(f"GEMINI_API_KEY: {'âœ… Found' if GEMINI_API_KEY else 'âŒ Missing'}")
print(f"ğŸ”§ Current Vietnam time: {get_current_datetime_str()}")
print("=" * 50)

if not TOKEN:
    print("âŒ CRITICAL: DISCORD_TOKEN not found!")
    exit(1)

# ğŸ”§ OPTIMIZED RSS FEEDS - CafeF Focus + Working Yahoo Finance URLs
RSS_FEEDS = {
    # === KINH Táº¾ TRONG NÆ¯á»šC - CHá»ˆ CAFEF ===
    'domestic': {
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'cafef_batdongsan': 'https://cafef.vn/bat-dong-san.rss',
        'cafef_taichinh': 'https://cafef.vn/tai-chinh-ngan-hang.rss',
        'cafef_vimo': 'https://cafef.vn/vi-mo-dau-tu.rss',
        'cafef_doanhnghiep': 'https://cafef.vn/doanh-nghiep.rss'
    },
    
    # === QUá»C Táº¾ - YAHOO FINANCE WORKING URLs ===
    'international': {
        'yahoo_finance_news': 'https://finance.yahoo.com/news/rssindex',
        'yahoo_finance_main': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'yahoo_finance_business': 'https://feeds.finance.yahoo.com/rss/2.0/category-business',
        'yahoo_finance_world': 'https://finance.yahoo.com/news/rss'
    }
}

def convert_utc_to_vietnam_time(utc_time_tuple):
    """Convert UTC to Vietnam time"""
    try:
        utc_timestamp = calendar.timegm(utc_time_tuple)
        utc_dt = datetime.fromtimestamp(utc_timestamp, tz=UTC_TIMEZONE)
        vn_dt = utc_dt.astimezone(VN_TIMEZONE)
        return vn_dt
    except Exception as e:
        return datetime.now(VN_TIMEZONE)

# ğŸ”§ CONTENT VALIDATION FOR DISCORD
def validate_and_truncate_content(content: str, limit: int, suffix: str = "...") -> str:
    """Strict validation and truncation for Discord limits"""
    if not content:
        return "KhÃ´ng cÃ³ ná»™i dung."
    
    content = str(content).strip()
    safe_limit = max(limit - 50, 100)
    
    if len(content) <= safe_limit:
        return content
    
    available_space = safe_limit - len(suffix)
    if available_space <= 0:
        return suffix[:safe_limit]
    
    truncated = content[:available_space].rstrip()
    last_sentence = truncated.rfind('. ')
    if last_sentence > available_space * 0.7:
        truncated = truncated[:last_sentence + 1]
    
    return truncated + suffix

def validate_embed_field(name: str, value: str) -> Tuple[str, str]:
    """Strict embed field validation for Discord limits"""
    safe_name = validate_and_truncate_content(name, DISCORD_EMBED_TITLE_LIMIT, "...")
    safe_value = validate_and_truncate_content(value, DISCORD_EMBED_FIELD_VALUE_LIMIT, "...")
    
    if not safe_value or safe_value == "...":
        safe_value = "Ná»™i dung khÃ´ng kháº£ dá»¥ng."
    
    return safe_name, safe_value

def create_safe_embed(title: str, description: str = "", color: int = 0x00ff88) -> discord.Embed:
    """Create safe embed that fits Discord limits"""
    safe_title = validate_and_truncate_content(title, DISCORD_EMBED_TITLE_LIMIT, "...")
    safe_description = validate_and_truncate_content(description, DISCORD_EMBED_DESCRIPTION_LIMIT, "...")
    
    return discord.Embed(
        title=safe_title,
        description=safe_description,
        color=color,
        timestamp=get_current_vietnam_datetime()
    )

# ğŸ”§ Enhanced headers for CafeF and Yahoo Finance
def get_enhanced_headers(url=None):
    """Enhanced headers for CafeF and Yahoo Finance"""
    user_agent = random.choice(USER_AGENTS)
    
    headers = {
        'User-Agent': user_agent,
        'Accept': 'application/rss+xml, application/xml, text/xml, text/html, application/xhtml+xml, */*',
        'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'DNT': '1',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache'
    }
    
    if url:
        if 'yahoo' in url.lower():
            headers.update({
                'Referer': 'https://finance.yahoo.com/',
                'Origin': 'https://finance.yahoo.com',
                'Sec-Fetch-Site': 'same-origin',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Dest': 'empty'
            })
        elif 'cafef.vn' in url.lower():
            headers.update({
                'Referer': 'https://cafef.vn/',
                'Origin': 'https://cafef.vn'
            })
    
    return headers

def add_random_delay():
    """Add random delay to avoid rate limiting"""
    delay = random.uniform(1.0, 3.0)
    time.sleep(delay)

# ğŸš€ ENHANCED CONTENT EXTRACTION WITH GEMINI TRANSLATION
async def extract_content_enhanced(url, source_name, news_item=None):
    """Enhanced content extraction with Gemini translation for international news"""
    
    try:
        add_random_delay()
        session = requests.Session()
        headers = get_enhanced_headers(url)
        session.headers.update(headers)
        
        response = session.get(url, timeout=20, allow_redirects=True)
        
        if response.status_code == 200:
            # Method 1: Trafilatura
            if TRAFILATURA_AVAILABLE:
                try:
                    result = trafilatura.bare_extraction(
                        response.content,
                        include_comments=False,
                        include_tables=True,
                        include_links=False,
                        favor_precision=True,
                        with_metadata=True
                    )
                    
                    if result and result.get('text') and len(result['text']) > 300:
                        content = result['text']
                        session.close()
                        
                        # Enhanced Gemini translation for international news
                        if is_international_source(source_name):
                            translated_content = await translate_with_gemini(content, source_name)
                            return translated_content if translated_content else content
                        
                        return content.strip()
                except Exception as e:
                    pass
            
            # Method 2: Newspaper3k
            if NEWSPAPER_AVAILABLE:
                try:
                    session.close()
                    article = Article(url)
                    article.set_config({
                        'headers': headers,
                        'timeout': 20
                    })
                    
                    article.download()
                    article.parse()
                    
                    if article.text and len(article.text) > 300:
                        content = article.text
                        
                        # Enhanced Gemini translation for international news
                        if is_international_source(source_name):
                            translated_content = await translate_with_gemini(content, source_name)
                            return translated_content if translated_content else content
                        
                        return content.strip()
                
                except Exception as e:
                    pass
            
            # Method 3: BeautifulSoup
            if BEAUTIFULSOUP_AVAILABLE:
                try:
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # Enhanced selectors for both CafeF and Yahoo Finance
                    content_selectors = [
                        '[data-testid="article-content"]',  # Yahoo Finance
                        'div.caas-body',  # Yahoo Finance
                        'div.detail-content',  # CafeF
                        'div.fck_detail',  # CafeF
                        'div.content-detail',
                        'div.article-content',
                        'div.entry-content',
                        'div.post-content',
                        'article',
                        'main'
                    ]
                    
                    content = ""
                    for selector in content_selectors:
                        elements = soup.select(selector)
                        if elements:
                            for element in elements:
                                text = element.get_text(strip=True)
                                if len(text) > 500:
                                    content = text
                                    break
                            if content:
                                break
                    
                    if content and len(content) > 500:
                        # Clean content
                        content = clean_content_enhanced(content)
                        
                        session.close()
                        
                        # Enhanced Gemini translation for international news
                        if is_international_source(source_name):
                            translated_content = await translate_with_gemini(content, source_name)
                            return translated_content if translated_content else content
                        
                        return content.strip()
                        
                except Exception as e:
                    pass
        
        session.close()
        return create_fallback_content(url, source_name)
        
    except Exception as e:
        return create_fallback_content(url, source_name, str(e))

def clean_content_enhanced(content):
    """Enhanced content cleaning for both CafeF and Yahoo Finance"""
    if not content:
        return content
    
    # Remove common patterns
    unwanted_patterns = [
        r'Subscribe.*?Premium.*?',
        r'Sign in.*?Account.*?',
        r'Advertisement.*?',
        r'Quáº£ng cÃ¡o.*?',
        r'Theo.*?CafeF.*?',
        r'Nguá»“n.*?:.*?',
        r'Tags:.*?$',
        r'Tá»« khÃ³a:.*?$',
        r'ÄÄƒng kÃ½.*?nháº­n tin.*?',
        r'Like.*?Fanpage.*?',
        r'Follow.*?us.*?'
    ]
    
    for pattern in unwanted_patterns:
        content = re.sub(pattern, '', content, flags=re.IGNORECASE | re.DOTALL)
    
    # Remove excessive whitespace
    content = re.sub(r'\s+', ' ', content)
    content = re.sub(r'\n\s*\n', '\n', content)
    
    return content.strip()

def is_international_source(source_name):
    """Check if source is international (Yahoo Finance)"""
    international_sources = {
        'yahoo_finance_news', 'yahoo_finance_main', 'yahoo_finance_business', 'yahoo_finance_world'
    }
    return source_name in international_sources

def create_fallback_content(url, source_name, error_msg=""):
    """Create fallback content when extraction fails"""
    try:
        article_id = url.split('/')[-1] if '/' in url else 'news-article'
        
        if is_international_source(source_name):
            return f"""**Yahoo Finance News Analysis:**

ğŸ“ˆ **Financial Market Insights:** This article provides financial market analysis and economic insights from Yahoo Finance.

ğŸ“Š **Market Coverage:**
â€¢ Real-time stock market data and analysis
â€¢ Economic indicators and market trends
â€¢ Corporate earnings and financial reports
â€¢ Investment strategies and forecasts

**Article ID:** {article_id}
**Note:** For complete article, please visit the original link.

{f'**Error:** {error_msg}' if error_msg else ''}"""
        else:
            return f"""**Tin tá»©c kinh táº¿ CafeF:**

ğŸ“° **ThÃ´ng tin kinh táº¿:** BÃ i viáº¿t cung cáº¥p thÃ´ng tin kinh táº¿, tÃ i chÃ­nh tá»« CafeF.

ğŸ“Š **Ná»™i dung chuyÃªn sÃ¢u:**
â€¢ PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam
â€¢ Tin tá»©c kinh táº¿ vÄ© mÃ´ vÃ  chÃ­nh sÃ¡ch
â€¢ BÃ¡o cÃ¡o doanh nghiá»‡p vÃ  tÃ i chÃ­nh
â€¢ Báº¥t Ä‘á»™ng sáº£n vÃ  Ä‘áº§u tÆ°

**MÃ£ bÃ i viáº¿t:** {article_id}
**LÆ°u Ã½:** Äá»ƒ Ä‘á»c Ä‘áº§y Ä‘á»§, vui lÃ²ng truy cáº­p link gá»‘c.

{f'**Lá»—i:** {error_msg}' if error_msg else ''}"""
        
    except Exception as e:
        return f"Ná»™i dung tá»« {source_name}. Vui lÃ²ng truy cáº­p link gá»‘c Ä‘á»ƒ Ä‘á»c Ä‘áº§y Ä‘á»§."

# ğŸ†• GEMINI TRANSLATION SYSTEM
async def translate_with_gemini(content: str, source_name: str):
    """Enhanced Gemini translation for international news"""
    try:
        if not GEMINI_API_KEY or not GEMINI_AVAILABLE:
            return None
        
        # Enhanced detection for English content
        english_indicators = ['the', 'and', 'is', 'are', 'was', 'were', 'have', 'has', 
                            'will', 'market', 'price', 'stock', 'financial', 'economic',
                            'company', 'business', 'trade', 'investment', 'percent']
        content_lower = content.lower()
        english_word_count = sum(1 for word in english_indicators if f' {word} ' in f' {content_lower} ')
        
        if english_word_count < 3:
            return None  # Not English content
        
        translation_prompt = f"""Báº¡n lÃ  chuyÃªn gia dá»‹ch thuáº­t kinh táº¿-tÃ i chÃ­nh. HÃ£y dá»‹ch bÃ i bÃ¡o tiáº¿ng Anh sau sang tiáº¿ng Viá»‡t má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  tá»± nhiÃªn.

YÃŠU Cáº¦U Dá»ŠCH:
1. Giá»¯ nguyÃªn Ã½ nghÄ©a vÃ  ngá»¯ cáº£nh kinh táº¿
2. Sá»­ dá»¥ng thuáº­t ngá»¯ kinh táº¿ tiáº¿ng Viá»‡t chuáº©n
3. Dá»‹ch tá»± nhiÃªn, khÃ´ng mÃ¡y mÃ³c
4. Giá»¯ nguyÃªn cÃ¡c con sá»‘, tá»· lá»‡ pháº§n trÄƒm, tÃªn cÃ´ng ty
5. KHÃ”NG thÃªm giáº£i thÃ­ch hay bÃ¬nh luáº­n
6. Chá»‰ tráº£ vá» báº£n dá»‹ch tiáº¿ng Viá»‡t

BÃ€I BÃO Cáº¦N Dá»ŠCH:
{content[:2000]}

Báº¢N Dá»ŠCH TIáº¾NG VIá»†T:"""

        try:
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.1,
                top_p=0.8,
                max_output_tokens=1500,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    translation_prompt,
                    generation_config=generation_config
                ),
                timeout=20
            )
            
            translated_text = response.text.strip()
            return f"[ÄÃ£ dá»‹ch tá»« {source_name}] {translated_text}"
            
        except Exception as e:
            return f"[Lá»—i dá»‹ch tá»« {source_name}] {content[:1000]}..."
            
    except Exception as e:
        return None

# ğŸš€ ENHANCED NEWS COLLECTION
async def collect_news_enhanced(sources_dict, limit_per_source=15):
    """Enhanced news collection for CafeF and Yahoo Finance with improved error handling"""
    all_news = []
    
    for source_name, rss_url in sources_dict.items():
        try:
            print(f"ğŸ”„ Fetching from {source_name}: {rss_url}")
            add_random_delay()
            
            session = requests.Session()
            headers = get_enhanced_headers(rss_url)
            session.headers.update(headers)
            
            # Enhanced error handling for Yahoo Finance
            feed = None
            try:
                response = session.get(rss_url, timeout=15, allow_redirects=True)
                print(f"ğŸ“Š {source_name} response: {response.status_code}")
                
                if response.status_code == 403:
                    print(f"âš ï¸ 403 for {source_name}, trying fallback...")
                    # Try with curl user-agent for Yahoo Finance
                    headers['User-Agent'] = 'curl/7.68.0'
                    session.headers.update(headers)
                    time.sleep(random.uniform(2.0, 4.0))
                    response = session.get(rss_url, timeout=15, allow_redirects=True)
                    print(f"ğŸ”„ Fallback {source_name} response: {response.status_code}")
                
                if response.status_code == 200:
                    feed = feedparser.parse(response.content)
                else:
                    print(f"âš ï¸ {source_name} failed with {response.status_code}, trying direct parse...")
                    feed = feedparser.parse(rss_url)
                
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ Request error for {source_name}: {e}")
                print(f"ğŸ”„ Trying direct feedparser for {source_name}...")
                feed = feedparser.parse(rss_url)
            
            session.close()
            
            if not feed or not hasattr(feed, 'entries') or len(feed.entries) == 0:
                print(f"âŒ No entries for {source_name}")
                # For Yahoo Finance sources, try alternative approach
                if 'yahoo_finance' in source_name:
                    print(f"ğŸ”„ Trying alternative Yahoo Finance approach for {source_name}...")
                    # Skip this source but don't fail completely
                continue
                
            entries_processed = 0
            for entry in feed.entries[:limit_per_source]:
                try:
                    vn_time = get_current_vietnam_datetime()
                    
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.published_parsed)
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.updated_parsed)
                    
                    description = ""
                    if hasattr(entry, 'summary'):
                        description = entry.summary[:400] + "..." if len(entry.summary) > 400 else entry.summary
                    elif hasattr(entry, 'description'):
                        description = entry.description[:400] + "..." if len(entry.description) > 400 else entry.description
                    
                    if hasattr(entry, 'title') and hasattr(entry, 'link'):
                        title = entry.title.strip()
                        
                        # Filter for relevant economic/financial content
                        if is_relevant_news(title, description, source_name):
                            news_item = {
                                'title': html.unescape(title),
                                'link': entry.link,
                                'source': source_name,
                                'published': vn_time,
                                'published_str': vn_time.strftime("%H:%M %d/%m"),
                                'description': html.unescape(description) if description else ""
                            }
                            all_news.append(news_item)
                            entries_processed += 1
                    
                except Exception as entry_error:
                    print(f"âš ï¸ Entry error for {source_name}: {entry_error}")
                    continue
                    
            print(f"âœ… Processed {entries_processed} entries from {source_name}")
            
        except Exception as e:
            print(f"âŒ Error for {source_name}: {e}")
            continue
    
    print(f"ğŸ“Š Total news collected: {len(all_news)}")
    
    # Sort by publish time
    all_news.sort(key=lambda x: x['published'], reverse=True)
    return all_news

def is_relevant_news(title, description, source_name):
    """Filter for relevant economic/financial news"""
    
    # For CafeF sources, all content is relevant (already filtered by RSS category)
    if 'cafef' in source_name:
        return True
    
    # For Yahoo Finance, filter for economic/financial keywords
    if 'yahoo_finance' in source_name:
        economic_keywords = [
            'economy', 'economic', 'gdp', 'inflation', 'fed', 'federal reserve',
            'market', 'stock', 'bond', 'trading', 'investment', 'investor',
            'financial', 'finance', 'bank', 'banking', 'earnings', 'revenue',
            'profit', 'loss', 'company', 'corporate', 'business', 'merger',
            'acquisition', 'ipo', 'dividend', 'interest rate', 'currency',
            'real estate', 'property', 'housing', 'mortgage', 'commodity',
            'oil', 'gold', 'bitcoin', 'crypto', 'policy', 'regulation'
        ]
        
        text_to_check = f"{title} {description}".lower()
        return any(keyword in text_to_check for keyword in economic_keywords)
    
    return True

def save_user_news_enhanced(user_id, news_list, command_type):
    """Enhanced user news saving"""
    global user_news_cache
    
    user_news_cache[user_id] = {
        'news': news_list,
        'command': command_type,
        'timestamp': get_current_vietnam_datetime()
    }
    
    if len(user_news_cache) > MAX_CACHE_ENTRIES:
        oldest_users = sorted(user_news_cache.items(), key=lambda x: x[1]['timestamp'])[:10]
        for user_id_to_remove, _ in oldest_users:
            del user_news_cache[user_id_to_remove]

def save_user_last_detail(user_id, news_item):
    """Save last article accessed via !chitiet"""
    global user_last_detail_cache
    
    user_last_detail_cache[user_id] = {
        'article': news_item,
        'timestamp': get_current_vietnam_datetime()
    }

# ğŸ”§ DISCORD EMBED HELPERS
def split_text_for_discord(text: str, max_length: int = 950) -> List[str]:
    """Split text to fit Discord field limits"""
    if len(text) <= max_length:
        return [text]
    
    parts = []
    current_part = ""
    
    sentences = text.split('. ')
    
    for sentence in sentences:
        if len(current_part + sentence + '. ') <= max_length:
            current_part += sentence + '. '
        else:
            if current_part:
                parts.append(current_part.strip())
                current_part = sentence + '. '
            else:
                parts.append(sentence[:max_length])
                current_part = ""
    
    if current_part:
        parts.append(current_part.strip())
    
    return parts

def create_optimized_embeds(title: str, content: str, color: int = 0x9932cc) -> List[discord.Embed]:
    """Create optimized embeds for Discord limits"""
    embeds = []
    
    content_parts = split_text_for_discord(content, 950)
    
    for i, part in enumerate(content_parts):
        if i == 0:
            embed = discord.Embed(
                title=validate_and_truncate_content(title, DISCORD_EMBED_TITLE_LIMIT),
                color=color,
                timestamp=get_current_vietnam_datetime()
            )
        else:
            embed = discord.Embed(
                title=validate_and_truncate_content(f"{title[:150]}... (Pháº§n {i+1})", DISCORD_EMBED_TITLE_LIMIT),
                color=color,
                timestamp=get_current_vietnam_datetime()
            )
        
        field_name = f"ğŸ“„ Ná»™i dung {f'(Pháº§n {i+1})' if len(content_parts) > 1 else ''}"
        safe_field_name, safe_field_value = validate_embed_field(field_name, part)
        
        embed.add_field(
            name=safe_field_name,
            value=safe_field_value,
            inline=False
        )
        
        embeds.append(embed)
    
    return embeds

def create_safe_embed_with_fields(title: str, description: str, fields_data: List[Tuple[str, str]], color: int = 0x00ff88) -> List[discord.Embed]:
    """Create safe embeds with multiple fields"""
    embeds = []
    
    safe_title = validate_and_truncate_content(title, DISCORD_EMBED_TITLE_LIMIT, "...")
    safe_description = validate_and_truncate_content(description, DISCORD_EMBED_DESCRIPTION_LIMIT, "...")
    
    main_embed = discord.Embed(
        title=safe_title,
        description=safe_description,
        color=color,
        timestamp=get_current_vietnam_datetime()
    )
    
    fields_added = 0
    current_embed = main_embed
    total_chars = len(safe_title) + len(safe_description)
    
    for field_name, field_value in fields_data:
        safe_name, safe_value = validate_embed_field(field_name, field_value)
        
        field_chars = len(safe_name) + len(safe_value)
        
        if fields_added >= 20 or total_chars + field_chars > DISCORD_EMBED_TOTAL_EMBED_LIMIT:
            embeds.append(current_embed)
            current_embed = discord.Embed(
                title=validate_and_truncate_content(f"{safe_title[:180]}... (tiáº¿p theo)", DISCORD_EMBED_TITLE_LIMIT),
                color=color,
                timestamp=get_current_vietnam_datetime()
            )
            fields_added = 0
            total_chars = len(current_embed.title or "")
        
        current_embed.add_field(name=safe_name, value=safe_value, inline=False)
        fields_added += 1
        total_chars += field_chars
    
    embeds.append(current_embed)
    
    return embeds

# ğŸ†• GEMINI AI SYSTEM
class GeminiAIEngine:
    def __init__(self):
        self.available = GEMINI_AVAILABLE and GEMINI_API_KEY
        if self.available:
            genai.configure(api_key=GEMINI_API_KEY)
    
    async def ask_question(self, question: str, context: str = ""):
        """Gemini AI question answering with context"""
        if not self.available:
            return "âš ï¸ Gemini AI khÃ´ng kháº£ dá»¥ng."
        
        try:
            current_date_str = get_current_date_str()
            
            prompt = f"""Báº¡n lÃ  Gemini AI - chuyÃªn gia kinh táº¿ tÃ i chÃ­nh thÃ´ng minh. HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn kiáº¿n thá»©c chuyÃªn mÃ´n cá»§a báº¡n.

CÃ‚U Há»I: {question}

{f"Bá»I Cáº¢NH THÃŠM: {context}" if context else ""}

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
1. Sá»­ dá»¥ng kiáº¿n thá»©c chuyÃªn mÃ´n sÃ¢u rá»™ng cá»§a báº¡n
2. ÄÆ°a ra phÃ¢n tÃ­ch chuyÃªn sÃ¢u vÃ  toÃ n diá»‡n
3. Káº¿t ná»‘i vá»›i bá»‘i cáº£nh kinh táº¿ hiá»‡n táº¡i (ngÃ y {current_date_str})
4. ÄÆ°a ra vÃ­ dá»¥ thá»±c táº¿ vÃ  minh há»a cá»¥ thá»ƒ
5. Äá»™ dÃ i: 400-800 tá»« vá»›i cáº¥u trÃºc rÃµ rÃ ng
6. Sá»­ dá»¥ng Ä‘áº§u má»¥c sá»‘ Ä‘á»ƒ tá»• chá»©c ná»™i dung

HÃ£y thá»ƒ hiá»‡n trÃ­ thÃ´ng minh vÃ  kiáº¿n thá»©c chuyÃªn sÃ¢u cá»§a Gemini AI:"""

            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.2,
                top_p=0.8,
                max_output_tokens=1500,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=25
            )
            
            return response.text.strip()
            
        except asyncio.TimeoutError:
            return "âš ï¸ Gemini AI timeout. Vui lÃ²ng thá»­ láº¡i."
        except Exception as e:
            return f"âš ï¸ Lá»—i Gemini AI: {str(e)}"
    
    async def analyze_article(self, article_content: str, question: str = ""):
        """Analyze specific article with Gemini"""
        if not self.available:
            return "âš ï¸ Gemini AI khÃ´ng kháº£ dá»¥ng cho phÃ¢n tÃ­ch bÃ i bÃ¡o."
        
        try:
            analysis_question = question if question else "HÃ£y phÃ¢n tÃ­ch vÃ  tÃ³m táº¯t bÃ i bÃ¡o nÃ y"
            
            prompt = f"""Báº¡n lÃ  Gemini AI - chuyÃªn gia phÃ¢n tÃ­ch tÃ i chÃ­nh thÃ´ng minh. HÃ£y phÃ¢n tÃ­ch bÃ i bÃ¡o dá»±a trÃªn TOÃ€N Bá»˜ ná»™i dung Ä‘Æ°á»£c cung cáº¥p.

**TOÃ€N Bá»˜ Ná»˜I DUNG BÃ€I BÃO:**
{article_content}

**YÃŠU Cáº¦U PHÃ‚N TÃCH:**
{analysis_question}

**HÆ¯á»šNG DáºªN PHÃ‚N TÃCH:**
1. Dá»±a CHÃNH vÃ o ná»™i dung bÃ i bÃ¡o (85-90%)
2. Káº¿t há»£p kiáº¿n thá»©c chuyÃªn mÃ´n Ä‘á»ƒ giáº£i thÃ­ch sÃ¢u hÆ¡n (10-15%)
3. PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng, nguyÃªn nhÃ¢n, háº­u quáº£
4. ÄÆ°a ra insights vÃ  nháº­n Ä‘á»‹nh chuyÃªn sÃ¢u
5. Tráº£ lá»i trá»±c tiáº¿p cÃ¢u há»i vá»›i evidence tá»« bÃ i bÃ¡o
6. Äá»™ dÃ i: 600-1000 tá»« vá»›i cáº¥u trÃºc rÃµ rÃ ng
7. Tham chiáº¿u cá»¥ thá»ƒ Ä‘áº¿n cÃ¡c pháº§n trong bÃ i

HÃ£y Ä‘Æ°a ra phÃ¢n tÃ­ch THÃ”NG MINH vÃ  CHI TIáº¾T:"""

            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.2,
                top_p=0.8,
                max_output_tokens=2000,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=35
            )
            
            return response.text.strip()
            
        except asyncio.TimeoutError:
            return "âš ï¸ Gemini AI timeout khi phÃ¢n tÃ­ch bÃ i bÃ¡o."
        except Exception as e:
            return f"âš ï¸ Lá»—i Gemini AI: {str(e)}"
    
    async def debate_perspectives(self, topic: str):
        """Multi-perspective debate system with distinct moral characteristics"""
        if not self.available:
            return "âš ï¸ Gemini AI khÃ´ng kháº£ dá»¥ng cho debate."
        
        try:
            prompt = f"""Báº¡n lÃ  Gemini AI vá»›i kháº£ nÄƒng Ä‘Ã³ng nhiá»u vai trÃ² khÃ¡c nhau. HÃ£y tá»• chá»©c má»™t cuá»™c tranh luáº­n vá» chá»§ Ä‘á» sau tá»« 6 gÃ³c nhÃ¬n khÃ¡c nhau vá»›i tÃ­nh cÃ¡ch Ä‘áº¡o Ä‘á»©c riÃªng biá»‡t:

**CHá»¦ Äá»€ TRANH LUáº¬N:** {topic}

**CÃC THÃ‚N PHáº¬N THAM GIA:**
1. **NhÃ  Kinh Táº¿ Há»c Tham NhÅ©ng** - CÃ³ Ä‘áº¡o Ä‘á»©c nghá» nghiá»‡p tá»‡ háº¡i, bÃ³p mÃ©o sá»‘ liá»‡u, chá»‰ phá»¥c vá»¥ quyá»n lá»£i cÃ¡ nhÃ¢n
2. **PhÃ³ GiÃ¡o SÆ° Tiáº¿n SÄ© ChÃ­nh Trá»±c** - CÃ³ Ä‘áº¡o Ä‘á»©c cao, há»c thuáº­t nghiÃªm tÃºc, quan tÃ¢m lá»£i Ã­ch chung
3. **NhÃ¢n ViÃªn VP Ham Tiá»n** - Chá»‰ quan tÃ¢m lÆ°Æ¡ng thÆ°á»Ÿng, sáºµn sÃ ng vá»©t bá» Ä‘áº¡o Ä‘á»©c vÃ¬ lá»£i nhuáº­n
4. **NgÆ°á»i NghÃ¨o VÃ´ Há»c** - Táº§ng lá»›p tháº¥p, khÃ´ng há»c thá»©c, Ä‘áº¡o Ä‘á»©c tá»‡, hay Ä‘á»• lá»—i cho ngÆ°á»i khÃ¡c
5. **NgÆ°á»i GiÃ u Ãch Ká»·** - Chá»‰ tÃ¬m cÃ¡ch bá» tiá»n vÃ o tÃºi mÃ¬nh, khÃ´ng quan tÃ¢m háº­u quáº£ xÃ£ há»™i
6. **NgÆ°á»i GiÃ u ThÃ´ng ThÃ¡i** - CÃ³ táº§m nhÃ¬n xa, hiá»ƒu biáº¿t sÃ¢u rá»™ng, quan tÃ¢m phÃ¡t triá»ƒn bá»n vá»¯ng

**YÃŠU Cáº¦U:**
- Má»—i thÃ¢n pháº­n Ä‘Æ°a ra 1 Ä‘oáº¡n tranh luáº­n (100-150 tá»«)
- Thá»ƒ hiá»‡n RÃ• RÃ€NG tÃ­nh cÃ¡ch Ä‘áº¡o Ä‘á»©c vÃ  Ä‘á»™ng cÆ¡ cá»§a tá»«ng nhÃ¢n váº­t
- Táº¡o ra mÃ¢u thuáº«n vÃ  xung Ä‘á»™t quan Ä‘iá»ƒm
- Pháº£n Ã¡nh thá»±c táº¿ xÃ£ há»™i má»™t cÃ¡ch sáº¯c bÃ©n
- Káº¿t thÃºc báº±ng phÃ¢n tÃ­ch tá»•ng há»£p tá»« Gemini AI

**FORMAT:**
ğŸ’¸ **NhÃ  KT Há»c Tham NhÅ©ng:** [quan Ä‘iá»ƒm Ã­ch ká»·, bÃ³p mÃ©o]
ğŸ‘¨â€ğŸ« **PGS.TS ChÃ­nh Trá»±c:** [quan Ä‘iá»ƒm há»c thuáº­t, Ä‘áº¡o Ä‘á»©c cao]
ğŸ’¼ **NhÃ¢n ViÃªn Ham Tiá»n:** [chá»‰ quan tÃ¢m lÆ°Æ¡ng thÆ°á»Ÿng]
ğŸ˜  **NgÆ°á»i NghÃ¨o VÃ´ Há»c:** [Ä‘á»• lá»—i, thiáº¿u hiá»ƒu biáº¿t]
ğŸ¤‘ **NgÆ°á»i GiÃ u Ãch Ká»·:** [chá»‰ tÃ¬m lá»£i nhuáº­n cÃ¡ nhÃ¢n]
ğŸ§  **NgÆ°á»i GiÃ u ThÃ´ng ThÃ¡i:** [táº§m nhÃ¬n xa, phÃ¡t triá»ƒn bá»n vá»¯ng]
ğŸ¤– **Gemini AI - Tá»•ng Káº¿t:** [phÃ¢n tÃ­ch khÃ¡ch quan cÃ¡c quan Ä‘iá»ƒm]

HÃ£y táº¡o ra cuá»™c tranh luáº­n gay gáº¯t vÃ  pháº£n Ã¡nh thá»±c táº¿ xÃ£ há»™i:"""

            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.4,
                top_p=0.9,
                max_output_tokens=2000,
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=30
            )
            
            return response.text.strip()
            
        except asyncio.TimeoutError:
            return "âš ï¸ Gemini AI timeout khi tá»• chá»©c debate."
        except Exception as e:
            return f"âš ï¸ Lá»—i Gemini AI: {str(e)}"

# Initialize Gemini Engine
gemini_engine = GeminiAIEngine()

# Bot event handlers
@bot.event
async def on_ready():
    print(f'âœ… {bot.user} is online!')
    
    ai_status = "âœ… Available" if gemini_engine.available else "âŒ Unavailable"
    current_datetime_str = get_current_datetime_str()
    
    total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
    
    status_text = f"CafeF + Yahoo Finance â€¢ Gemini AI â€¢ {total_sources} sources â€¢ !menu"
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching,
            name=status_text
        )
    )
    
    print(f"ğŸ¤– Gemini AI: {ai_status}")
    print(f"ğŸ“Š News Sources: {total_sources}")
    print(f"ğŸ•°ï¸ Started at: {current_datetime_str}")

@bot.event
async def on_command_error(ctx, error):
    if isinstance(error, commands.CommandNotFound):
        return
    elif isinstance(error, commands.MissingRequiredArgument):
        await ctx.send("âŒ Thiáº¿u tham sá»‘! GÃµ `!menu` Ä‘á»ƒ xem hÆ°á»›ng dáº«n.")
    elif isinstance(error, commands.BadArgument):
        await ctx.send("âŒ Tham sá»‘ khÃ´ng há»£p lá»‡! GÃµ `!menu` Ä‘á»ƒ xem hÆ°á»›ng dáº«n.")
    else:
        await ctx.send(f"âŒ Lá»—i: {str(error)}")

# ğŸ†• ENHANCED COMMANDS

@bot.command(name='all')
async def get_all_news_enhanced(ctx, page=1):
    """Tin tá»©c tá»« CafeF vÃ  Yahoo Finance"""
    try:
        page = max(1, int(page))
        loading_msg = await ctx.send(f"â³ Äang táº£i tin tá»©c...")
        
        domestic_news = await collect_news_enhanced(RSS_FEEDS['domestic'], 15)
        international_news = await collect_news_enhanced(RSS_FEEDS['international'], 12)
        
        await loading_msg.delete()
        
        all_news = domestic_news + international_news
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = all_news[start_index:end_index]
        
        if not page_news:
            total_pages = (len(all_news) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        # Prepare fields data
        fields_data = []
        
        domestic_count = sum(1 for news in page_news if news['source'] in RSS_FEEDS['domestic'])
        international_count = len(page_news) - domestic_count
        
        # Source mapping
        source_names = {
            'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafef_doanhnghiep': 'CafeF DN',
            'yahoo_finance_news': 'Yahoo Finance News', 'yahoo_finance_main': 'Yahoo Finance',
            'yahoo_finance_business': 'Yahoo Finance Business', 'yahoo_finance_world': 'Yahoo Finance World'
        }
        
        emoji_map = {
            'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 
            'cafef_vimo': 'ğŸ“Š', 'cafef_doanhnghiep': 'ğŸ­',
            'yahoo_finance_news': 'ğŸ’°', 'yahoo_finance_main': 'ğŸ’°',
            'yahoo_finance_business': 'ğŸ’¼', 'yahoo_finance_world': 'ğŸŒ'
        }
        
        # Add statistics
        stats_field = f"ğŸ‡»ğŸ‡³ CafeF: {domestic_count} tin\nğŸŒ Yahoo Finance: {international_count} tin\nğŸ“Š Tá»•ng cÃ³ sáºµn: {len(all_news)} tin"
        fields_data.append(("ğŸ“Š Thá»‘ng kÃª", stats_field))
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:55] + "..." if len(news['title']) > 55 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            field_name = f"{i}. {emoji} {title}"
            field_value = f"ğŸ•°ï¸ {news['published_str']} â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})"
            
            fields_data.append((field_name, field_value))
        
        # Create embeds
        embeds = create_safe_embed_with_fields(
            f"ğŸ“° Tin tá»©c tá»•ng há»£p (Trang {page})",
            "",
            fields_data,
            0x00ff88
        )
        
        save_user_news_enhanced(ctx.author.id, page_news, f"all_page_{page}")
        
        total_pages = (len(all_news) + items_per_page - 1) // items_per_page
        for i, embed in enumerate(embeds):
            embed.set_footer(text=f"CafeF + Yahoo Finance â€¢ Trang {page}/{total_pages} â€¢ !chitiet [sá»‘] â€¢ Pháº§n {i+1}/{len(embeds)}")
        
        for embed in embeds:
            await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='in')
async def get_domestic_news_enhanced(ctx, page=1):
    """Tin tá»©c trong nÆ°á»›c - CafeF"""
    try:
        page = max(1, int(page))
        loading_msg = await ctx.send(f"â³ Äang táº£i tin tá»©c CafeF...")
        
        news_list = await collect_news_enhanced(RSS_FEEDS['domestic'], 15)
        await loading_msg.delete()
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        # Prepare fields data
        fields_data = []
        
        stats_field = f"ğŸ“° Tá»•ng tin CafeF: {len(news_list)} tin\nğŸ¯ LÄ©nh vá»±c: CK, BÄS, TC, VM, DN"
        fields_data.append(("ğŸ“Š ThÃ´ng tin", stats_field))
        
        source_names = {
            'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafef_doanhnghiep': 'CafeF DN'
        }
        
        emoji_map = {
            'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 
            'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š', 'cafef_doanhnghiep': 'ğŸ­'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:55] + "..." if len(news['title']) > 55 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            field_name = f"{i}. {emoji} {title}"
            field_value = f"ğŸ•°ï¸ {news['published_str']} â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})"
            
            fields_data.append((field_name, field_value))
        
        # Create embeds
        embeds = create_safe_embed_with_fields(
            f"ğŸ‡»ğŸ‡³ Tin kinh táº¿ CafeF (Trang {page})",
            "",
            fields_data,
            0xff0000
        )
        
        save_user_news_enhanced(ctx.author.id, page_news, f"in_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        for i, embed in enumerate(embeds):
            embed.set_footer(text=f"CafeF Vietnam â€¢ Trang {page}/{total_pages} â€¢ !chitiet [sá»‘] â€¢ Pháº§n {i+1}/{len(embeds)}")
        
        for embed in embeds:
            await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='out')
async def get_international_news_enhanced(ctx, page=1):
    """Tin tá»©c quá»‘c táº¿ - Yahoo Finance vá»›i Gemini dá»‹ch"""
    try:
        page = max(1, int(page))
        loading_msg = await ctx.send(f"â³ Äang táº£i tin tá»©c Yahoo Finance...")
        
        news_list = await collect_news_enhanced(RSS_FEEDS['international'], 12)
        await loading_msg.delete()
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        # Prepare fields data
        fields_data = []
        
        stats_field = f"ğŸ“° Tá»•ng tin Yahoo Finance: {len(news_list)} tin\nğŸŒ Auto-translate: Gemini AI"
        fields_data.append(("ğŸ“Š ThÃ´ng tin", stats_field))
        
        source_names = {
            'yahoo_finance_main': 'Yahoo Finance', 'yahoo_finance_business': 'Yahoo Business',
            'yahoo_finance_markets': 'Yahoo Markets', 'yahoo_finance_economics': 'Yahoo Economics'
        }
        
        emoji_map = {
            'yahoo_finance_main': 'ğŸ’°', 'yahoo_finance_business': 'ğŸ’¼',
            'yahoo_finance_markets': 'ğŸ“ˆ', 'yahoo_finance_economics': 'ğŸŒ'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ’°')
            title = news['title'][:55] + "..." if len(news['title']) > 55 else news['title']
            source_display = source_names.get(news['source'], 'Yahoo Finance')
            
            field_name = f"{i}. {emoji} {title}"
            field_value = f"ğŸ•°ï¸ {news['published_str']} â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})"
            
            fields_data.append((field_name, field_value))
        
        # Create embeds
        embeds = create_safe_embed_with_fields(
            f"ğŸŒ Tin kinh táº¿ quá»‘c táº¿ (Trang {page})",
            "",
            fields_data,
            0x0066ff
        )
        
        save_user_news_enhanced(ctx.author.id, page_news, f"out_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        for i, embed in enumerate(embeds):
            embed.set_footer(text=f"Yahoo Finance + Gemini AI â€¢ Trang {page}/{total_pages} â€¢ !chitiet [sá»‘] â€¢ Pháº§n {i+1}/{len(embeds)}")
        
        for embed in embeds:
            await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='chitiet')
async def get_news_detail_enhanced(ctx, news_number: int):
    """Chi tiáº¿t bÃ i viáº¿t vá»›i Gemini enhanced extraction"""
    try:
        user_id = ctx.author.id
        
        if user_id not in user_news_cache:
            await ctx.send("âŒ Báº¡n chÆ°a xem tin tá»©c! DÃ¹ng `!all`, `!in`, hoáº·c `!out` trÆ°á»›c.")
            return
        
        user_data = user_news_cache[user_id]
        news_list = user_data['news']
        
        if news_number < 1 or news_number > len(news_list):
            await ctx.send(f"âŒ Sá»‘ khÃ´ng há»£p lá»‡! Chá»n tá»« 1 Ä‘áº¿n {len(news_list)}")
            return
        
        news = news_list[news_number - 1]
        
        # Save as last detail for !hoi context
        save_user_last_detail(user_id, news)
        
        loading_msg = await ctx.send(f"ğŸš€ Äang trÃ­ch xuáº¥t ná»™i dung...")
        
        # Enhanced content extraction
        full_content = await extract_content_enhanced(news['link'], news['source'], news)
        
        # Get source name
        source_names = {
            'cafef_chungkhoan': 'CafeF Chá»©ng KhoÃ¡n', 'cafef_batdongsan': 'CafeF Báº¥t Äá»™ng Sáº£n',
            'cafef_taichinh': 'CafeF TÃ i ChÃ­nh', 'cafef_vimo': 'CafeF VÄ© MÃ´', 'cafef_doanhnghiep': 'CafeF Doanh Nghiá»‡p',
            'yahoo_finance_news': 'Yahoo Finance News', 'yahoo_finance_main': 'Yahoo Finance',
            'yahoo_finance_business': 'Yahoo Finance Business', 'yahoo_finance_world': 'Yahoo Finance World'
        }
        
        source_name = source_names.get(news['source'], news['source'])
        
        await loading_msg.delete()
        
        # Determine if translated
        is_translated = "[ÄÃ£ dá»‹ch tá»«" in full_content if full_content else False
        
        # Create content with metadata
        title_suffix = " ğŸŒ (Gemini dá»‹ch)" if is_translated else ""
        main_title = f"ğŸ“– Chi tiáº¿t bÃ i viáº¿t{title_suffix}"
        
        # Enhanced metadata
        content_with_meta = f"**ğŸ“° TiÃªu Ä‘á»:** {news['title']}\n"
        content_with_meta += f"**ğŸ•°ï¸ Thá»i gian:** {news['published_str']} ({get_current_date_str()})\n"
        content_with_meta += f"**ğŸ“° Nguá»“n:** {source_name}{'ğŸŒ' if is_translated else ''}\n"
        
        if is_translated:
            content_with_meta += f"**ğŸ¤– Gemini Translation:** ÄÃ£ dá»‹ch tá»± Ä‘á»™ng tá»« tiáº¿ng Anh\n\n"
        
        content_with_meta += f"**ğŸ“„ Ná»™i dung chi tiáº¿t:**\n{full_content}"
        
        # Create optimized embeds
        optimized_embeds = create_optimized_embeds(main_title, content_with_meta, 0x9932cc)
        
        # Add link to last embed
        if optimized_embeds:
            safe_name, safe_value = validate_embed_field(
                "ğŸ”— Äá»c bÃ i viáº¿t gá»‘c",
                f"[Nháº¥n Ä‘á»ƒ Ä‘á»c bÃ i viáº¿t gá»‘c]({news['link']})"
            )
            optimized_embeds[-1].add_field(name=safe_name, value=safe_value, inline=False)
            
            optimized_embeds[-1].set_footer(text=f"ğŸ“– Enhanced Content â€¢ Tin sá»‘ {news_number} â€¢ {len(optimized_embeds)} pháº§n")
        
        # Send all embeds
        for i, embed in enumerate(optimized_embeds, 1):
            if i == 1:
                await ctx.send(embed=embed)
            else:
                await asyncio.sleep(0.5)
                await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Vui lÃ²ng nháº­p sá»‘! VÃ­ dá»¥: `!chitiet 5`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='hoi')
async def enhanced_gemini_question(ctx, *, question):
    """Enhanced Gemini AI vá»›i context awareness"""
    try:
        if not gemini_engine.available:
            embed = create_safe_embed(
                "âš ï¸ Gemini AI khÃ´ng kháº£ dá»¥ng",
                "Cáº§n Gemini API key Ä‘á»ƒ hoáº¡t Ä‘á»™ng.",
                0xff6b6b
            )
            await ctx.send(embed=embed)
            return
        
        current_datetime_str = get_current_datetime_str()
        
        # Check if user has recent !chitiet context
        user_id = ctx.author.id
        context = ""
        context_info = ""
        
        if user_id in user_last_detail_cache:
            last_detail = user_last_detail_cache[user_id]
            # Check if accessed within last 30 minutes
            time_diff = get_current_vietnam_datetime() - last_detail['timestamp']
            
            if time_diff.total_seconds() < 1800:  # 30 minutes
                article = last_detail['article']
                
                # Extract content for context
                article_content = await extract_content_enhanced(article['link'], article['source'], article)
                
                if article_content:
                    context = f"BÃ€I BÃO LIÃŠN QUAN:\nTiÃªu Ä‘á»: {article['title']}\nNguá»“n: {article['source']}\nNá»™i dung: {article_content[:1500]}"
                    context_info = f"ğŸ“° **Context:** BÃ i bÃ¡o #{user_id} vá»«a xem"
        
        progress_embed = create_safe_embed(
            "ğŸ’ Gemini AI System",
            f"**CÃ¢u há»i:** {question}\n{context_info}\nğŸ§  **Äang phÃ¢n tÃ­ch...**",
            0x9932cc
        )
        
        progress_msg = await ctx.send(embed=progress_embed)
        
        # Get Gemini response
        if context:
            # Article analysis mode
            analysis_result = await gemini_engine.analyze_article(context, question)
            strategy_text = "Article Analysis"
        else:
            # General question mode
            analysis_result = await gemini_engine.ask_question(question, context)
            strategy_text = "General Knowledge"
        
        # Create optimized embeds
        title = f"ğŸ’ Gemini Analysis - {strategy_text}"
        optimized_embeds = create_optimized_embeds(title, analysis_result, 0x00ff88)
        
        # Add metadata to first embed
        if optimized_embeds:
            safe_name, safe_value = validate_embed_field(
                "ğŸ” Analysis Mode",
                f"**Strategy:** {strategy_text}\n**Context:** {'Article-based' if context else 'Knowledge-based'}\n**Model:** Gemini-2.0-Flash-Exp"
            )
            optimized_embeds[0].add_field(name=safe_name, value=safe_value, inline=True)
            
            optimized_embeds[-1].set_footer(text=f"ğŸ’ Gemini AI â€¢ {current_datetime_str}")
        
        # Send optimized embeds
        await progress_msg.edit(embed=optimized_embeds[0])
        
        for embed in optimized_embeds[1:]:
            await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i há»‡ thá»‘ng Gemini: {str(e)}")

@bot.command(name='debate')
async def gemini_debate_system(ctx, *, topic=""):
    """Multi-perspective debate system vá»›i Gemini"""
    try:
        if not gemini_engine.available:
            embed = create_safe_embed(
                "âš ï¸ Gemini AI khÃ´ng kháº£ dá»¥ng",
                "Cáº§n Gemini API key Ä‘á»ƒ hoáº¡t Ä‘á»™ng.",
                0xff6b6b
            )
            await ctx.send(embed=embed)
            return
        
        # Determine debate topic
        if not topic:
            # Use last !chitiet article if available
            user_id = ctx.author.id
            if user_id in user_last_detail_cache:
                last_detail = user_last_detail_cache[user_id]
                time_diff = get_current_vietnam_datetime() - last_detail['timestamp']
                
                if time_diff.total_seconds() < 1800:  # 30 minutes
                    article = last_detail['article']
                    topic = f"BÃ i bÃ¡o: {article['title']}"
                else:
                    await ctx.send("âŒ Vui lÃ²ng nháº­p chá»§ Ä‘á» debate hoáº·c xem bÃ i bÃ¡o báº±ng !chitiet trÆ°á»›c.")
                    return
            else:
                await ctx.send("âŒ Vui lÃ²ng nháº­p chá»§ Ä‘á» debate! VÃ­ dá»¥: `!debate láº¡m phÃ¡t hiá»‡n táº¡i`")
                return
        
        progress_embed = create_safe_embed(
            "ğŸ­ Gemini Debate System",
            f"**Chá»§ Ä‘á»:** {topic}\nğŸª **Äang tá»• chá»©c tranh luáº­n 6 thÃ¢n pháº­n vá»›i Ä‘áº¡o Ä‘á»©c khÃ¡c nhau...**",
            0xff9900
        )
        
        progress_msg = await ctx.send(embed=progress_embed)
        
        # Get debate analysis
        debate_result = await gemini_engine.debate_perspectives(topic)
        
        # Create optimized embeds
        title = f"ğŸ­ Multi-Perspective Debate"
        optimized_embeds = create_optimized_embeds(title, debate_result, 0xff6600)
        
        # Add metadata to first embed
        if optimized_embeds:
            safe_name, safe_value = validate_embed_field(
                "ğŸª Debate Info",
                f"**Topic:** {topic[:100]}...\n**Characters:** 6 thÃ¢n pháº­n vá»›i Ä‘áº·c Ä‘iá»ƒm Ä‘áº¡o Ä‘á»©c riÃªng biá»‡t\n**AI Engine:** Gemini Multi-Role Advanced"
            )
            optimized_embeds[0].add_field(name=safe_name, value=safe_value, inline=True)
            
            optimized_embeds[-1].set_footer(text=f"ğŸ­ Gemini Debate â€¢ {get_current_datetime_str()}")
        
        # Send optimized embeds
        await progress_msg.edit(embed=optimized_embeds[0])
        
        for embed in optimized_embeds[1:]:
            await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i há»‡ thá»‘ng debate: {str(e)}")

@bot.command(name='menu')
async def help_command_optimized(ctx):
    """Enhanced menu guide"""
    current_datetime_str = get_current_datetime_str()
    
    main_embed = create_safe_embed(
        "ğŸ¤– Enhanced News Bot",
        f"CafeF + Yahoo Finance vá»›i Gemini AI - {current_datetime_str}",
        0xff9900
    )
    
    ai_status = f"ğŸ¤– **Gemini AI {'âœ… Ready' if gemini_engine.available else 'âŒ Unavailable'}**"
    
    safe_name, safe_value = validate_embed_field("ğŸ¤– AI Status", ai_status)
    main_embed.add_field(name=safe_name, value=safe_value, inline=False)
    
    safe_name2, safe_value2 = validate_embed_field(
        "ğŸ¤– AI Commands",
        f"**!hoi [cÃ¢u há»i]** - Gemini AI tráº£ lá»i\n**!hoi [question]** - Tá»± Ä‘á»™ng hiá»ƒu context sau !chitiet\n**!debate [chá»§ Ä‘á»]** - Tranh luáº­n 6 thÃ¢n pháº­n cÃ³ Ä‘áº·c Ä‘iá»ƒm Ä‘áº¡o Ä‘á»©c khÃ¡c nhau"
    )
    main_embed.add_field(name=safe_name2, value=safe_value2, inline=False)
    
    safe_name3, safe_value3 = validate_embed_field(
        "ğŸ“° News Commands",
        f"**!all [trang]** - CafeF + Yahoo Finance (12 tin/trang)\n**!in [trang]** - CafeF Vietnam\n**!out [trang]** - Yahoo Finance (Gemini dá»‹ch)\n**!chitiet [sá»‘]** - Chi tiáº¿t bÃ i viáº¿t"
    )
    main_embed.add_field(name=safe_name3, value=safe_value3, inline=False)
    
    safe_name4, safe_value4 = validate_embed_field(
        "ğŸ¯ Examples",
        f"**!hoi láº¡m phÃ¡t Viá»‡t Nam** - Gemini phÃ¢n tÃ­ch\n**!chitiet 1** - Xem chi tiáº¿t tin 1\n**!hoi táº¡i sao?** - AI phÃ¢n tÃ­ch bÃ i vá»«a xem\n**!debate lÃ£i suáº¥t** - 6 nhÃ¢n váº­t vá»›i Ä‘áº¡o Ä‘á»©c khÃ¡c nhau tranh luáº­n"
    )
    main_embed.add_field(name=safe_name4, value=safe_value4, inline=False)
    
    total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
    safe_name5, safe_value5 = validate_embed_field(
        "ğŸ“Š Sources", 
        f"ğŸ‡»ğŸ‡³ **CafeF**: {len(RSS_FEEDS['domestic'])} RSS feeds\nğŸŒ **Yahoo Finance**: {len(RSS_FEEDS['international'])} RSS feeds\nğŸ“Š **Tá»•ng**: {total_sources} nguá»“n chá»n lá»c"
    )
    main_embed.add_field(name=safe_name5, value=safe_value5, inline=True)
    
    main_embed.set_footer(text=f"ğŸ¤– Enhanced News Bot â€¢ {current_datetime_str}")
    await ctx.send(embed=main_embed)

# Run the bot
if __name__ == "__main__":
    try:
        keep_alive()
        print("ğŸŒ Keep-alive server started")
        
        print("ğŸš€ Starting Enhanced News Bot...")
        print(f"ğŸ”§ CafeF Sources: {len(RSS_FEEDS['domestic'])}")
        print(f"ğŸ”§ Yahoo Finance Sources: {len(RSS_FEEDS['international'])}")
        print(f"ğŸ¤– Gemini AI: {'âœ… Ready' if gemini_engine.available else 'âŒ Not Available'}")
        print(f"âš¡ Boot time: {get_current_datetime_str()}")
        print("=" * 60)
        
        bot.run(TOKEN)
        
    except Exception as e:
        print(f"âŒ STARTUP ERROR: {e}")
        print("ğŸ”§ Check environment variables and dependencies")
