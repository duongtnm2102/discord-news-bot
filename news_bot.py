import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime
import time
import calendar
from urllib.parse import urljoin
import html
import chardet
import pytz
from keep_alive import keep_alive

# ğŸ†• THÃŠM CÃC THá»¬ VIá»†N Máº NH Máº¼ CHO TRÃCH XUáº¤T Ná»˜I DUNG
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
    print("âœ… Trafilatura Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p - TrÃ­ch xuáº¥t ná»™i dung cáº£i tiáº¿n!")
except ImportError:
    TRAFILATURA_AVAILABLE = False
    print("âš ï¸ Trafilatura chÆ°a cÃ i Ä‘áº·t. Cháº¡y: pip install trafilatura")

try:
    import newspaper
    from newspaper import Article
    NEWSPAPER_AVAILABLE = True
    print("âœ… Newspaper3k Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p - Fallback extraction!")
except ImportError:
    NEWSPAPER_AVAILABLE = False
    print("âš ï¸ Newspaper3k chÆ°a cÃ i Ä‘áº·t. Cháº¡y: pip install newspaper3k")

# Cáº¥u hÃ¬nh bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# ğŸ”’ Báº¢O Máº¬T: Láº¥y token tá»« environment variable
TOKEN = os.getenv('DISCORD_TOKEN')

if not TOKEN:
    print("âŒ Cáº¢NH BÃO: KhÃ´ng tÃ¬m tháº¥y DISCORD_TOKEN trong environment variables!")
    print("ğŸ”§ Vui lÃ²ng thÃªm DISCORD_TOKEN vÃ o Render Environment Variables")
    exit(1)

# ğŸ‡»ğŸ‡³ TIMEZONE VIá»†T NAM - ÄÃƒ Sá»¬A Lá»–I MÃšI GIá»œ
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# LÆ°u trá»¯ tin tá»©c theo tá»«ng user
user_news_cache = {}

# RSS feeds Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm tra vÃ  xÃ¡c nháº­n hoáº¡t Ä‘á»™ng
RSS_FEEDS = {
    # === KINH Táº¾ TRONG NÆ¯á»šC - ÄÃƒ KIá»‚M TRA ===
    'domestic': {
        # CafeF - RSS chÃ­nh hoáº¡t Ä‘á»™ng tá»‘t
        'cafef_main': 'https://cafef.vn/index.rss',
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'cafef_batdongsan': 'https://cafef.vn/bat-dong-san.rss',
        'cafef_taichinh': 'https://cafef.vn/tai-chinh-ngan-hang.rss',
        'cafef_vimo': 'https://cafef.vn/vi-mo-dau-tu.rss',
        
        # CafeBiz - RSS tá»•ng há»£p
        'cafebiz_main': 'https://cafebiz.vn/index.rss',
        
        # BÃ¡o Äáº§u tÆ° - RSS hoáº¡t Ä‘á»™ng
        'baodautu_main': 'https://baodautu.vn/rss.xml',
        
        # VnEconomy - RSS tin tá»©c chÃ­nh
        'vneconomy_main': 'https://vneconomy.vn/rss/home.rss',
        'vneconomy_chungkhoan': 'https://vneconomy.vn/rss/chung-khoan.rss',
        
        # VnExpress Kinh doanh 
        'vnexpress_kinhdoanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'vnexpress_chungkhoan': 'https://vnexpress.net/rss/kinh-doanh/chung-khoan.rss',
        
        # Thanh NiÃªn - RSS kinh táº¿
        'thanhnien_kinhtevimo': 'https://thanhnien.vn/rss/kinh-te/vi-mo.rss',
        'thanhnien_chungkhoan': 'https://thanhnien.vn/rss/kinh-te/chung-khoan.rss',
        
        # NhÃ¢n DÃ¢n - RSS tÃ i chÃ­nh chá»©ng khoÃ¡n
        'nhandanonline_tc': 'https://nhandan.vn/rss/tai-chinh-chung-khoan.rss'
    },
    
    # === KINH Táº¾ QUá»C Táº¾ ===
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg_markets': 'https://feeds.bloomberg.com/markets/news.rss',
        'marketwatch_latest': 'https://feeds.marketwatch.com/marketwatch/realtimeheadlines/',
        'forbes_money': 'https://www.forbes.com/money/feed/',
        'financial_times': 'https://www.ft.com/rss/home',
        'business_insider': 'https://feeds.businessinsider.com/custom/all',
        'the_economist': 'https://www.economist.com/rss'
    }
}

def convert_utc_to_vietnam_time(utc_time_tuple):
    """ğŸ”§ Sá»¬A Lá»–I MÃšI GIá»œ: Chuyá»ƒn Ä‘á»•i UTC sang giá» Viá»‡t Nam chÃ­nh xÃ¡c"""
    try:
        # Sá»­ dá»¥ng calendar.timegm() thay vÃ¬ time.mktime() Ä‘á»ƒ xá»­ lÃ½ UTC Ä‘Ãºng cÃ¡ch
        utc_timestamp = calendar.timegm(utc_time_tuple)
        
        # Táº¡o datetime object UTC
        utc_dt = datetime.fromtimestamp(utc_timestamp, tz=UTC_TIMEZONE)
        
        # Chuyá»ƒn sang mÃºi giá» Viá»‡t Nam
        vn_dt = utc_dt.astimezone(VN_TIMEZONE)
        
        return vn_dt
    except Exception as e:
        print(f"âš ï¸ Lá»—i chuyá»ƒn Ä‘á»•i mÃºi giá»: {e}")
        # Fallback: sá»­ dá»¥ng thá»i gian hiá»‡n táº¡i
        return datetime.now(VN_TIMEZONE)

@bot.event
async def on_ready():
    print(f'âœ… {bot.user} Ä‘Ã£ online!')
    print(f'ğŸ“Š Káº¿t ná»‘i vá»›i {len(bot.guilds)} server(s)')
    total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
    print(f'ğŸ“° Sáºµn sÃ ng cung cáº¥p tin tá»« {total_sources} nguá»“n ÄÃƒ KIá»‚M TRA')
    print(f'ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {len(RSS_FEEDS["domestic"])} nguá»“n')
    print(f'ğŸŒ Quá»‘c táº¿: {len(RSS_FEEDS["international"])} nguá»“n')
    print('ğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, VÄ© mÃ´, Báº¥t Ä‘á»™ng sáº£n')
    
    # Kiá»ƒm tra thÆ° viá»‡n Ä‘Ã£ cÃ i Ä‘áº·t
    if TRAFILATURA_AVAILABLE:
        print('ğŸš€ Trafilatura: TrÃ­ch xuáº¥t ná»™i dung cáº£i tiáº¿n (94.5% Ä‘á»™ chÃ­nh xÃ¡c)')
    if NEWSPAPER_AVAILABLE:
        print('ğŸ“° Newspaper3k: Fallback extraction cho tin tá»©c')
    
    print('ğŸ•°ï¸ MÃºi giá»: ÄÃ£ sá»­a lá»—i - Hiá»ƒn thá»‹ chÃ­nh xÃ¡c giá» Viá»‡t Nam')
    print('ğŸ¯ GÃµ !menu Ä‘á»ƒ xem hÆ°á»›ng dáº«n')
    
    # Set bot status
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching, 
            name="tin tá»©c VN chuáº©n giá» | !menu"
        )
    )

async def fetch_content_with_trafilatura(url):
    """ğŸ†• TRÃCH XUáº¤T Ná»˜I DUNG Báº°NG TRAFILATURA - Tá»T NHáº¤T 2024"""
    try:
        if not TRAFILATURA_AVAILABLE:
            return None
        
        print(f"ğŸš€ Sá»­ dá»¥ng Trafilatura cho: {url}")
        
        # Táº£i ná»™i dung
        downloaded = trafilatura.fetch_url(url)
        if not downloaded:
            return None
        
        # TrÃ­ch xuáº¥t vá»›i metadata
        result = trafilatura.bare_extraction(
            downloaded,
            include_comments=False,
            include_tables=True,
            include_links=False,
            with_metadata=True
        )
        
        if result and result.get('text'):
            content = result['text']
            
            # Giá»›i háº¡n Ä‘á»™ dÃ i vÃ  lÃ m sáº¡ch
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            return content.strip()
        
        return None
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i Trafilatura cho {url}: {e}")
        return None

async def fetch_content_with_newspaper(url):
    """ğŸ“° TRÃCH XUáº¤T Báº°NG NEWSPAPER3K - FALLBACK"""
    try:
        if not NEWSPAPER_AVAILABLE:
            return None
        
        print(f"ğŸ“° Sá»­ dá»¥ng Newspaper3k cho: {url}")
        
        # Táº¡o article object
        article = Article(url)
        article.download()
        article.parse()
        
        if article.text:
            content = article.text
            
            # Giá»›i háº¡n Ä‘á»™ dÃ i
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            return content.strip()
        
        return None
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i Newspaper3k cho {url}: {e}")
        return None

async def fetch_content_legacy(url):
    """ğŸ”„ PHÆ¯Æ NG PHÃP CÅ¨ - CUá»I CÃ™NG FALLBACK"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        response = requests.get(url, headers=headers, timeout=8, stream=True)
        response.raise_for_status()
        
        # Xá»­ lÃ½ encoding
        raw_content = response.content
        detected = chardet.detect(raw_content)
        encoding = detected['encoding'] or 'utf-8'
        
        try:
            content = raw_content.decode(encoding)
        except:
            content = raw_content.decode('utf-8', errors='ignore')
        
        # Loáº¡i bá» HTML tags cÆ¡ báº£n
        clean_content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
        clean_content = re.sub(r'<style[^>]*>.*?</style>', '', clean_content, flags=re.DOTALL | re.IGNORECASE)
        clean_content = re.sub(r'<[^>]+>', ' ', clean_content)
        clean_content = html.unescape(clean_content)
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
        
        # Láº¥y pháº§n Ä‘áº§u cÃ³ Ã½ nghÄ©a
        sentences = clean_content.split('. ')
        meaningful_content = []
        
        for sentence in sentences[:8]:
            if len(sentence.strip()) > 20:
                meaningful_content.append(sentence.strip())
                
        result = '. '.join(meaningful_content)
        
        if len(result) > 1800:
            result = result[:1800] + "..."
            
        return result if result else "KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« bÃ i viáº¿t nÃ y."
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i legacy extraction tá»« {url}: {e}")
        return f"KhÃ´ng thá»ƒ láº¥y ná»™i dung chi tiáº¿t. Lá»—i: {str(e)}"

async def fetch_full_content_improved(url):
    """ğŸ†• TRÃCH XUáº¤T Ná»˜I DUNG Cáº¢I TIáº¾N - Sá»¬ Dá»¤NG 3 PHÆ¯Æ NG PHÃP"""
    # Thá»­ phÆ°Æ¡ng phÃ¡p 1: Trafilatura (tá»‘t nháº¥t)
    content = await fetch_content_with_trafilatura(url)
    if content and len(content) > 50:
        print("âœ… ThÃ nh cÃ´ng vá»›i Trafilatura")
        return content
    
    # Thá»­ phÆ°Æ¡ng phÃ¡p 2: Newspaper3k (fallback)
    content = await fetch_content_with_newspaper(url)
    if content and len(content) > 50:
        print("âœ… ThÃ nh cÃ´ng vá»›i Newspaper3k")
        return content
    
    # PhÆ°Æ¡ng phÃ¡p 3: Legacy method (cuá»‘i cÃ¹ng)
    content = await fetch_content_legacy(url)
    print("âš ï¸ Sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p legacy")
    return content

async def collect_news_from_sources(sources_dict, limit_per_source=8):
    """Thu tháº­p tin tá»©c vá»›i xá»­ lÃ½ mÃºi giá» chÃ­nh xÃ¡c"""
    all_news = []
    
    for source_name, rss_url in sources_dict.items():
        try:
            print(f"ğŸ”„ Äang láº¥y tin tá»« {source_name}...")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/rss+xml, application/xml, text/xml',
                'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8'
            }
            
            try:
                response = requests.get(rss_url, headers=headers, timeout=10)
                response.raise_for_status()
                feed = feedparser.parse(response.content)
            except Exception as req_error:
                print(f"âš ï¸ Lá»—i request tá»« {source_name}: {req_error}")
                feed = feedparser.parse(rss_url)
            
            if not hasattr(feed, 'entries') or len(feed.entries) == 0:
                print(f"âš ï¸ KhÃ´ng cÃ³ tin tá»« {source_name}")
                continue
                
            entries_processed = 0
            for entry in feed.entries[:limit_per_source]:
                try:
                    # ğŸ”§ Xá»¬ LÃ THá»œI GIAN CHÃNH XÃC
                    vn_time = datetime.now(VN_TIMEZONE)  # Default fallback
                    
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.published_parsed)
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.updated_parsed)
                    
                    # Láº¥y mÃ´ táº£
                    description = ""
                    if hasattr(entry, 'summary'):
                        description = entry.summary[:500] + "..." if len(entry.summary) > 500 else entry.summary
                    elif hasattr(entry, 'description'):
                        description = entry.description[:500] + "..." if len(entry.description) > 500 else entry.description
                    
                    if not hasattr(entry, 'title') or not hasattr(entry, 'link'):
                        continue
                    
                    title = html.unescape(entry.title.strip())
                    
                    news_item = {
                        'title': title,
                        'link': entry.link,
                        'source': source_name,
                        'published': vn_time,
                        'published_str': vn_time.strftime("%H:%M %d/%m"),
                        'description': html.unescape(description) if description else ""
                    }
                    all_news.append(news_item)
                    entries_processed += 1
                    
                except Exception as entry_error:
                    print(f"âš ï¸ Lá»—i xá»­ lÃ½ tin tá»« {source_name}: {entry_error}")
                    continue
                    
            print(f"âœ… Láº¥y Ä‘Æ°á»£c {entries_processed} tin tá»« {source_name}")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi láº¥y tin tá»« {source_name}: {e}")
            continue
    
    print(f"ğŸ“Š Tá»•ng cá»™ng láº¥y Ä‘Æ°á»£c {len(all_news)} tin tá»« táº¥t cáº£ nguá»“n")
    
    # Loáº¡i bá» tin trÃ¹ng láº·p
    unique_news = remove_duplicate_news(all_news)
    print(f"ğŸ”„ Sau khi loáº¡i trÃ¹ng cÃ²n {len(unique_news)} tin")
    
    # Sáº¯p xáº¿p theo thá»i gian má»›i nháº¥t
    unique_news.sort(key=lambda x: x['published'], reverse=True)
    return unique_news

def remove_duplicate_news(news_list):
    """Loáº¡i bá» tin tá»©c trÃ¹ng láº·p"""
    seen_links = set()
    seen_titles = set()
    unique_news = []
    
    for news in news_list:
        normalized_title = normalize_title(news['title'])
        
        is_duplicate = False
        
        if news['link'] in seen_links:
            is_duplicate = True
        else:
            for existing_title in seen_titles:
                similarity = calculate_title_similarity(normalized_title, existing_title)
                if similarity > 0.75:
                    is_duplicate = True
                    break
        
        if not is_duplicate:
            seen_links.add(news['link'])
            seen_titles.add(normalized_title)
            unique_news.append(news)
    
    return unique_news

def calculate_title_similarity(title1, title2):
    """TÃ­nh Ä‘á»™ tÆ°Æ¡ng tá»± giá»¯a 2 tiÃªu Ä‘á»"""
    words1 = set(title1.split())
    words2 = set(title2.split())
    
    if not words1 or not words2:
        return 0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0

def normalize_title(title):
    """Chuáº©n hÃ³a tiÃªu Ä‘á» Ä‘á»ƒ so sÃ¡nh trÃ¹ng láº·p"""
    import re
    title = title.lower()
    title = re.sub(r'[^\w\s]', '', title)
    title = ' '.join(title.split())
    
    words = title.split()[:10]
    return ' '.join(words)

def save_user_news(user_id, news_list, command_type):
    """LÆ°u tin tá»©c cá»§a user Ä‘á»ƒ sá»­ dá»¥ng cho lá»‡nh !detail"""
    user_news_cache[user_id] = {
        'news': news_list,
        'command': command_type,
        'timestamp': datetime.now(VN_TIMEZONE)
    }

@bot.command(name='all')
async def get_all_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« táº¥t cáº£ nguá»“n vá»›i mÃºi giá» chÃ­nh xÃ¡c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c tá»« táº¥t cáº£ nguá»“n...")
        
        domestic_news = await collect_news_from_sources(RSS_FEEDS['domestic'], 8)
        international_news = await collect_news_from_sources(RSS_FEEDS['international'], 6)
        
        await loading_msg.delete()
        
        all_news = domestic_news + international_news
        all_news.sort(key=lambda x: x['published'], reverse=True)
        
        # PhÃ¢n trang
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = all_news[start_index:end_index]
        
        if not page_news:
            total_pages = (len(all_news) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        # Táº¡o embed vá»›i thÃ´ng tin mÃºi giá»
        embed = discord.Embed(
            title=f"ğŸ“° Tin tá»©c kinh táº¿ tá»•ng há»£p (Trang {page})",
            description=f"ğŸ•°ï¸ Giá» Viá»‡t Nam chÃ­nh xÃ¡c â€¢ ğŸš€ Trafilatura â€¢ ğŸ“° Tá»« {len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])} nguá»“n",
            color=0x00ff88,
            timestamp=ctx.message.created_at
        )
        
        # Emoji map
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸', 'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 
            'marketwatch_latest': 'ğŸ“ˆ', 'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        # Thá»‘ng kÃª
        domestic_count = sum(1 for news in page_news if news['source'] in RSS_FEEDS['domestic'])
        international_count = len(page_news) - domestic_count
        
        embed.add_field(
            name="ğŸ“Š Thá»‘ng kÃª trang nÃ y",
            value=f"ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {domestic_count} tin\nğŸŒ Quá»‘c táº¿: {international_count} tin\nğŸ“Š Tá»•ng cÃ³ sáºµn: {len(all_news)} tin",
            inline=False
        )
        
        # Hiá»ƒn thá»‹ tin tá»©c vá»›i thá»i gian chÃ­nh xÃ¡c
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy CK',
            'vnexpress_kinhdoanh': 'VnExpress KD', 'vnexpress_chungkhoan': 'VnExpress CK',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VM', 'thanhnien_chungkhoan': 'Thanh NiÃªn CK',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TC', 'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters',
            'bloomberg_markets': 'Bloomberg', 'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes',
            'financial_times': 'Financial Times', 'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ•°ï¸ {news['published_str']} (VN) â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"all_page_{page}")
        
        total_pages = (len(all_news) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸš€ Bot cáº£i tiáº¿n â€¢ Trang {page}/{total_pages} â€¢ !all {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Sá»‘ trang khÃ´ng há»£p lá»‡! Sá»­ dá»¥ng: `!all [sá»‘]`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='in')
async def get_domestic_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« cÃ¡c nguá»“n trong nÆ°á»›c vá»›i mÃºi giá» chÃ­nh xÃ¡c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c trong nÆ°á»›c...")
        
        news_list = await collect_news_from_sources(RSS_FEEDS['domestic'], 10)
        
        await loading_msg.delete()
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"ğŸ‡»ğŸ‡³ Tin kinh táº¿ trong nÆ°á»›c (Trang {page})",
            description=f"ğŸ•°ï¸ Giá» Viá»‡t Nam chÃ­nh xÃ¡c â€¢ ğŸš€ Trafilatura â€¢ Tá»« {len(RSS_FEEDS['domestic'])} nguá»“n chuyÃªn ngÃ nh",
            color=0xff0000,
            timestamp=ctx.message.created_at
        )
        
        embed.add_field(
            name="ğŸ“Š ThÃ´ng tin",
            value=f"ğŸ“° Tá»•ng tin cÃ³ sáºµn: {len(news_list)} tin\nğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, Báº¥t Ä‘á»™ng sáº£n, VÄ© mÃ´",
            inline=False
        )
        
        # Hiá»ƒn thá»‹ tin tá»©c trong nÆ°á»›c
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸'
        }
        
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy CK',
            'vnexpress_kinhdoanh': 'VnExpress KD', 'vnexpress_chungkhoan': 'VnExpress CK',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VM', 'thanhnien_chungkhoan': 'Thanh NiÃªn CK',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TC'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ•°ï¸ {news['published_str']} (VN) â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"in_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸš€ Bot cáº£i tiáº¿n â€¢ Trang {page}/{total_pages} â€¢ !in {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='out')
async def get_international_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« cÃ¡c nguá»“n quá»‘c táº¿ vá»›i mÃºi giá» chÃ­nh xÃ¡c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c quá»‘c táº¿...")
        
        news_list = await collect_news_from_sources(RSS_FEEDS['international'], 8)
        
        await loading_msg.delete()
        
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"ğŸŒ Tin kinh táº¿ quá»‘c táº¿ (Trang {page})",
            description=f"ğŸ•°ï¸ Giá» Viá»‡t Nam chÃ­nh xÃ¡c â€¢ ğŸš€ Trafilatura â€¢ Tá»« {len(RSS_FEEDS['international'])} nguá»“n hÃ ng Ä‘áº§u",
            color=0x0066ff,
            timestamp=ctx.message.created_at
        )
        
        embed.add_field(
            name="ğŸ“Š ThÃ´ng tin",
            value=f"ğŸ“° Tá»•ng tin cÃ³ sáºµn: {len(news_list)} tin",
            inline=False
        )
        
        emoji_map = {
            'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 'marketwatch_latest': 'ğŸ“ˆ',
            'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        source_names = {
            'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters', 'bloomberg_markets': 'Bloomberg', 
            'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes', 'financial_times': 'Financial Times', 
            'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸŒ')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ•°ï¸ {news['published_str']} (VN) â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"out_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸš€ Bot cáº£i tiáº¿n â€¢ Trang {page}/{total_pages} â€¢ !out {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='chitiet')
async def get_news_detail(ctx, news_number: int):
    """ğŸ†• XEM CHI TIáº¾T Báº°NG TRAFILATURA + NEWSPAPER3K"""
    try:
        user_id = ctx.author.id
        
        if user_id not in user_news_cache:
            await ctx.send("âŒ Báº¡n chÆ°a xem tin tá»©c nÃ o! HÃ£y dÃ¹ng `!all`, `!in`, hoáº·c `!out` trÆ°á»›c.")
            return
        
        user_data = user_news_cache[user_id]
        news_list = user_data['news']
        
        if news_number < 1 or news_number > len(news_list):
            await ctx.send(f"âŒ Sá»‘ khÃ´ng há»£p lá»‡! Chá»n tá»« 1 Ä‘áº¿n {len(news_list)}")
            return
        
        news = news_list[news_number - 1]
        
        # ThÃ´ng bÃ¡o Ä‘ang táº£i vá»›i thÃ´ng tin cÃ´ng nghá»‡
        if TRAFILATURA_AVAILABLE and NEWSPAPER_AVAILABLE:
            loading_msg = await ctx.send("ğŸš€ Äang trÃ­ch xuáº¥t ná»™i dung báº±ng Trafilatura + Newspaper3k...")
        elif TRAFILATURA_AVAILABLE:
            loading_msg = await ctx.send("ğŸš€ Äang trÃ­ch xuáº¥t ná»™i dung báº±ng Trafilatura...")
        else:
            loading_msg = await ctx.send("â³ Äang trÃ­ch xuáº¥t ná»™i dung...")
        
        # Sá»­ dá»¥ng function cáº£i tiáº¿n
        full_content = await fetch_full_content_improved(news['link'])
        
        await loading_msg.delete()
        
        # Táº¡o embed Ä‘áº¹p hÆ¡n
        embed = discord.Embed(
            title="ğŸ“– Chi tiáº¿t bÃ i viáº¿t",
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        # Emoji cho nguá»“n
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸', 'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 
            'marketwatch_latest': 'ğŸ“ˆ', 'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF Chá»©ng khoÃ¡n', 'cafef_batdongsan': 'CafeF Báº¥t Ä‘á»™ng sáº£n',
            'cafef_taichinh': 'CafeF TÃ i chÃ­nh', 'cafef_vimo': 'CafeF VÄ© mÃ´', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy Chá»©ng khoÃ¡n',
            'vnexpress_kinhdoanh': 'VnExpress Kinh doanh', 'vnexpress_chungkhoan': 'VnExpress Chá»©ng khoÃ¡n',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VÄ© mÃ´', 'thanhnien_chungkhoan': 'Thanh NiÃªn Chá»©ng khoÃ¡n',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TÃ i chÃ­nh', 'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters Business',
            'bloomberg_markets': 'Bloomberg Markets', 'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes Money',
            'financial_times': 'Financial Times', 'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        emoji = emoji_map.get(news['source'], 'ğŸ“°')
        source_display = source_names.get(news['source'], news['source'])
        
        embed.add_field(
            name=f"{emoji} TiÃªu Ä‘á»",
            value=news['title'],
            inline=False
        )
        
        embed.add_field(
            name="ğŸ•°ï¸ Thá»i gian (VN)",
            value=news['published_str'],
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“° Nguá»“n",
            value=source_display,
            inline=True
        )
        
        # Hiá»ƒn thá»‹ ná»™i dung Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
        if len(full_content) > 1000:
            # Chia ná»™i dung thÃ nh 2 pháº§n
            embed.add_field(
                name="ğŸ“„ Ná»™i dung chi tiáº¿t (Pháº§n 1)",
                value=full_content[:1000] + "...",
                inline=False
            )
            
            await ctx.send(embed=embed)
            
            # Táº¡o embed thá»© 2
            embed2 = discord.Embed(
                title=f"ğŸ“– Chi tiáº¿t bÃ i viáº¿t (tiáº¿p theo)",
                color=0x9932cc
            )
            
            embed2.add_field(
                name="ğŸ“„ Ná»™i dung chi tiáº¿t (Pháº§n 2)",
                value=full_content[1000:2000],
                inline=False
            )
            
            embed2.add_field(
                name="ğŸ”— Äá»c bÃ i viáº¿t Ä‘áº§y Ä‘á»§",
                value=f"[Nháº¥n Ä‘á»ƒ Ä‘á»c toÃ n bá»™ bÃ i viáº¿t]({news['link']})",
                inline=False
            )
            
            # ThÃ´ng tin cÃ´ng nghá»‡ sá»­ dá»¥ng
            tech_info = "ğŸš€ Trafilatura" if TRAFILATURA_AVAILABLE else "ğŸ“° Legacy"
            if NEWSPAPER_AVAILABLE:
                tech_info += " + Newspaper3k"
            
            embed2.set_footer(text=f"{tech_info} â€¢ Tá»« lá»‡nh: {user_data['command']} â€¢ Tin sá»‘ {news_number}")
            
            await ctx.send(embed=embed2)
            return
        else:
            embed.add_field(
                name="ğŸ“„ Ná»™i dung chi tiáº¿t",
                value=full_content,
                inline=False
            )
        
        embed.add_field(
            name="ğŸ”— Äá»c bÃ i viáº¿t Ä‘áº§y Ä‘á»§",
            value=f"[Nháº¥n Ä‘á»ƒ Ä‘á»c toÃ n bá»™ bÃ i viáº¿t]({news['link']})",
            inline=False
        )
        
        # ThÃ´ng tin cÃ´ng nghá»‡ sá»­ dá»¥ng
        tech_info = "ğŸš€ Trafilatura" if TRAFILATURA_AVAILABLE else "ğŸ“° Legacy"
        if NEWSPAPER_AVAILABLE:
            tech_info += " + Newspaper3k"
        
        embed.set_footer(text=f"{tech_info} â€¢ Tá»« lá»‡nh: {user_data['command']} â€¢ Tin sá»‘ {news_number} â€¢ !menu Ä‘á»ƒ xem thÃªm lá»‡nh")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Vui lÃ²ng nháº­p sá»‘! VÃ­ dá»¥: `!chitiet 5`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

# Alias cho lá»‡nh chitiet
@bot.command(name='cuthe')
async def get_news_detail_alias(ctx, news_number: int):
    """Alias cho lá»‡nh !chitiet"""
    await get_news_detail(ctx, news_number)

@bot.command(name='menu')
async def help_command(ctx):
    """Hiá»ƒn thá»‹ menu lá»‡nh - ÄÃƒ Cáº¬P NHáº¬T"""
    embed = discord.Embed(
        title="ğŸ¤–ğŸš€ Menu News Bot - PhiÃªn báº£n cáº£i tiáº¿n 2024",
        description="Bot tin tá»©c kinh táº¿ vá»›i cÃ´ng nghá»‡ trÃ­ch xuáº¥t tiÃªn tiáº¿n",
        color=0xff9900
    )
    
    embed.add_field(
        name="ğŸ“° Lá»‡nh chÃ­nh",
        value="""
**!all [trang]** - Tin tá»« táº¥t cáº£ nguá»“n (12 tin/trang)
**!in [trang]** - Tin trong nÆ°á»›c (12 tin/trang)  
**!out [trang]** - Tin quá»‘c táº¿ (12 tin/trang)
**!chitiet [sá»‘]** - Xem ná»™i dung chi tiáº¿t (cáº£i tiáº¿n)
        """,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ‡»ğŸ‡³ Nguá»“n trong nÆ°á»›c (9 nguá»“n)",
        value="CafeF, CafeBiz, BÃ¡o Äáº§u tÆ°, VnEconomy, VnExpress KD, Thanh NiÃªn, NhÃ¢n DÃ¢n",
        inline=True
    )
    
    embed.add_field(
        name="ğŸŒ Nguá»“n quá»‘c táº¿ (8 nguá»“n)",
        value="Yahoo Finance, Reuters, Bloomberg, MarketWatch, Forbes, Financial Times, Business Insider, The Economist",
        inline=True
    )
    
    embed.add_field(
        name="ğŸš€ Cáº£i tiáº¿n má»›i 2024",
        value=f"""
**ğŸ•°ï¸ MÃºi giá» chÃ­nh xÃ¡c** - Hiá»ƒn thá»‹ Ä‘Ãºng giá» Viá»‡t Nam
**ğŸš€ Trafilatura** - TrÃ­ch xuáº¥t ná»™i dung 94.5% Ä‘á»™ chÃ­nh xÃ¡c{' âœ…' if TRAFILATURA_AVAILABLE else ' âŒ ChÆ°a cÃ i'}
**ğŸ“° Newspaper3k** - Fallback extraction cho tin tá»©c{' âœ…' if NEWSPAPER_AVAILABLE else ' âŒ ChÆ°a cÃ i'}
**ğŸ”’ Báº£o máº­t token** - Sá»­ dá»¥ng Environment Variables
        """,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ“‹ HÆ°á»›ng dáº«n sá»­ dá»¥ng",
        value="""
1ï¸âƒ£ GÃµ **!all** Ä‘á»ƒ xem tin má»›i nháº¥t (giá» VN chÃ­nh xÃ¡c)
2ï¸âƒ£ Chá»n sá»‘ tin muá»‘n Ä‘á»c chi tiáº¿t (1-12)
3ï¸âƒ£ GÃµ **!chitiet [sá»‘]** Ä‘á»ƒ xem ná»™i dung Ä‘áº§y Ä‘á»§ (cáº£i tiáº¿n)
4ï¸âƒ£ DÃ¹ng **!all 2**, **!all 3** Ä‘á»ƒ xem trang tiáº¿p theo
        """,
        inline=False
    )
    
    if not TRAFILATURA_AVAILABLE or not NEWSPAPER_AVAILABLE:
        embed.add_field(
            name="âš™ï¸ CÃ i Ä‘áº·t thÆ° viá»‡n bá»• sung",
            value="""
Äá»ƒ cÃ³ tráº£i nghiá»‡m tá»‘t nháº¥t, cÃ i Ä‘áº·t:
```bash
pip install trafilatura newspaper3k pytz
```
            """,
            inline=False
        )
    
    embed.set_footer(text="ğŸš€ Bot cáº£i tiáº¿n vá»›i Trafilatura + Newspaper3k â€¢ MÃºi giá» VN chÃ­nh xÃ¡c â€¢ Token báº£o máº­t")
    await ctx.send(embed=embed)

# Cháº¡y bot vá»›i error handling tá»‘t hÆ¡n
if __name__ == "__main__":
    try:
        print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng News Bot cáº£i tiáº¿n...")
        # Khá»Ÿi Ä‘á»™ng web server Ä‘á»ƒ keep alive
        keep_alive()
        print("ğŸ”‘ Äang kiá»ƒm tra token tá»« Environment Variables...")
        
        if TOKEN:
            print("âœ… Token Ä‘Ã£ Ä‘Æ°á»£c táº£i tá»« Environment Variables")
        
        total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
        print(f"ğŸ“Š ÄÃ£ load {total_sources} nguá»“n RSS ÄÃƒ KIá»‚M TRA")
        print(f"ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {len(RSS_FEEDS['domestic'])} nguá»“n")
        print(f"ğŸŒ Quá»‘c táº¿: {len(RSS_FEEDS['international'])} nguá»“n")
        print("ğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, VÄ© mÃ´, Báº¥t Ä‘á»™ng sáº£n")
        print("ğŸ•°ï¸ MÃºi giá»: ÄÃ£ sá»­a lá»—i - Hiá»ƒn thá»‹ chÃ­nh xÃ¡c giá» Viá»‡t Nam")
        
        if TRAFILATURA_AVAILABLE:
            print("ğŸš€ Trafilatura: Sáºµn sÃ ng - TrÃ­ch xuáº¥t ná»™i dung 94.5% Ä‘á»™ chÃ­nh xÃ¡c")
        else:
            print("âš ï¸ Trafilatura: ChÆ°a cÃ i Ä‘áº·t - Sáº½ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p cÅ©")
            
        if NEWSPAPER_AVAILABLE:
            print("ğŸ“° Newspaper3k: Sáºµn sÃ ng - Fallback extraction")
        else:
            print("âš ï¸ Newspaper3k: ChÆ°a cÃ i Ä‘áº·t - Chá»‰ dÃ¹ng Trafilatura")
        
        print("âœ… Bot sáºµn sÃ ng nháº­n lá»‡nh!")
        
        bot.run(TOKEN)
        
    except discord.LoginFailure:
        print("âŒ Lá»—i Ä‘Äƒng nháº­p Discord!")
        print("ğŸ”§ Token cÃ³ thá»ƒ khÃ´ng há»£p lá»‡ hoáº·c Ä‘Ã£ bá»‹ reset")
        print("ğŸ”§ Kiá»ƒm tra DISCORD_TOKEN trong Environment Variables")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi cháº¡y bot: {e}")
        print("ğŸ”§ Kiá»ƒm tra káº¿t ná»‘i internet vÃ  Environment Variables")
        
    input("Nháº¥n Enter Ä‘á»ƒ thoÃ¡t...")
