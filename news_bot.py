import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime
import time
import calendar
from urllib.parse import urljoin
import html
import chardet
import pytz
import json
from keep_alive import keep_alive
import google.generativeai as genai
from enum import Enum

# ğŸ†• MULTI-AI ENGINE ARCHITECTURE
class AIProvider(Enum):
    GEMINI = "gemini"
    DEEPSEEK = "deepseek"
    CLAUDE = "claude"
    GROQ = "groq"  # Fallback

# ğŸ¤– AI CONFIGURATION
AI_CONFIGS = {
    AIProvider.GEMINI: {
        'api_key_env': 'GEMINI_API_KEY',
        'model': 'gemini-2.0-flash-exp',
        'endpoint': 'google_ai_studio',
        'free_tier': 'unlimited',
        'strengths': ['search_integration', 'instruction_following', 'multimodal']
    },
    AIProvider.DEEPSEEK: {
        'api_key_env': 'DEEPSEEK_API_KEY',
        'model': 'deepseek-v3',
        'endpoint': 'https://api.deepseek.com/v1/chat/completions',
        'free_tier': 'generous',
        'strengths': ['reasoning', 'cost_effective', 'math']
    },
    AIProvider.CLAUDE: {
        'api_key_env': 'ANTHROPIC_API_KEY',
        'model': 'claude-3-5-sonnet-20241022',
        'endpoint': 'https://api.anthropic.com/v1/messages',
        'free_tier': 'limited',
        'strengths': ['safety', 'analysis', 'structured_output']
    },
    AIProvider.GROQ: {
        'api_key_env': 'GROQ_API_KEY',
        'model': 'llama-3.3-70b-versatile',
        'endpoint': 'https://api.groq.com/openai/v1/chat/completions',
        'free_tier': 'rate_limited',
        'strengths': ['speed', 'compatibility']
    }
}

# Cáº¥u hÃ¬nh bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# ğŸ”’ Báº¢O Máº¬T: Environment Variables
TOKEN = os.getenv('DISCORD_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')

# AI API Keys
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
GROQ_API_KEY = os.getenv('GROQ_API_KEY')

if not TOKEN:
    print("âŒ DISCORD_TOKEN khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y!")
    exit(1)

# ğŸ‡»ğŸ‡³ TIMEZONE VIá»†T NAM
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

# LÆ°u trá»¯ tin tá»©c theo tá»«ng user
user_news_cache = {}

# ğŸ†• AI ENGINE MANAGER
class AIEngineManager:
    def __init__(self):
        self.primary_ai = None
        self.fallback_ais = []
        self.initialize_engines()
    
    def initialize_engines(self):
        """Khá»Ÿi táº¡o cÃ¡c AI engines theo thá»© tá»± Æ°u tiÃªn"""
        available_engines = []
        
        # Gemini - Highest priority
        if GEMINI_API_KEY:
            try:
                genai.configure(api_key=GEMINI_API_KEY)
                available_engines.append(AIProvider.GEMINI)
                print("âœ… Gemini AI initialized - PRIMARY ENGINE")
            except Exception as e:
                print(f"âš ï¸ Gemini initialization failed: {e}")
        
        # DeepSeek - Second priority  
        if DEEPSEEK_API_KEY:
            available_engines.append(AIProvider.DEEPSEEK)
            print("âœ… DeepSeek AI available - FALLBACK 1")
            
        # Claude - Third priority
        if ANTHROPIC_API_KEY:
            available_engines.append(AIProvider.CLAUDE)
            print("âœ… Claude AI available - FALLBACK 2")
            
        # Groq - Last fallback
        if GROQ_API_KEY:
            available_engines.append(AIProvider.GROQ)
            print("âœ… Groq AI available - LAST FALLBACK")
        
        if available_engines:
            self.primary_ai = available_engines[0]
            self.fallback_ais = available_engines[1:]
            print(f"ğŸš€ Primary AI: {self.primary_ai.value}")
            print(f"ğŸ›¡ï¸ Fallback AIs: {[ai.value for ai in self.fallback_ais]}")
        else:
            print("âŒ No AI engines available!")
            self.primary_ai = None

    async def call_ai_with_fallback(self, prompt, context="", require_specific_data=True):
        """Gá»i AI vá»›i fallback automatic"""
        
        # Thá»­ primary AI trÆ°á»›c
        if self.primary_ai:
            try:
                response = await self._call_specific_ai(self.primary_ai, prompt, context, require_specific_data)
                if self._validate_response(response, require_specific_data):
                    return response, self.primary_ai.value
            except Exception as e:
                print(f"âš ï¸ Primary AI {self.primary_ai.value} failed: {e}")
        
        # Thá»­ fallback AIs
        for fallback_ai in self.fallback_ais:
            try:
                response = await self._call_specific_ai(fallback_ai, prompt, context, require_specific_data)
                if self._validate_response(response, require_specific_data):
                    print(f"âœ… Fallback to {fallback_ai.value} successful")
                    return response, fallback_ai.value
            except Exception as e:
                print(f"âš ï¸ Fallback AI {fallback_ai.value} failed: {e}")
                continue
        
        # Náº¿u táº¥t cáº£ fail
        return "âŒ Táº¥t cáº£ AI engines Ä‘á»u khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng thá»­ láº¡i sau.", "error"

    async def _call_specific_ai(self, ai_provider, prompt, context, require_specific_data):
        """Gá»i AI engine cá»¥ thá»ƒ"""
        
        if ai_provider == AIProvider.GEMINI:
            return await self._call_gemini(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.DEEPSEEK:
            return await self._call_deepseek(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.CLAUDE:
            return await self._call_claude(prompt, context, require_specific_data)
        elif ai_provider == AIProvider.GROQ:
            return await self._call_groq(prompt, context, require_specific_data)
        
        raise Exception(f"Unknown AI provider: {ai_provider}")

    async def _call_gemini(self, prompt, context, require_specific_data):
        """ğŸš€ Gemini 2.5 Flash - RECOMMENDED"""
        
        # Táº¡o prompt siÃªu nghiÃªm kháº¯c cho Gemini
        system_prompt = """Báº N LÃ€ CHUYÃŠN GIA TÃ€I CHÃNH VIá»†T NAM. QUY Táº®C NGHIÃŠM NGáº¶T:

ğŸ”¥ Báº®T BUá»˜C (VI PHáº M = THáº¤T Báº I HOÃ€N TOÃ€N):
1. Sá»¬ Dá»¤NG Sá» LIá»†U Cá»¤ THá»‚ tá»« ná»™i dung tin tá»©c Ä‘Æ°á»£c cung cáº¥p
2. NÃŠU THá»œI GIAN Cá»¤ THá»‚ (ngÃ y/thÃ¡ng/nÄƒm, giá» náº¿u cÃ³)  
3. TRÃCH DáºªN CHÃNH XÃC tá»« nguá»“n tin
4. GIáº¢I THÃCH LÃ DO dá»±a trÃªn sá»± kiá»‡n thá»±c táº¿

âŒ NGHIÃŠM Cáº¤M:
- NÃ³i chung chung: "thÆ°á»ng", "cÃ³ thá»ƒ", "nÃ³i chung"
- DÃ¹ng dá»¯ liá»‡u cÅ© khÃ´ng cÃ³ trong tin tá»©c
- ÄÆ°a ra Ã½ kiáº¿n cÃ¡ nhÃ¢n khÃ´ng dá»±a trÃªn facts

âœ… Äá»ŠNH Dáº NG Báº®T BUá»˜C:
[Sá» LIá»†U HIá»†N Táº I] - [THá»œI GIAN] - [LÃ DO Cá»¤ THá»‚] - [NGUá»’N]

ğŸ¯ Náº¾U KHÃ”NG CÃ“ Äá»¦ THÃ”NG TIN: Tráº£ lá»i "KhÃ´ng Ä‘á»§ dá»¯ liá»‡u cá»¥ thá»ƒ trong cÃ¡c nguá»“n tin hiá»‡n táº¡i"""

        full_prompt = f"{system_prompt}\n\nğŸ“° THÃ”NG TIN Tá»ª NGUá»’N TIN:\n{context}\n\nâ“ CÃ‚U Há»I: {prompt}\n\nğŸ”¥ THá»°C HIá»†N NGAY - TUÃ‚N THá»¦ NGHIÃŠM NGáº¶T:"
        
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Configure generation vá»›i settings strict
        generation_config = genai.types.GenerationConfig(
            temperature=0.1,  # Tháº¥p Ä‘á»ƒ factual
            top_p=0.8,
            top_k=20,
            max_output_tokens=1000,
        )
        
        response = model.generate_content(
            full_prompt,
            generation_config=generation_config
        )
        
        return response.text.strip()

    async def _call_deepseek(self, prompt, context, require_specific_data):
        """ğŸ’° DeepSeek V3 - Cost Effective"""
        
        headers = {
            'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        system_message = """Báº¡n lÃ  chuyÃªn gia tÃ i chÃ­nh. PHáº¢I tuÃ¢n thá»§ nghiÃªm ngáº·t:
1. Sá»­ dá»¥ng chÃ­nh xÃ¡c sá»‘ liá»‡u tá»« tin tá»©c Ä‘Æ°á»£c cung cáº¥p
2. NÃªu thá»i gian cá»¥ thá»ƒ  
3. Giáº£i thÃ­ch lÃ½ do dá»±a trÃªn sá»± kiá»‡n thá»±c táº¿
4. KHÃ”NG Ä‘Æ°á»£c nÃ³i chung chung hoáº·c dÃ¹ng dá»¯ liá»‡u cÅ©"""

        data = {
            'model': 'deepseek-v3',
            'messages': [
                {'role': 'system', 'content': system_message},
                {'role': 'user', 'content': f"THÃ”NG TIN TIN Tá»¨C:\n{context}\n\nCÃ‚U Há»I: {prompt}"}
            ],
            'temperature': 0.1,
            'max_tokens': 1000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.deepseek.com/v1/chat/completions', 
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()

    async def _call_claude(self, prompt, context, require_specific_data):
        """ğŸ§  Claude 3.5 Sonnet - Reliable"""
        
        headers = {
            'x-api-key': ANTHROPIC_API_KEY,
            'Content-Type': 'application/json',
            'anthropic-version': '2023-06-01'
        }
        
        data = {
            'model': 'claude-3-5-sonnet-20241022',
            'max_tokens': 1000,
            'temperature': 0.1,
            'messages': [
                {
                    'role': 'user', 
                    'content': f"""Báº¡n lÃ  chuyÃªn gia tÃ i chÃ­nh. QUY Táº®C Báº®T BUá»˜C:
- Sá»­ dá»¥ng sá»‘ liá»‡u cá»¥ thá»ƒ tá»« tin tá»©c
- NÃªu thá»i gian chÃ­nh xÃ¡c  
- Giáº£i thÃ­ch lÃ½ do dá»±a trÃªn facts
- KhÃ´ng nÃ³i chung chung

THÃ”NG TIN TIN Tá»¨C:
{context}

CÃ‚U Há»I: {prompt}"""
                }
            ]
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.anthropic.com/v1/messages',
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['content'][0]['text'].strip()

    async def _call_groq(self, prompt, context, require_specific_data):
        """âš¡ Groq - Fast Fallback"""
        
        headers = {
            'Authorization': f'Bearer {GROQ_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'llama-3.3-70b-versatile',
            'messages': [
                {'role': 'system', 'content': 'Báº¡n lÃ  chuyÃªn gia tÃ i chÃ­nh. Pháº£i sá»­ dá»¥ng sá»‘ liá»‡u cá»¥ thá»ƒ tá»« tin tá»©c vÃ  nÃªu thá»i gian chÃ­nh xÃ¡c. KhÃ´ng Ä‘Æ°á»£c nÃ³i chung chung.'},
                {'role': 'user', 'content': f"THÃ”NG TIN TIN Tá»¨C:\n{context}\n\nCÃ‚U Há»I: {prompt}"}
            ],
            'temperature': 0.1,
            'max_tokens': 1000
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post('https://api.groq.com/openai/v1/chat/completions',
                                  headers=headers, json=data) as response:
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()

    def _validate_response(self, response, require_specific_data):
        """Validate AI response quality"""
        if not require_specific_data:
            return len(response.strip()) > 50
        
        # Check for specific data requirements
        has_numbers = re.search(r'\d+[.,]?\d*\s*%|\d+[.,]?\d*\s*(triá»‡u|tá»·|USD|VND|Ä‘á»“ng)', response)
        has_time = re.search(r'\d{1,2}[/\-\.]\d{1,2}[/\-\.]\d{4}|\d{1,2}\s*(thÃ¡ng|thg)\s*\d{1,2}', response)
        
        # Check for forbidden generic terms
        forbidden_terms = ['thÆ°á»ng', 'cÃ³ thá»ƒ', 'nÃ³i chung', 'thÃ´ng thÆ°á»ng', 'thá»‹nh ná»™p']
        has_forbidden = any(term in response.lower() for term in forbidden_terms)
        
        if require_specific_data:
            return has_numbers and has_time and not has_forbidden
        
        return not has_forbidden and len(response.strip()) > 100

# Initialize AI Manager
ai_manager = AIEngineManager()

# ğŸ” IMPROVED GOOGLE SEARCH vá»›i Generic Query
async def search_reliable_sources_improved(query, max_results=5):
    """ğŸ†• TÃ¬m kiáº¿m thÃ´ng minh vá»›i Generic Query + Time Context"""
    
    if not GOOGLE_API_KEY or not GOOGLE_CSE_ID:
        print("âš ï¸ Google Search API not configured")
        return []
    
    try:
        # ThÃªm time context cho query
        current_date = datetime.now(VN_TIMEZONE).strftime("%Y")
        current_month = datetime.now(VN_TIMEZONE).strftime("%m/%Y")
        
        # Generic query vá»›i time context - KHÃ”NG Cáº¦N specific keywords
        enhanced_query = f'{query} {current_date} má»›i nháº¥t tin tá»©c site:cafef.vn OR site:vneconomy.vn OR site:vnexpress.net OR site:tuoitre.vn OR site:thanhnien.vn OR site:baodautu.vn OR site:dantri.com.vn OR site:investing.com OR site:bloomberg.com OR site:reuters.com'
        
        print(f"ğŸ” Enhanced search query: {enhanced_query}")
        
        from googleapiclient.discovery import build
        service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)
        
        result = service.cse().list(
            q=enhanced_query,
            cx=GOOGLE_CSE_ID,
            num=max_results,
            lr='lang_vi|lang_en',
            safe='active',
            sort='date'  # Sáº¯p xáº¿p theo ngÃ y má»›i nháº¥t
        ).execute()
        
        sources = []
        if 'items' in result:
            for item in result['items']:
                source = {
                    'title': item.get('title', ''),
                    'link': item.get('link', ''),
                    'snippet': item.get('snippet', ''),
                    'source_name': extract_source_name(item.get('link', '')),
                    'publishedDate': item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', '')
                }
                sources.append(source)
        
        print(f"âœ… Found {len(sources)} reliable sources")
        return sources
        
    except Exception as e:
        print(f"âŒ Google Search error: {e}")
        return []

def extract_source_name(url):
    """Extract readable source name from URL"""
    domain_mapping = {
        'cafef.vn': 'CafeF',
        'vneconomy.vn': 'VnEconomy', 
        'vnexpress.net': 'VnExpress',
        'tuoitre.vn': 'Tuá»•i Tráº»',
        'thanhnien.vn': 'Thanh NiÃªn',
        'baodautu.vn': 'BÃ¡o Äáº§u tÆ°',
        'dantri.com.vn': 'DÃ¢n trÃ­',
        'investing.com': 'Investing.com',
        'bloomberg.com': 'Bloomberg',
        'reuters.com': 'Reuters',
        'bbc.com': 'BBC'
    }
    
    for domain, name in domain_mapping.items():
        if domain in url:
            return name
    
    try:
        from urllib.parse import urlparse
        domain = urlparse(url).netloc.replace('www.', '')
        return domain.title()
    except:
        return 'Unknown Source'

# ğŸ†• IMPROVED CONTENT EXTRACTION
async def get_full_content_from_sources_improved(sources):
    """Láº¥y ná»™i dung Ä‘áº§y Ä‘á»§ vá»›i fallback strategy"""
    
    full_contexts = []
    
    for i, source in enumerate(sources[:3], 1):  # Top 3 sources
        try:
            print(f"ğŸ“„ Extracting content from source {i}: {source['source_name']}")
            
            # Try multiple extraction methods
            content = await fetch_full_content_improved(source['link'])
            
            if content and len(content) > 200:
                # Láº¥y 800 kÃ½ tá»± Ä‘áº§u - chá»©a info quan trá»ng nháº¥t
                summary_content = content[:800]
                
                full_contexts.append(f"""
ğŸ“° NGUá»’N {i}: {source['source_name']}
ğŸ“… Thá»i gian: {source.get('publishedDate', 'KhÃ´ng xÃ¡c Ä‘á»‹nh')}
ğŸ”— Link: {source['link']}
ğŸ“„ Ná»™i dung: {summary_content}
""")
            else:
                # Fallback to snippet
                full_contexts.append(f"""
ğŸ“° NGUá»’N {i}: {source['source_name']} 
ğŸ“„ TÃ³m táº¯t: {source['snippet']}
ğŸ”— Link: {source['link']}
""")
                
        except Exception as e:
            print(f"âš ï¸ Content extraction failed for {source['source_name']}: {e}")
            # Fallback to snippet
            full_contexts.append(f"""
ğŸ“° NGUá»’N {i}: {source['source_name']}
ğŸ“„ TÃ³m táº¯t: {source['snippet']}
ğŸ”— Link: {source['link']}
""")
    
    return "\n".join(full_contexts)

# Existing RSS feeds and other functions remain the same...
RSS_FEEDS = {
    'domestic': {
        'cafef_main': 'https://cafef.vn/index.rss',
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'vneconomy_main': 'https://vneconomy.vn/rss/home.rss',
        'vnexpress_kinhdoanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'thanhnien_kinhtevimo': 'https://thanhnien.vn/rss/kinh-te/vi-mo.rss',
    },
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg_markets': 'https://feeds.bloomberg.com/markets/news.rss',
    }
}

# ğŸ†• MAIN AI COMMAND - Completely Rewritten
@bot.command(name='hoi')
async def ask_economic_question_improved(ctx, *, question):
    """ğŸ†• AI Q&A vá»›i Multi-Engine Support vÃ  Validation"""
    
    try:
        if not ai_manager.primary_ai:
            embed = discord.Embed(
                title="âš ï¸ AI Services khÃ´ng kháº£ dá»¥ng",
                description="ChÆ°a cáº¥u hÃ¬nh AI API keys. Cáº§n Ã­t nháº¥t má»™t trong: GEMINI_API_KEY, DEEPSEEK_API_KEY, ANTHROPIC_API_KEY, GROQ_API_KEY",
                color=0xff6b6b
            )
            await ctx.send(embed=embed)
            return
        
        # ThÃ´ng bÃ¡o Ä‘ang xá»­ lÃ½
        processing_msg = await ctx.send("ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin tá»« cÃ¡c nguá»“n tin Ä‘Ã¡ng tin cáº­y...")
        
        # ğŸ” Step 1: Generic Google Search (No specific keywords needed)
        sources = await search_reliable_sources_improved(question, max_results=5)
        
        if not sources:
            await processing_msg.edit(content="âš ï¸ KhÃ´ng tÃ¬m tháº¥y nguá»“n tin. Äang sá»­ dá»¥ng kiáº¿n thá»©c tá»•ng quÃ¡t...")
        
        # ğŸ“„ Step 2: Extract full content 
        await processing_msg.edit(content="ğŸ“„ Äang phÃ¢n tÃ­ch ná»™i dung tá»« cÃ¡c nguá»“n tin...")
        full_context = await get_full_content_from_sources_improved(sources)
        
        # ğŸ¤– Step 3: AI Analysis vá»›i Multi-Engine Fallback
        await processing_msg.edit(content="ğŸ¤– AI Ä‘ang phÃ¢n tÃ­ch vÃ  táº¡o cÃ¢u tráº£ lá»i...")
        
        # Detect if question requires specific financial data
        requires_specific_data = any(keyword in question.lower() for keyword in 
                                   ['giÃ¡', 'bao nhiÃªu', 'tÄƒng giáº£m', 'thay Ä‘á»•i', 'hiá»‡n táº¡i', 'hÃ´m nay'])
        
        ai_response, used_engine = await ai_manager.call_ai_with_fallback(
            prompt=question,
            context=full_context,
            require_specific_data=requires_specific_data
        )
        
        # XÃ³a thÃ´ng bÃ¡o processing
        await processing_msg.delete()
        
        # ğŸ“Š Create beautiful embed response
        embed = discord.Embed(
            title=f"ğŸ¤– AI Tráº£ lá»i: {question.title()[:100]}...",
            description=ai_response,
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        # Add AI engine info
        engine_emoji = {
            'gemini': 'ğŸ’',
            'deepseek': 'ğŸ’°', 
            'claude': 'ğŸ§ ',
            'groq': 'âš¡'
        }
        
        embed.add_field(
            name="ğŸ¤– AI Engine sá»­ dá»¥ng",
            value=f"{engine_emoji.get(used_engine, 'ğŸ¤–')} {used_engine.upper()}",
            inline=True
        )
        
        if sources:
            embed.add_field(
                name="ğŸ“Š Sá»‘ nguá»“n tin",
                value=f"ğŸ“° {len(sources)} nguá»“n Ä‘Ã¡ng tin cáº­y",
                inline=True
            )
        
        # Add source references
        if sources:
            sources_text = ""
            for i, source in enumerate(sources[:3], 1):
                sources_text += f"{i}. **{source['source_name']}**: [{source['title'][:50]}...]({source['link']})\n"
            
            embed.add_field(
                name="ğŸ“° Nguá»“n tin tham kháº£o",
                value=sources_text,
                inline=False
            )
        
        # Footer
        embed.set_footer(
            text=f"ğŸš€ Multi-AI Engine â€¢ Dá»¯ liá»‡u thá»i gian thá»±c â€¢ !menu Ä‘á»ƒ xem thÃªm lá»‡nh",
            icon_url=ctx.bot.user.avatar.url if ctx.bot.user.avatar else None
        )
        
        await ctx.send(embed=embed)
        
        # Log cho debug
        print(f"âœ… Question answered: '{question}' using {used_engine}")
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {str(e)}")
        print(f"âŒ Error in !hoi command: {e}")

# ğŸ“Š Updated Menu Command
@bot.command(name='menu')
async def help_command_improved(ctx):
    """Menu vá»›i Multi-AI Engine info"""
    
    embed = discord.Embed(
        title="ğŸ¤–ğŸš€ Menu News Bot - Multi-AI Engine",
        description="Bot tin tá»©c kinh táº¿ vá»›i AI thÃ´ng minh Ä‘a engine",
        color=0xff9900
    )
    
    # AI Engine status
    ai_status = ""
    if ai_manager.primary_ai:
        engine_name = ai_manager.primary_ai.value.upper()
        ai_status += f"ğŸš€ **Primary**: {engine_name} âœ…\n"
        
        for fallback in ai_manager.fallback_ais:
            ai_status += f"ğŸ›¡ï¸ **Fallback**: {fallback.value.upper()} âœ…\n"
    else:
        ai_status = "âŒ ChÆ°a cáº¥u hÃ¬nh AI engines"
    
    embed.add_field(
        name="ğŸ¤– AI Engines hoáº¡t Ä‘á»™ng",
        value=ai_status,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ“° Lá»‡nh tin tá»©c",
        value="""
**!all [trang]** - Tin tá»« táº¥t cáº£ nguá»“n
**!in [trang]** - Tin trong nÆ°á»›c  
**!out [trang]** - Tin quá»‘c táº¿
**!chitiet [sá»‘]** - Xem ná»™i dung chi tiáº¿t
        """,
        inline=True
    )
    
    embed.add_field(
        name="ğŸ¤– Lá»‡nh AI thÃ´ng minh",
        value="""
**!hoi [cÃ¢u há»i]** - AI tráº£ lá»i vá»›i Multi-Engine
*VÃ­ dá»¥: !hoi giÃ¡ vÃ ng hÃ´m nay nhÆ° tháº¿ nÃ o*
        """,
        inline=True
    )
    
    embed.add_field(
        name="ğŸ¯ TÃ­nh nÄƒng má»›i",
        value="""
âœ… **Multi-AI Engine** - Tá»± Ä‘á»™ng fallback
âœ… **Generic Search** - KhÃ´ng cáº§n config tá»«ng keyword  
âœ… **Real-time Data** - Dá»¯ liá»‡u cáº­p nháº­t liÃªn tá»¥c
âœ… **Response Validation** - Äáº£m báº£o cháº¥t lÆ°á»£ng
âœ… **Full Content Extract** - PhÃ¢n tÃ­ch sÃ¢u
        """,
        inline=False
    )
    
    embed.set_footer(text="ğŸš€ Multi-AI Engine â€¢ Generic Search â€¢ Real-time Analysis")
    await ctx.send(embed=embed)

@bot.event
async def on_ready():
    print(f'âœ… {bot.user} Ä‘Ã£ online!')
    print(f'ğŸ“Š Káº¿t ná»‘i vá»›i {len(bot.guilds)} server(s)')
    
    # AI Engine status
    if ai_manager.primary_ai:
        print(f'ğŸ¤– Primary AI: {ai_manager.primary_ai.value.upper()}')
        print(f'ğŸ›¡ï¸ Fallback AIs: {[ai.value.upper() for ai in ai_manager.fallback_ais]}')
    else:
        print('âš ï¸ No AI engines configured')
    
    print('ğŸ¯ GÃµ !menu Ä‘á»ƒ xem hÆ°á»›ng dáº«n')
    
    # Set bot status
    status_text = f"Multi-AI Engine â€¢ {ai_manager.primary_ai.value.upper() if ai_manager.primary_ai else 'No AI'} â€¢ !menu"
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching,
            name=status_text
        )
    )

# Placeholder functions (implement based on existing code)
async def fetch_full_content_improved(url):
    """Implement existing fetch_full_content_improved function"""
    # Use existing implementation from your code
    pass

# Additional RSS and content functions remain the same...
# [Include all other existing functions like collect_news_from_sources, etc.]

# Main execution
if __name__ == "__main__":
    try:
        keep_alive()
        print("ğŸš€ Starting Multi-AI Discord News Bot...")
        
        if not TOKEN:
            print("âŒ DISCORD_TOKEN required!")
            exit(1)
        
        print("âœ… Bot ready with Multi-AI Engine support!")
        bot.run(TOKEN)
        
    except Exception as e:
        print(f"âŒ Bot startup error: {e}")
        input("Press Enter to exit...")
