import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime
import time
from urllib.parse import urljoin
import html
import chardet

# Cáº¥u hÃ¬nh bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# ğŸ”’ Báº¢O Máº¬T: Láº¥y token tá»« environment variable
# KHÃ”NG BAO GIá»œ hardcode token trong code ná»¯a!
TOKEN = os.getenv('DISCORD_TOKEN')

if not TOKEN:
    print("âŒ Cáº¢NH BÃO: KhÃ´ng tÃ¬m tháº¥y DISCORD_TOKEN trong environment variables!")
    print("ğŸ”§ Vui lÃ²ng thÃªm DISCORD_TOKEN vÃ o Render Environment Variables")
    exit(1)

# LÆ°u trá»¯ tin tá»©c theo tá»«ng user Ä‘á»ƒ xem chi tiáº¿t
user_news_cache = {}

# RSS feeds Ä‘Ã£ Ä‘Æ°á»£c kiá»ƒm tra vÃ  xÃ¡c nháº­n hoáº¡t Ä‘á»™ng
RSS_FEEDS = {
    # === KINH Táº¾ TRONG NÆ¯á»šC - ÄÃƒ KIá»‚M TRA ===
    'domestic': {
        # CafeF - RSS chÃ­nh hoáº¡t Ä‘á»™ng tá»‘t
        'cafef_main': 'https://cafef.vn/index.rss',
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'cafef_batdongsan': 'https://cafef.vn/bat-dong-san.rss',
        'cafef_taichinh': 'https://cafef.vn/tai-chinh-ngan-hang.rss',
        'cafef_vimo': 'https://cafef.vn/vi-mo-dau-tu.rss',
        
        # CafeBiz - RSS tá»•ng há»£p
        'cafebiz_main': 'https://cafebiz.vn/index.rss',
        
        # BÃ¡o Äáº§u tÆ° - RSS hoáº¡t Ä‘á»™ng
        'baodautu_main': 'https://baodautu.vn/rss.xml',
        
        # VnEconomy - RSS tin tá»©c chÃ­nh
        'vneconomy_main': 'https://vneconomy.vn/rss/home.rss',
        'vneconomy_chungkhoan': 'https://vneconomy.vn/rss/chung-khoan.rss',
        
        # VnExpress Kinh doanh 
        'vnexpress_kinhdoanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'vnexpress_chungkhoan': 'https://vnexpress.net/rss/kinh-doanh/chung-khoan.rss',
        
        # Thanh NiÃªn - RSS kinh táº¿
        'thanhnien_kinhtevimo': 'https://thanhnien.vn/rss/kinh-te/vi-mo.rss',
        'thanhnien_chungkhoan': 'https://thanhnien.vn/rss/kinh-te/chung-khoan.rss',
        
        # NhÃ¢n DÃ¢n - RSS tÃ i chÃ­nh chá»©ng khoÃ¡n
        'nhandanonline_tc': 'https://nhandan.vn/rss/tai-chinh-chung-khoan.rss'
    },
    
    # === KINH Táº¾ QUá»C Táº¾ ===
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg_markets': 'https://feeds.bloomberg.com/markets/news.rss',
        'marketwatch_latest': 'https://feeds.marketwatch.com/marketwatch/realtimeheadlines/',
        'forbes_money': 'https://www.forbes.com/money/feed/',
        'financial_times': 'https://www.ft.com/rss/home',
        'business_insider': 'https://feeds.businessinsider.com/custom/all',
        'the_economist': 'https://www.economist.com/rss'
    }
}

@bot.event
async def on_ready():
    print(f'âœ… {bot.user} Ä‘Ã£ online!')
    print(f'ğŸ“Š Káº¿t ná»‘i vá»›i {len(bot.guilds)} server(s)')
    total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
    print(f'ğŸ“° Sáºµn sÃ ng cung cáº¥p tin tá»« {total_sources} nguá»“n ÄÃƒ KIá»‚M TRA')
    print(f'ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {len(RSS_FEEDS["domestic"])} nguá»“n')
    print(f'ğŸŒ Quá»‘c táº¿: {len(RSS_FEEDS["international"])} nguá»“n')
    print('ğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, VÄ© mÃ´, Báº¥t Ä‘á»™ng sáº£n')
    print('ğŸ¯ GÃµ !menu Ä‘á»ƒ xem hÆ°á»›ng dáº«n')
    
    # Set bot status
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching, 
            name="tin kinh táº¿ báº£o máº­t | !menu"
        )
    )

async def fetch_full_content(url):
    """Láº¥y ná»™i dung Ä‘áº§y Ä‘á»§ tá»« URL bÃ i viáº¿t vá»›i xá»­ lÃ½ encoding tá»‘t hÆ¡n"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # Láº¥y ná»™i dung vá»›i timeout ngáº¯n hÆ¡n
        response = requests.get(url, headers=headers, timeout=8, stream=True)
        response.raise_for_status()
        
        # Xá»­ lÃ½ encoding
        raw_content = response.content
        
        # Tá»± Ä‘á»™ng detect encoding
        detected = chardet.detect(raw_content)
        encoding = detected['encoding'] or 'utf-8'
        
        try:
            content = raw_content.decode(encoding)
        except:
            # Fallback encoding
            content = raw_content.decode('utf-8', errors='ignore')
        
        # Loáº¡i bá» HTML tags má»™t cÃ¡ch thÃ´ng minh hÆ¡n
        # TÃ¬m ná»™i dung chÃ­nh
        content_patterns = [
            r'<article[^>]*>(.*?)</article>',
            r'<div[^>]*class="[^"]*content[^"]*"[^>]*>(.*?)</div>',
            r'<div[^>]*class="[^"]*article[^"]*"[^>]*>(.*?)</div>',
            r'<div[^>]*id="[^"]*content[^"]*"[^>]*>(.*?)</div>',
            r'<main[^>]*>(.*?)</main>',
            r'<section[^>]*class="[^"]*content[^"]*"[^>]*>(.*?)</section>'
        ]
        
        main_content = ""
        for pattern in content_patterns:
            matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)
            if matches:
                main_content = matches[0]
                break
        
        # Náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c content chÃ­nh, láº¥y toÃ n bá»™ body
        if not main_content:
            body_match = re.search(r'<body[^>]*>(.*?)</body>', content, re.DOTALL | re.IGNORECASE)
            if body_match:
                main_content = body_match.group(1)
            else:
                main_content = content
        
        # Loáº¡i bá» scripts, styles, vÃ  cÃ¡c tháº» khÃ´ng cáº§n thiáº¿t
        main_content = re.sub(r'<script[^>]*>.*?</script>', '', main_content, flags=re.DOTALL | re.IGNORECASE)
        main_content = re.sub(r'<style[^>]*>.*?</style>', '', main_content, flags=re.DOTALL | re.IGNORECASE)
        main_content = re.sub(r'<nav[^>]*>.*?</nav>', '', main_content, flags=re.DOTALL | re.IGNORECASE)
        main_content = re.sub(r'<header[^>]*>.*?</header>', '', main_content, flags=re.DOTALL | re.IGNORECASE)
        main_content = re.sub(r'<footer[^>]*>.*?</footer>', '', main_content, flags=re.DOTALL | re.IGNORECASE)
        main_content = re.sub(r'<aside[^>]*>.*?</aside>', '', main_content, flags=re.DOTALL | re.IGNORECASE)
        
        # Loáº¡i bá» HTML tags
        clean_content = re.sub(r'<[^>]+>', ' ', main_content)
        
        # Decode HTML entities
        clean_content = html.unescape(clean_content)
        
        # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a vÃ  normalize
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
        
        # Láº¥y pháº§n Ä‘áº§u cÃ³ Ã½ nghÄ©a
        sentences = clean_content.split('. ')
        meaningful_content = []
        
        for sentence in sentences[:10]:  # Láº¥y 10 cÃ¢u Ä‘áº§u
            if len(sentence.strip()) > 20:  # Chá»‰ láº¥y cÃ¢u cÃ³ Ä‘á»™ dÃ i há»£p lÃ½
                meaningful_content.append(sentence.strip())
                
        result = '. '.join(meaningful_content)
        
        # Giá»›i háº¡n Ä‘á»™ dÃ i
        if len(result) > 1800:
            result = result[:1800] + "..."
            
        return result if result else "KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« bÃ i viáº¿t nÃ y."
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i láº¥y ná»™i dung tá»« {url}: {e}")
        return f"KhÃ´ng thá»ƒ láº¥y ná»™i dung chi tiáº¿t. Lá»—i: {str(e)}"

async def collect_news_from_sources(sources_dict, limit_per_source=8):
    """Thu tháº­p tin tá»©c tá»« nhiá»u nguá»“n vÃ  sáº¯p xáº¿p theo thá»i gian"""
    all_news = []
    
    for source_name, rss_url in sources_dict.items():
        try:
            print(f"ğŸ”„ Äang láº¥y tin tá»« {source_name}...")
            
            # Headers cáº£i thiá»‡n
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'application/rss+xml, application/xml, text/xml',
                'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8'
            }
            
            # Parse RSS feed vá»›i xá»­ lÃ½ lá»—i tá»‘t hÆ¡n
            try:
                response = requests.get(rss_url, headers=headers, timeout=10)
                response.raise_for_status()
                
                # Parse vá»›i feedparser
                feed = feedparser.parse(response.content)
                
            except Exception as req_error:
                print(f"âš ï¸ Lá»—i request tá»« {source_name}: {req_error}")
                # Thá»­ parse trá»±c tiáº¿p vá»›i feedparser
                feed = feedparser.parse(rss_url)
            
            # Kiá»ƒm tra xem feed cÃ³ há»£p lá»‡ khÃ´ng
            if not hasattr(feed, 'entries') or len(feed.entries) == 0:
                print(f"âš ï¸ KhÃ´ng cÃ³ tin tá»« {source_name} - RSS cÃ³ thá»ƒ khÃ´ng hoáº¡t Ä‘á»™ng")
                continue
                
            entries_processed = 0
            for entry in feed.entries[:limit_per_source]:
                try:
                    # Láº¥y thá»i gian published
                    published_time = datetime.now()
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        try:
                            published_time = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                        except:
                            pass
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        try:
                            published_time = datetime.fromtimestamp(time.mktime(entry.updated_parsed))
                        except:
                            pass
                    
                    # Láº¥y mÃ´ táº£/tÃ³m táº¯t náº¿u cÃ³
                    description = ""
                    if hasattr(entry, 'summary'):
                        description = entry.summary[:500] + "..." if len(entry.summary) > 500 else entry.summary
                    elif hasattr(entry, 'description'):
                        description = entry.description[:500] + "..." if len(entry.description) > 500 else entry.description
                    
                    # Kiá»ƒm tra cÃ¡c trÆ°á»ng báº¯t buá»™c
                    if not hasattr(entry, 'title') or not hasattr(entry, 'link'):
                        continue
                    
                    # Clean title
                    title = html.unescape(entry.title.strip())
                    
                    news_item = {
                        'title': title,
                        'link': entry.link,
                        'source': source_name,
                        'published': published_time,
                        'published_str': published_time.strftime("%H:%M %d/%m"),
                        'description': html.unescape(description) if description else ""
                    }
                    all_news.append(news_item)
                    entries_processed += 1
                    
                except Exception as entry_error:
                    print(f"âš ï¸ Lá»—i xá»­ lÃ½ tin tá»« {source_name}: {entry_error}")
                    continue
                    
            print(f"âœ… Láº¥y Ä‘Æ°á»£c {entries_processed} tin tá»« {source_name}")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi láº¥y tin tá»« {source_name}: {e}")
            continue
    
    print(f"ğŸ“Š Tá»•ng cá»™ng láº¥y Ä‘Æ°á»£c {len(all_news)} tin tá»« táº¥t cáº£ nguá»“n")
    
    # Loáº¡i bá» tin trÃ¹ng láº·p
    unique_news = remove_duplicate_news(all_news)
    print(f"ğŸ”„ Sau khi loáº¡i trÃ¹ng cÃ²n {len(unique_news)} tin")
    
    # Sáº¯p xáº¿p theo thá»i gian má»›i nháº¥t
    unique_news.sort(key=lambda x: x['published'], reverse=True)
    return unique_news

def remove_duplicate_news(news_list):
    """Loáº¡i bá» tin tá»©c trÃ¹ng láº·p dá»±a trÃªn tiÃªu Ä‘á» vÃ  link"""
    seen_links = set()
    seen_titles = set()
    unique_news = []
    
    for news in news_list:
        # Chuáº©n hÃ³a tiÃªu Ä‘á» Ä‘á»ƒ so sÃ¡nh
        normalized_title = normalize_title(news['title'])
        
        # Kiá»ƒm tra trÃ¹ng láº·p
        is_duplicate = False
        
        if news['link'] in seen_links:
            is_duplicate = True
        else:
            # Kiá»ƒm tra tiÃªu Ä‘á» tÆ°Æ¡ng tá»±
            for existing_title in seen_titles:
                similarity = calculate_title_similarity(normalized_title, existing_title)
                if similarity > 0.75:  # 75% tÆ°Æ¡ng tá»± thÃ¬ coi lÃ  trÃ¹ng
                    is_duplicate = True
                    break
        
        if not is_duplicate:
            seen_links.add(news['link'])
            seen_titles.add(normalized_title)
            unique_news.append(news)
    
    return unique_news

def calculate_title_similarity(title1, title2):
    """TÃ­nh Ä‘á»™ tÆ°Æ¡ng tá»± giá»¯a 2 tiÃªu Ä‘á»"""
    words1 = set(title1.split())
    words2 = set(title2.split())
    
    if not words1 or not words2:
        return 0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0

def normalize_title(title):
    """Chuáº©n hÃ³a tiÃªu Ä‘á» Ä‘á»ƒ so sÃ¡nh trÃ¹ng láº·p"""
    import re
    # Chuyá»ƒn vá» chá»¯ thÆ°á»ng
    title = title.lower()
    # Loáº¡i bá» dáº¥u cÃ¢u vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t
    title = re.sub(r'[^\w\s]', '', title)
    # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    title = ' '.join(title.split())
    
    # Chá»‰ láº¥y 10 tá»« Ä‘áº§u Ä‘á»ƒ so sÃ¡nh
    words = title.split()[:10]
    return ' '.join(words)

def save_user_news(user_id, news_list, command_type):
    """LÆ°u tin tá»©c cá»§a user Ä‘á»ƒ sá»­ dá»¥ng cho lá»‡nh !detail"""
    user_news_cache[user_id] = {
        'news': news_list,
        'command': command_type,
        'timestamp': datetime.now()
    }

@bot.command(name='all')
async def get_all_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« táº¥t cáº£ nguá»“n (trong nÆ°á»›c + quá»‘c táº¿)"""
    try:
        page = max(1, int(page))
        
        # Gá»­i thÃ´ng bÃ¡o Ä‘ang táº£i
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c tá»« táº¥t cáº£ nguá»“n...")
        
        # Thu tháº­p tin tá»« cáº£ hai nguá»“n
        domestic_news = await collect_news_from_sources(RSS_FEEDS['domestic'], 8)
        international_news = await collect_news_from_sources(RSS_FEEDS['international'], 6)
        
        # XÃ³a thÃ´ng bÃ¡o loading
        await loading_msg.delete()
        
        # Káº¿t há»£p vÃ  sáº¯p xáº¿p
        all_news = domestic_news + international_news
        all_news.sort(key=lambda x: x['published'], reverse=True)
        
        # PhÃ¢n trang
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = all_news[start_index:end_index]
        
        if not page_news:
            total_pages = (len(all_news) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        # Táº¡o embed vá»›i thiáº¿t káº¿ tá»‘t hÆ¡n
        embed = discord.Embed(
            title=f"ğŸ“° Tin tá»©c kinh táº¿ tá»•ng há»£p (Trang {page})",
            description=f"ğŸ”’ Bot báº£o máº­t â€¢ Cáº­p nháº­t tá»« {len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])} nguá»“n tin uy tÃ­n",
            color=0x00ff88,
            timestamp=ctx.message.created_at
        )
        
        # Emoji map cho tá»«ng nguá»“n
        emoji_map = {
            # Nguá»“n trong nÆ°á»›c
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸',
            # Nguá»“n quá»‘c táº¿
            'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 'marketwatch_latest': 'ğŸ“ˆ',
            'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        # Thá»‘ng kÃª
        domestic_count = sum(1 for news in page_news if news['source'] in RSS_FEEDS['domestic'])
        international_count = len(page_news) - domestic_count
        
        embed.add_field(
            name="ğŸ“Š Thá»‘ng kÃª trang nÃ y",
            value=f"ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {domestic_count} tin\nğŸŒ Quá»‘c táº¿: {international_count} tin\nğŸ“Š Tá»•ng cÃ³ sáºµn: {len(all_news)} tin",
            inline=False
        )
        
        # Hiá»ƒn thá»‹ tin tá»©c
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            
            # TÃªn nguá»“n hiá»ƒn thá»‹
            source_names = {
                'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
                'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafebiz_main': 'CafeBiz',
                'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy CK',
                'vnexpress_kinhdoanh': 'VnExpress KD', 'vnexpress_chungkhoan': 'VnExpress CK',
                'thanhnien_kinhtevimo': 'Thanh NiÃªn VM', 'thanhnien_chungkhoan': 'Thanh NiÃªn CK',
                'nhandanonline_tc': 'NhÃ¢n DÃ¢n TC', 'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters',
                'bloomberg_markets': 'Bloomberg', 'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes',
                'financial_times': 'Financial Times', 'business_insider': 'Business Insider', 'the_economist': 'The Economist'
            }
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ“… {news['published_str']} â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        # LÆ°u tin tá»©c
        save_user_news(ctx.author.id, page_news, f"all_page_{page}")
        
        # Footer
        total_pages = (len(all_news) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸ”’ Bot báº£o máº­t â€¢ Trang {page}/{total_pages} â€¢ !all {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Sá»‘ trang khÃ´ng há»£p lá»‡! Sá»­ dá»¥ng: `!all [sá»‘]`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='in')
async def get_domestic_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« cÃ¡c nguá»“n trong nÆ°á»›c"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c trong nÆ°á»›c...")
        
        news_list = await collect_news_from_sources(RSS_FEEDS['domestic'], 10)
        
        await loading_msg.delete()
        
        # PhÃ¢n trang
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"ğŸ‡»ğŸ‡³ Tin kinh táº¿ trong nÆ°á»›c (Trang {page})",
            description=f"ğŸ”’ Bot báº£o máº­t â€¢ Tá»« {len(RSS_FEEDS['domestic'])} nguá»“n tin chuyÃªn ngÃ nh Viá»‡t Nam",
            color=0xff0000,
            timestamp=ctx.message.created_at
        )
        
        embed.add_field(
            name="ğŸ“Š ThÃ´ng tin",
            value=f"ğŸ“° Tá»•ng tin cÃ³ sáºµn: {len(news_list)} tin\nğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, Báº¥t Ä‘á»™ng sáº£n, VÄ© mÃ´",
            inline=False
        )
        
        # Hiá»ƒn thá»‹ tin tá»©c trong nÆ°á»›c
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸'
        }
        
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF CK', 'cafef_batdongsan': 'CafeF BÄS',
            'cafef_taichinh': 'CafeF TC', 'cafef_vimo': 'CafeF VM', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy CK',
            'vnexpress_kinhdoanh': 'VnExpress KD', 'vnexpress_chungkhoan': 'VnExpress CK',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VM', 'thanhnien_chungkhoan': 'Thanh NiÃªn CK',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TC'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸ“°')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ“… {news['published_str']} â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"in_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸ”’ Bot báº£o máº­t â€¢ Trang {page}/{total_pages} â€¢ !in {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='out')
async def get_international_news(ctx, page=1):
    """Láº¥y tin tá»©c tá»« cÃ¡c nguá»“n quá»‘c táº¿"""
    try:
        page = max(1, int(page))
        
        loading_msg = await ctx.send("â³ Äang táº£i tin tá»©c quá»‘c táº¿...")
        
        news_list = await collect_news_from_sources(RSS_FEEDS['international'], 8)
        
        await loading_msg.delete()
        
        # PhÃ¢n trang
        items_per_page = 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"âŒ KhÃ´ng cÃ³ tin tá»©c á»Ÿ trang {page}! Tá»•ng cá»™ng cÃ³ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"ğŸŒ Tin kinh táº¿ quá»‘c táº¿ (Trang {page})",
            description=f"ğŸ”’ Bot báº£o máº­t â€¢ Tá»« {len(RSS_FEEDS['international'])} nguá»“n tin hÃ ng Ä‘áº§u tháº¿ giá»›i",
            color=0x0066ff,
            timestamp=ctx.message.created_at
        )
        
        embed.add_field(
            name="ğŸ“Š ThÃ´ng tin",
            value=f"ğŸ“° Tá»•ng tin cÃ³ sáºµn: {len(news_list)} tin",
            inline=False
        )
        
        emoji_map = {
            'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 'marketwatch_latest': 'ğŸ“ˆ',
            'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        source_names = {
            'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters', 'bloomberg_markets': 'Bloomberg', 
            'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes', 'financial_times': 'Financial Times', 
            'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        for i, news in enumerate(page_news, 1):
            emoji = emoji_map.get(news['source'], 'ğŸŒ')
            title = news['title'][:70] + "..." if len(news['title']) > 70 else news['title']
            source_display = source_names.get(news['source'], news['source'])
            
            embed.add_field(
                name=f"{i}. {emoji} {title}",
                value=f"ğŸ“… {news['published_str']} â€¢ ğŸ“° {source_display}\nğŸ”— [Äá»c bÃ i viáº¿t]({news['link']})",
                inline=False
            )
        
        save_user_news(ctx.author.id, page_news, f"out_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"ğŸ”’ Bot báº£o máº­t â€¢ Trang {page}/{total_pages} â€¢ !out {page+1} tiáº¿p â€¢ !chitiet [sá»‘] xem chi tiáº¿t")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

@bot.command(name='chitiet')
async def get_news_detail(ctx, news_number: int):
    """Xem chi tiáº¿t tin tá»©c theo sá»‘ thá»© tá»± - ÄÃƒ Sá»¬A Lá»–I ENCODING"""
    try:
        user_id = ctx.author.id
        
        if user_id not in user_news_cache:
            await ctx.send("âŒ Báº¡n chÆ°a xem tin tá»©c nÃ o! HÃ£y dÃ¹ng `!all`, `!in`, hoáº·c `!out` trÆ°á»›c.")
            return
        
        user_data = user_news_cache[user_id]
        news_list = user_data['news']
        
        if news_number < 1 or news_number > len(news_list):
            await ctx.send(f"âŒ Sá»‘ khÃ´ng há»£p lá»‡! Chá»n tá»« 1 Ä‘áº¿n {len(news_list)}")
            return
        
        news = news_list[news_number - 1]
        
        # ThÃ´ng bÃ¡o Ä‘ang táº£i vá»›i progress
        loading_msg = await ctx.send("â³ Äang phÃ¢n tÃ­ch vÃ  trÃ­ch xuáº¥t ná»™i dung bÃ i viáº¿t...")
        
        # Láº¥y ná»™i dung vá»›i function Ä‘Ã£ cáº£i tiáº¿n
        full_content = await fetch_full_content(news['link'])
        
        await loading_msg.delete()
        
        # Táº¡o embed Ä‘áº¹p hÆ¡n
        embed = discord.Embed(
            title="ğŸ“– Chi tiáº¿t bÃ i viáº¿t",
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        # Emoji cho nguá»“n
        emoji_map = {
            'cafef_main': 'â˜•', 'cafef_chungkhoan': 'ğŸ“ˆ', 'cafef_batdongsan': 'ğŸ¢', 'cafef_taichinh': 'ğŸ’°', 'cafef_vimo': 'ğŸ“Š',
            'cafebiz_main': 'ğŸ’¼', 'baodautu_main': 'ğŸ¯', 'vneconomy_main': 'ğŸ“°', 'vneconomy_chungkhoan': 'ğŸ“ˆ',
            'vnexpress_kinhdoanh': 'âš¡', 'vnexpress_chungkhoan': 'ğŸ“ˆ', 'thanhnien_kinhtevimo': 'ğŸ“Š', 'thanhnien_chungkhoan': 'ğŸ“ˆ',
            'nhandanonline_tc': 'ğŸ›ï¸', 'yahoo_finance': 'ğŸ’°', 'reuters_business': 'ğŸŒ', 'bloomberg_markets': 'ğŸ’¹', 
            'marketwatch_latest': 'ğŸ“ˆ', 'forbes_money': 'ğŸ’', 'financial_times': 'ğŸ’¼', 'business_insider': 'ğŸ“°', 'the_economist': 'ğŸ“'
        }
        
        source_names = {
            'cafef_main': 'CafeF', 'cafef_chungkhoan': 'CafeF Chá»©ng khoÃ¡n', 'cafef_batdongsan': 'CafeF Báº¥t Ä‘á»™ng sáº£n',
            'cafef_taichinh': 'CafeF TÃ i chÃ­nh', 'cafef_vimo': 'CafeF VÄ© mÃ´', 'cafebiz_main': 'CafeBiz',
            'baodautu_main': 'BÃ¡o Äáº§u tÆ°', 'vneconomy_main': 'VnEconomy', 'vneconomy_chungkhoan': 'VnEconomy Chá»©ng khoÃ¡n',
            'vnexpress_kinhdoanh': 'VnExpress Kinh doanh', 'vnexpress_chungkhoan': 'VnExpress Chá»©ng khoÃ¡n',
            'thanhnien_kinhtevimo': 'Thanh NiÃªn VÄ© mÃ´', 'thanhnien_chungkhoan': 'Thanh NiÃªn Chá»©ng khoÃ¡n',
            'nhandanonline_tc': 'NhÃ¢n DÃ¢n TÃ i chÃ­nh', 'yahoo_finance': 'Yahoo Finance', 'reuters_business': 'Reuters Business',
            'bloomberg_markets': 'Bloomberg Markets', 'marketwatch_latest': 'MarketWatch', 'forbes_money': 'Forbes Money',
            'financial_times': 'Financial Times', 'business_insider': 'Business Insider', 'the_economist': 'The Economist'
        }
        
        emoji = emoji_map.get(news['source'], 'ğŸ“°')
        source_display = source_names.get(news['source'], news['source'])
        
        embed.add_field(
            name=f"{emoji} TiÃªu Ä‘á»",
            value=news['title'],
            inline=False
        )
        
        embed.add_field(
            name="ğŸ“… Thá»i gian",
            value=news['published_str'],
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“° Nguá»“n",
            value=source_display,
            inline=True
        )
        
        # Hiá»ƒn thá»‹ ná»™i dung Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
        if len(full_content) > 1000:
            # Chia ná»™i dung thÃ nh 2 pháº§n
            embed.add_field(
                name="ğŸ“„ Ná»™i dung chi tiáº¿t (Pháº§n 1)",
                value=full_content[:1000] + "...",
                inline=False
            )
            
            await ctx.send(embed=embed)
            
            # Táº¡o embed thá»© 2
            embed2 = discord.Embed(
                title=f"ğŸ“– Chi tiáº¿t bÃ i viáº¿t (tiáº¿p theo)",
                color=0x9932cc
            )
            
            embed2.add_field(
                name="ğŸ“„ Ná»™i dung chi tiáº¿t (Pháº§n 2)",
                value=full_content[1000:2000],
                inline=False
            )
            
            embed2.add_field(
                name="ğŸ”— Äá»c bÃ i viáº¿t Ä‘áº§y Ä‘á»§",
                value=f"[Nháº¥n Ä‘á»ƒ Ä‘á»c toÃ n bá»™ bÃ i viáº¿t]({news['link']})",
                inline=False
            )
            
            embed2.set_footer(text=f"ğŸ”’ Bot báº£o máº­t â€¢ Tá»« lá»‡nh: {user_data['command']} â€¢ Tin sá»‘ {news_number}")
            
            await ctx.send(embed=embed2)
            return
        else:
            embed.add_field(
                name="ğŸ“„ Ná»™i dung chi tiáº¿t",
                value=full_content,
                inline=False
            )
        
        embed.add_field(
            name="ğŸ”— Äá»c bÃ i viáº¿t Ä‘áº§y Ä‘á»§",
            value=f"[Nháº¥n Ä‘á»ƒ Ä‘á»c toÃ n bá»™ bÃ i viáº¿t]({news['link']})",
            inline=False
        )
        
        embed.set_footer(text=f"ğŸ”’ Bot báº£o máº­t â€¢ Tá»« lá»‡nh: {user_data['command']} â€¢ Tin sá»‘ {news_number} â€¢ !menu Ä‘á»ƒ xem thÃªm lá»‡nh")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("âŒ Vui lÃ²ng nháº­p sá»‘! VÃ­ dá»¥: `!chitiet 5`")
    except Exception as e:
        await ctx.send(f"âŒ Lá»—i: {str(e)}")

# Alias cho lá»‡nh chitiet
@bot.command(name='cuthe')
async def get_news_detail_alias(ctx, news_number: int):
    """Alias cho lá»‡nh !chitiet"""
    await get_news_detail(ctx, news_number)

@bot.command(name='menu')
async def help_command(ctx):
    """Hiá»ƒn thá»‹ menu lá»‡nh - ÄÃƒ Cáº¬P NHáº¬T Báº¢O Máº¬T"""
    embed = discord.Embed(
        title="ğŸ¤–ğŸ”’ Menu News Bot - Báº£o máº­t & á»”n Ä‘á»‹nh",
        description="Bot tin tá»©c kinh táº¿ Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u vÃ  báº£o máº­t token",
        color=0xff9900
    )
    
    embed.add_field(
        name="ğŸ“° Lá»‡nh chÃ­nh",
        value="""
**!all [trang]** - Tin tá»« táº¥t cáº£ nguá»“n (12 tin/trang)
**!in [trang]** - Tin trong nÆ°á»›c (12 tin/trang)  
**!out [trang]** - Tin quá»‘c táº¿ (12 tin/trang)
**!chitiet [sá»‘]** - Xem ná»™i dung chi tiáº¿t
        """,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ‡»ğŸ‡³ Nguá»“n trong nÆ°á»›c (9 nguá»“n)",
        value="CafeF, CafeBiz, BÃ¡o Äáº§u tÆ°, VnEconomy, VnExpress KD, Thanh NiÃªn, NhÃ¢n DÃ¢n",
        inline=True
    )
    
    embed.add_field(
        name="ğŸŒ Nguá»“n quá»‘c táº¿ (8 nguá»“n)",
        value="Yahoo Finance, Reuters, Bloomberg, MarketWatch, Forbes, Financial Times, Business Insider, The Economist",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ”’ Báº£o máº­t má»›i",
        value="""
âœ… **Token Ä‘Æ°á»£c báº£o vá»‡** - Sá»­ dá»¥ng Environment Variables
âœ… **KhÃ´ng hardcode** - Token khÃ´ng cÃ²n trong source code
âœ… **Deploy an toÃ n** - KhÃ´ng bá»‹ Discord reset token
âœ… **Monitoring tÃ­ch há»£p** - PhÃ¡t hiá»‡n lá»—i nhanh chÃ³ng
        """,
        inline=False
    )
    
    embed.add_field(
        name="ğŸ“‹ HÆ°á»›ng dáº«n sá»­ dá»¥ng",
        value="""
1ï¸âƒ£ GÃµ **!all** Ä‘á»ƒ xem tin má»›i nháº¥t
2ï¸âƒ£ Chá»n sá»‘ tin muá»‘n Ä‘á»c chi tiáº¿t (1-12)
3ï¸âƒ£ GÃµ **!chitiet [sá»‘]** Ä‘á»ƒ xem ná»™i dung Ä‘áº§y Ä‘á»§
4ï¸âƒ£ DÃ¹ng **!all 2**, **!all 3** Ä‘á»ƒ xem trang tiáº¿p theo
        """,
        inline=False
    )
    
    embed.set_footer(text="ğŸ”’ Bot Ä‘Ã£ Ä‘Æ°á»£c báº£o máº­t â€¢ Token an toÃ n â€¢ RSS feeds á»•n Ä‘á»‹nh")
    await ctx.send(embed=embed)

# Cháº¡y bot vá»›i error handling tá»‘t hÆ¡n
if __name__ == "__main__":
    try:
        print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng News Bot báº£o máº­t...")
        print("ğŸ”‘ Äang kiá»ƒm tra token tá»« Environment Variables...")
        
        if TOKEN:
            print("âœ… Token Ä‘Ã£ Ä‘Æ°á»£c táº£i tá»« Environment Variables")
        
        total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
        print(f"ğŸ“Š ÄÃ£ load {total_sources} nguá»“n RSS ÄÃƒ KIá»‚M TRA")
        print(f"ğŸ‡»ğŸ‡³ Trong nÆ°á»›c: {len(RSS_FEEDS['domestic'])} nguá»“n")
        print(f"ğŸŒ Quá»‘c táº¿: {len(RSS_FEEDS['international'])} nguá»“n")
        print("ğŸ¯ LÄ©nh vá»±c: Kinh táº¿, Chá»©ng khoÃ¡n, VÄ© mÃ´, Báº¥t Ä‘á»™ng sáº£n")
        print("ğŸ”’ Bot Ä‘Ã£ Ä‘Æ°á»£c báº£o máº­t token")
        print("âœ… Bot sáºµn sÃ ng nháº­n lá»‡nh!")
        
        bot.run(TOKEN)
        
    except discord.LoginFailure:
        print("âŒ Lá»—i Ä‘Äƒng nháº­p Discord!")
        print("ğŸ”§ Token cÃ³ thá»ƒ khÃ´ng há»£p lá»‡ hoáº·c Ä‘Ã£ bá»‹ reset")
        print("ğŸ”§ Kiá»ƒm tra DISCORD_TOKEN trong Environment Variables")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi cháº¡y bot: {e}")
        print("ğŸ”§ Kiá»ƒm tra káº¿t ná»‘i internet vÃ  Environment Variables")
        
    input("Nháº¥n Enter Ä‘á»ƒ thoÃ¡t...")
