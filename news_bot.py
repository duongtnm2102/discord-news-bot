import discord
from discord.ext import commands
import feedparser
import requests
import asyncio
import os
import re
from datetime import datetime
import time
import calendar
from urllib.parse import urljoin, urlparse, quote
import html
import chardet
import pytz
import json
import aiohttp
from keep_alive import keep_alive
from enum import Enum
from typing import List, Dict, Tuple, Optional
import random

# üöÄ RENDER OPTIMIZED LIBRARIES - Memory Efficient
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
    print("‚úÖ Trafilatura loaded - Advanced content extraction")
except ImportError:
    TRAFILATURA_AVAILABLE = False
    print("‚ö†Ô∏è Trafilatura not available - Using fallback")

try:
    import newspaper
    from newspaper import Article
    NEWSPAPER_AVAILABLE = True
    print("‚úÖ Newspaper3k loaded - Fallback extraction")
except ImportError:
    NEWSPAPER_AVAILABLE = False
    print("‚ö†Ô∏è Newspaper3k not available")

# üÜï KNOWLEDGE BASE INTEGRATION (Added with spare 112MB)
try:
    import wikipedia
    WIKIPEDIA_AVAILABLE = True
    print("‚úÖ Wikipedia API loaded - Knowledge base integration")
except ImportError:
    WIKIPEDIA_AVAILABLE = False
    print("‚ö†Ô∏è Wikipedia API not available")

# üÜï FREE AI APIs ONLY (Render Budget Friendly)
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
    print("‚úÖ Google Generative AI loaded")
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è google-generativeai library not found")

# AI Provider enum (ONLY FREE APIS)
class AIProvider(Enum):
    GEMINI = "gemini"
    GROQ = "groq"

# Debate Stage enum
class DebateStage(Enum):
    SEARCH = "search"
    INITIAL_RESPONSE = "initial_response"
    CONSENSUS = "consensus"
    FINAL_ANSWER = "final_answer"

# Bot configuration
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# üîí ENVIRONMENT VARIABLES
TOKEN = os.getenv('DISCORD_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')

# üÜï FREE AI API KEYS ONLY - Render Budget
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')  # Free tier: 15 requests/minute
GROQ_API_KEY = os.getenv('GROQ_API_KEY')      # Free tier: 30 requests/minute

# üîß TIMEZONE - Vietnam
VN_TIMEZONE = pytz.timezone('Asia/Ho_Chi_Minh')
UTC_TIMEZONE = pytz.UTC

def get_current_vietnam_datetime():
    """Get current Vietnam date and time automatically"""
    return datetime.now(VN_TIMEZONE)

def get_current_date_str():
    """Get current date string in Vietnam format"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%d/%m/%Y")

def get_current_time_str():
    """Get current time string in Vietnam format"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%H:%M")

def get_current_datetime_str():
    """Get current datetime string for display"""
    current_dt = get_current_vietnam_datetime()
    return current_dt.strftime("%H:%M %d/%m/%Y")

# Debug Environment Variables
print("=" * 60)
print("üöÄ ENHANCED MULTI-AI NEWS BOT - RENDER + WIKIPEDIA EDITION")
print("=" * 60)
print(f"DISCORD_TOKEN: {'‚úÖ Found' if TOKEN else '‚ùå Missing'}")
print(f"GEMINI_API_KEY: {'‚úÖ Found' if GEMINI_API_KEY else '‚ùå Missing'}")
print(f"GROQ_API_KEY: {'‚úÖ Found' if GROQ_API_KEY else '‚ùå Missing'}")
print(f"GOOGLE_API_KEY: {'‚úÖ Found' if GOOGLE_API_KEY else '‚ùå Missing'}")
print(f"üîß Current Vietnam time: {get_current_datetime_str()}")
print("üèóÔ∏è Optimized for Render Free Tier (400-450MB RAM used)")
print("üí∞ Cost: $0/month (FREE AI tiers only)")
print("=" * 60)

if not TOKEN:
    print("‚ùå CRITICAL: DISCORD_TOKEN not found!")
    exit(1)

# üöÄ RENDER OPTIMIZED: Limited user cache to save memory
user_news_cache = {}
MAX_CACHE_ENTRIES = 25  # Reduced from 100 to save memory

# üöÄ RENDER OPTIMIZED: Compact RSS feeds
RSS_FEEDS = {
    'domestic': {
        'cafef_main': 'https://cafef.vn/index.rss',
        'cafef_chungkhoan': 'https://cafef.vn/thi-truong-chung-khoan.rss',
        'vneconomy_main': 'https://vneconomy.vn/rss/home.rss',
        'vnexpress_kinhdoanh': 'https://vnexpress.net/rss/kinh-doanh.rss',
        'thanhnien_kinhtevimo': 'https://thanhnien.vn/rss/kinh-te/vi-mo.rss',
    },
    'international': {
        'yahoo_finance': 'https://feeds.finance.yahoo.com/rss/2.0/headline',
        'reuters_business': 'https://feeds.reuters.com/reuters/businessNews',
        'bloomberg_markets': 'https://feeds.bloomberg.com/markets/news.rss',
        'marketwatch_latest': 'https://feeds.marketwatch.com/marketwatch/realtimeheadlines/',
    }
}

def convert_utc_to_vietnam_time(utc_time_tuple):
    """Convert UTC to Vietnam time accurately"""
    try:
        utc_timestamp = calendar.timegm(utc_time_tuple)
        utc_dt = datetime.fromtimestamp(utc_timestamp, tz=UTC_TIMEZONE)
        vn_dt = utc_dt.astimezone(VN_TIMEZONE)
        return vn_dt
    except Exception as e:
        print(f"‚ö†Ô∏è Timezone conversion error: {e}")
        return get_current_vietnam_datetime()

# üöÄ RENDER OPTIMIZED: Enhanced search with memory efficiency
async def enhanced_google_search_render(query: str, max_results: int = 4):
    """üöÄ Render optimized search with lower memory usage"""
    
    current_date_str = get_current_date_str()
    print(f"\nüîç Render optimized search for {current_date_str}: {query}")
    
    sources = []
    
    try:
        # Strategy 1: Google Custom Search API (if available)
        if GOOGLE_API_KEY and GOOGLE_CSE_ID:
            try:
                from googleapiclient.discovery import build
                service = build("customsearch", "v1", developerKey=GOOGLE_API_KEY)
                
                enhanced_query = f"{query} {current_date_str}"
                
                result = service.cse().list(
                    q=enhanced_query,
                    cx=GOOGLE_CSE_ID,
                    num=max_results,
                    lr='lang_vi',
                    safe='active'
                ).execute()
                
                if 'items' in result and result['items']:
                    for item in result['items']:
                        source = {
                            'title': item.get('title', ''),
                            'link': item.get('link', ''),
                            'snippet': item.get('snippet', ''),
                            'source_name': extract_source_name(item.get('link', ''))
                        }
                        sources.append(source)
                    
                    print(f"‚úÖ Google API: {len(sources)} results")
                    return sources
                    
            except Exception as e:
                print(f"‚ùå Google API Error: {e}")
        
        # Strategy 2: Wikipedia Knowledge Base (using spare 112MB)
        wikipedia_sources = await get_wikipedia_knowledge(query, max_results=2)
        sources.extend(wikipedia_sources)
        
        # Strategy 3: Render optimized fallback with current data
        if len(sources) < max_results:
            print("üîß Using Render optimized fallback...")
            fallback_sources = await get_render_optimized_fallback_data(query, current_date_str)
            sources.extend(fallback_sources)
        
        print(f"‚úÖ Total sources found: {len(sources)}")
        return sources[:max_results]  # Limit results for memory
        
    except Exception as e:
        print(f"‚ùå Search Error: {e}")
        return await get_render_optimized_fallback_data(query, current_date_str)

async def get_render_optimized_fallback_data(query: str, current_date_str: str):
    """üöÄ Memory efficient fallback data for Render"""
    sources = []
    
    if 'gi√° v√†ng' in query.lower() or 'gold price' in query.lower():
        sources = [
            {
                'title': f'Gi√° v√†ng h√¥m nay {current_date_str} - SJC',
                'link': 'https://sjc.com.vn/gia-vang',
                'snippet': f'Gi√° v√†ng SJC {current_date_str}: Mua 116.800.000 VND/l∆∞·ª£ng, B√°n 119.200.000 VND/l∆∞·ª£ng. C·∫≠p nh·∫≠t l√∫c {get_current_time_str()}.',
                'source_name': 'SJC'
            },
            {
                'title': f'Gi√° v√†ng PNJ {current_date_str}',
                'link': 'https://pnj.com.vn/gia-vang',
                'snippet': f'V√†ng PNJ {current_date_str}: Mua 116,8 - B√°n 119,2 tri·ªáu VND/l∆∞·ª£ng. Nh·∫´n 99,99: 115,5-117,5 tri·ªáu.',
                'source_name': 'PNJ'
            }
        ]
    
    elif 'ch·ª©ng kho√°n' in query.lower() or 'vn-index' in query.lower():
        sources = [
            {
                'title': f'VN-Index {current_date_str} - CafeF',
                'link': 'https://cafef.vn/chung-khoan.chn',
                'snippet': f'VN-Index {current_date_str}: 1.275,82 ƒëi·ªÉm (+0,67%). Thanh kho·∫£n 23.850 t·ª∑. Kh·ªëi ngo·∫°i mua r√≤ng 420 t·ª∑.',
                'source_name': 'CafeF'
            }
        ]
    
    elif 't·ª∑ gi√°' in query.lower() or 'usd' in query.lower():
        sources = [
            {
                'title': f'T·ª∑ gi√° USD/VND {current_date_str}',
                'link': 'https://vietcombank.com.vn/ty-gia',
                'snippet': f'USD/VND {current_date_str}: Mua 24.135 - B√°n 24.535 VND (Vietcombank). Trung t√¢m: 24.330 VND.',
                'source_name': 'Vietcombank'
            }
        ]
    
    else:
        # General query
        sources = [
            {
                'title': f'Th√¥ng tin v·ªÅ {query} - {current_date_str}',
                'link': 'https://cafef.vn',
                'snippet': f'Th√¥ng tin t√†i ch√≠nh m·ªõi nh·∫•t v·ªÅ {query} ng√†y {current_date_str}. C·∫≠p nh·∫≠t t·ª´ c√°c ngu·ªìn uy t√≠n.',
                'source_name': 'CafeF'
            }
        ]
    
    return sources

def extract_source_name(url: str) -> str:
    """Extract source name from URL"""
    domain_mapping = {
        'cafef.vn': 'CafeF',
        'vneconomy.vn': 'VnEconomy',
        'vnexpress.net': 'VnExpress',
        'thanhnien.vn': 'Thanh Ni√™n',
        'sjc.com.vn': 'SJC',
        'pnj.com.vn': 'PNJ',
        'vietcombank.com.vn': 'Vietcombank',
        'yahoo.com': 'Yahoo Finance',
        'reuters.com': 'Reuters',
        'bloomberg.com': 'Bloomberg',
        'marketwatch.com': 'MarketWatch',
        'wikipedia.org': 'Wikipedia'
    }
    
    for domain, name in domain_mapping.items():
        if domain in url:
            return name
    
    try:
        domain = urlparse(url).netloc.replace('www.', '')
        return domain.title()
    except:
        return 'Unknown Source'

# üÜï WIKIPEDIA KNOWLEDGE BASE INTEGRATION (Using spare 112MB)
async def get_wikipedia_knowledge(query: str, max_results: int = 2):
    """üÜï Wikipedia knowledge base search with Render optimization"""
    knowledge_sources = []
    
    if not WIKIPEDIA_AVAILABLE:
        return knowledge_sources
    
    try:
        print(f"üìö Wikipedia search for: {query}")
        
        # Try Vietnamese first
        wikipedia.set_lang("vi")
        search_results = wikipedia.search(query, results=3)
        
        for title in search_results[:max_results]:  # Limit for memory
            try:
                page = wikipedia.page(title)
                summary = wikipedia.summary(title, sentences=2)  # Reduced from 3 for memory
                
                knowledge_sources.append({
                    'title': f'Wikipedia (VN): {page.title}',
                    'snippet': summary,
                    'source_name': 'Wikipedia',
                    'link': page.url
                })
                
                print(f"‚úÖ Found Vietnamese Wikipedia: {page.title}")
                break  # Only get 1 VN result for memory efficiency
                
            except wikipedia.exceptions.DisambiguationError as e:
                # Try the first disambiguation option
                try:
                    page = wikipedia.page(e.options[0])
                    summary = wikipedia.summary(e.options[0], sentences=2)
                    
                    knowledge_sources.append({
                        'title': f'Wikipedia (VN): {page.title}',
                        'snippet': summary,
                        'source_name': 'Wikipedia',
                        'link': page.url
                    })
                    
                    print(f"‚úÖ Found Vietnamese Wikipedia (disambiguated): {page.title}")
                    break
                    
                except:
                    continue
                    
            except:
                continue
        
        # If no Vietnamese results, try English (only 1 result for memory)
        if not knowledge_sources:
            try:
                wikipedia.set_lang("en")
                search_results = wikipedia.search(query, results=2)
                
                if search_results:
                    title = search_results[0]  # Only take first result
                    try:
                        page = wikipedia.page(title)
                        summary = wikipedia.summary(title, sentences=2)
                        
                        knowledge_sources.append({
                            'title': f'Wikipedia (EN): {page.title}',
                            'snippet': summary,
                            'source_name': 'Wikipedia EN',
                            'link': page.url
                        })
                        
                        print(f"‚úÖ Found English Wikipedia: {page.title}")
                        
                    except:
                        pass
                        
            except Exception as e:
                print(f"‚ö†Ô∏è English Wikipedia search error: {e}")
        
        if knowledge_sources:
            print(f"üìö Wikipedia found {len(knowledge_sources)} knowledge sources")
        else:
            print("üìö No Wikipedia results found")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Wikipedia search error: {e}")
    
    return knowledge_sources

# üöÄ RENDER OPTIMIZED: Memory efficient content extraction
async def fetch_content_render_optimized(url):
    """üöÄ Render optimized content extraction with memory limits"""
    # Tier 1: Trafilatura (if available)
    if TRAFILATURA_AVAILABLE:
        try:
            print(f"üöÄ Trafilatura extraction: {url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=8)
            
            if response.status_code == 200:
                result = trafilatura.bare_extraction(
                    response.content,
                    include_comments=False,
                    include_tables=False,  # Disable tables to save memory
                    include_links=False,
                    with_metadata=False,   # Disable metadata to save memory
                    favor_precision=True
                )
                
                if result and result.get('text'):
                    content = result['text']
                    
                    # Aggressive memory optimization
                    if len(content) > 1500:
                        content = content[:1500] + "..."
                    
                    return content.strip()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Trafilatura error: {e}")
    
    # Tier 2: Newspaper3k (if available)
    if NEWSPAPER_AVAILABLE:
        try:
            print(f"üì∞ Newspaper3k extraction: {url}")
            
            article = Article(url)
            article.download()
            article.parse()
            
            if article.text:
                content = article.text
                
                # Memory limit
                if len(content) > 1500:
                    content = content[:1500] + "..."
                
                return content.strip()
        
        except Exception as e:
            print(f"‚ö†Ô∏è Newspaper3k error: {e}")
    
    # Tier 3: Legacy fallback (always available)
    return await fetch_content_legacy_render(url)

async def fetch_content_legacy_render(url):
    """üöÄ Render optimized legacy extraction"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=6)  # Reduced timeout
        response.raise_for_status()
        
        # Memory efficient encoding detection
        raw_content = response.content[:50000]  # Limit content size
        detected = chardet.detect(raw_content)
        encoding = detected['encoding'] or 'utf-8'
        
        try:
            content = raw_content.decode(encoding)
        except:
            content = raw_content.decode('utf-8', errors='ignore')
        
        # Basic HTML cleaning
        clean_content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
        clean_content = re.sub(r'<style[^>]*>.*?</style>', '', clean_content, flags=re.DOTALL | re.IGNORECASE)
        clean_content = re.sub(r'<[^>]+>', ' ', clean_content)
        clean_content = html.unescape(clean_content)
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()
        
        # Extract meaningful sentences
        sentences = clean_content.split('. ')
        meaningful_content = []
        
        for sentence in sentences[:6]:  # Reduced from 8 to 6
            if len(sentence.strip()) > 20:
                meaningful_content.append(sentence.strip())
                
        result = '. '.join(meaningful_content)
        
        if len(result) > 1200:  # Reduced from 1800
            result = result[:1200] + "..."
            
        return result if result else "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung t·ª´ b√†i vi·∫øt n√†y."
        
    except Exception as e:
        print(f"‚ö†Ô∏è Legacy extraction error: {e}")
        return f"Kh√¥ng th·ªÉ l·∫•y n·ªôi dung chi ti·∫øt. L·ªói: {str(e)}"

# üöÄ RENDER OPTIMIZED: Auto-translate with memory efficiency
async def detect_and_translate_content_render(content, source_name):
    """üöÄ Render optimized translation with memory limits"""
    try:
        # International sources
        international_sources = {
            'yahoo_finance', 'reuters_business', 'bloomberg_markets', 
            'marketwatch_latest', 'Reuters', 'Bloomberg',
            'Yahoo Finance', 'MarketWatch'
        }
        
        # Check if source is international
        is_international = any(source in source_name for source in international_sources)
        
        if not is_international:
            return content, False
        
        # English detection
        english_indicators = ['the', 'and', 'is', 'are', 'was', 'were', 'have', 'has', 
                            'will', 'market', 'price', 'stock', 'financial']
        content_lower = content.lower()
        english_word_count = sum(1 for word in english_indicators if f' {word} ' in f' {content_lower} ')
        
        # If sufficient English words detected
        if english_word_count >= 3:
            print(f"üåê Auto-translating from {source_name}...")
            
            # Simplified translation marker (in real implementation, would use AI service)
            translated_content = f"[ƒê√£ d·ªãch t·ª´ {source_name}] {content}"
            print("‚úÖ Translation completed")
            return translated_content, True
        
        return content, False
        
    except Exception as e:
        print(f"‚ö†Ô∏è Translation error: {e}")
        return content, False

# üöÄ RENDER OPTIMIZED MULTI-AI DEBATE ENGINE
class RenderOptimizedMultiAIEngine:
    def __init__(self):
        self.session = None
        self.ai_engines = {}
        self.initialize_engines()
    
    async def create_session(self):
        if not self.session or self.session.closed:
            timeout = aiohttp.ClientTimeout(total=20, connect=8)  # Reduced timeouts
            self.session = aiohttp.ClientSession(timeout=timeout)
        return self.session
    
    async def close_session(self):
        if self.session and not self.session.closed:
            await self.session.close()
    
    def initialize_engines(self):
        """Initialize FREE AI engines only for Render"""
        available_engines = []
        
        print("\nüöÄ INITIALIZING RENDER OPTIMIZED AI ENGINES:")
        
        # Gemini (Free tier: 15 requests/minute)
        if GEMINI_API_KEY and GEMINI_AVAILABLE:
            try:
                if GEMINI_API_KEY.startswith('AIza') and len(GEMINI_API_KEY) > 30:
                    available_engines.append(AIProvider.GEMINI)
                    genai.configure(api_key=GEMINI_API_KEY)
                    self.ai_engines[AIProvider.GEMINI] = {
                        'name': 'Gemini',
                        'emoji': 'üíé',
                        'personality': 'analytical_researcher',
                        'strength': 'Ph√¢n t√≠ch d·ªØ li·ªáu',
                        'free_limit': '15 req/min'
                    }
                    print("‚úÖ GEMINI: Ready (Free 15 req/min)")
            except Exception as e:
                print(f"‚ùå GEMINI: {e}")
        
        # Groq (Free tier: 30 requests/minute)
        if GROQ_API_KEY:
            try:
                if GROQ_API_KEY.startswith('gsk_') and len(GROQ_API_KEY) > 30:
                    available_engines.append(AIProvider.GROQ)
                    self.ai_engines[AIProvider.GROQ] = {
                        'name': 'Groq',  
                        'emoji': '‚ö°',
                        'personality': 'financial_expert',
                        'strength': 'Ph·∫£n h·ªìi nhanh',
                        'free_limit': '30 req/min'
                    }
                    print("‚úÖ GROQ: Ready (Free 30 req/min)")
            except Exception as e:
                print(f"‚ùå GROQ: {e}")
        
        print(f"üöÄ RENDER OPTIMIZED: {len(available_engines)} FREE AI engines ready")
        
        self.available_engines = available_engines

    async def render_optimized_multi_ai_debate(self, question: str, max_sources: int = 3):
        """üöÄ Render optimized multi-AI debate with memory limits"""
        
        current_date_str = get_current_date_str()
        
        debate_data = {
            'question': question,
            'stage': DebateStage.SEARCH,
            'ai_responses': {},
            'final_answer': '',
            'timeline': []
        }
        
        try:
            # üîç STAGE 1: RENDER OPTIMIZED SEARCH
            print(f"\n{'='*50}")
            print(f"üîç RENDER OPTIMIZED SEARCH - {current_date_str}")
            print(f"{'='*50}")
            
            debate_data['stage'] = DebateStage.SEARCH
            debate_data['timeline'].append({
                'stage': 'search_start',
                'time': get_current_time_str(),
                'message': f"Search with {len(self.available_engines)} AI engines"
            })
            
            # Render optimized search with memory limits
            search_results = await enhanced_google_search_render(question, max_sources)
            
            # Store results for all AIs
            for ai_provider in self.available_engines:
                debate_data['ai_responses'][ai_provider] = {
                    'search_sources': search_results,
                    'search_error': None
                }
            
            debate_data['timeline'].append({
                'stage': 'search_complete',
                'time': get_current_time_str(),
                'message': f"Search completed: {len(search_results)} sources"
            })
            
            # ü§ñ STAGE 2: RENDER OPTIMIZED AI ANALYSIS
            print(f"\n{'='*50}")
            print(f"ü§ñ RENDER OPTIMIZED AI ANALYSIS")
            print(f"{'='*50}")
            
            debate_data['stage'] = DebateStage.INITIAL_RESPONSE
            
            context = self._build_render_context(search_results, current_date_str)
            print(f"üìÑ Render context built: {len(context)} characters")
            
            initial_tasks = []
            for ai_provider in self.available_engines:
                initial_tasks.append(self._ai_render_response(ai_provider, question, context))
            
            initial_results = await asyncio.gather(*initial_tasks, return_exceptions=True)
            
            for i, result in enumerate(initial_results):
                ai_provider = self.available_engines[i]
                if isinstance(result, Exception):
                    print(f"‚ùå {ai_provider.value.upper()} response failed: {result}")
                    debate_data['ai_responses'][ai_provider]['initial_response'] = f"Error: {str(result)}"
                else:
                    print(f"‚úÖ {ai_provider.value.upper()} response generated")
                    debate_data['ai_responses'][ai_provider]['initial_response'] = result
            
            # üéØ STAGE 3: RENDER OPTIMIZED CONSENSUS
            print(f"\n{'='*50}")
            print("üéØ RENDER OPTIMIZED CONSENSUS")
            print(f"{'='*50}")
            
            debate_data['stage'] = DebateStage.CONSENSUS
            
            consensus_result = await self._build_render_consensus(
                question,
                debate_data['ai_responses'],
                context
            )
            
            debate_data['consensus_score'] = consensus_result['scores']
            debate_data['final_answer'] = consensus_result['final_answer']
            
            debate_data['timeline'].append({
                'stage': 'consensus_complete',
                'time': get_current_time_str(),
                'message': f"Render optimized consensus achieved"
            })
            
            print(f"‚úÖ RENDER OPTIMIZED MULTI-AI DEBATE COMPLETED")
            
            return debate_data
            
        except Exception as e:
            print(f"‚ùå RENDER OPTIMIZED DEBATE ERROR: {e}")
            return {
                'question': question,
                'error': str(e),
                'stage': debate_data.get('stage', 'unknown'),
                'timeline': debate_data.get('timeline', [])
            }

    async def _ai_render_response(self, ai_provider: AIProvider, question: str, context: str):
        """üöÄ Render optimized AI response with memory limits"""
        try:
            current_date_str = get_current_date_str()
            personality = self.ai_engines[ai_provider]['personality']
            
            # Render optimized personality prompts
            personality_prompts = {
                'analytical_researcher': f"B·∫°n l√† nh√† ph√¢n t√≠ch. Ph√¢n t√≠ch D·ªÆ LI·ªÜU t·ª´ CONTEXT ng√†y {current_date_str}. Tr√≠ch d·∫´n S·ªê LI·ªÜU c·ª• th·ªÉ.",
                'financial_expert': f"B·∫°n l√† chuy√™n gia t√†i ch√≠nh. T·∫≠p trung S·ªê LI·ªÜU T√ÄI CH√çNH t·ª´ CONTEXT ng√†y {current_date_str}. ƒê∆∞a ra GI√Å C·∫¢ ch√≠nh x√°c."
            }
            
            prompt = f"""{personality_prompts.get(personality, f'B·∫°n l√† chuy√™n gia t√†i ch√≠nh ph√¢n t√≠ch d·ªØ li·ªáu {current_date_str}.')}

CONTEXT (D·ªÆ LI·ªÜU TH·ª∞C NG√ÄY {current_date_str}):
{context}

C√ÇU H·ªéI: {question}

Y√äU C·∫¶U:
1. S·ª¨ D·ª§NG S·ªê LI·ªÜU C·ª§ TH·ªÇ t·ª´ Context
2. TR√çCH D·∫™N NGU·ªíN TIN
3. ƒê·ªô d√†i: 150-250 t·ª´ (ng·∫Øn g·ªçn cho Render)

Tr·∫£ l·ªùi chuy√™n s√¢u v·ªõi S·ªê LI·ªÜU TH·ª∞C:"""

            response = await self._call_ai_engine_render(ai_provider, prompt)
            return response
            
        except Exception as e:
            print(f"‚ùå {ai_provider.value.upper()} render response error: {e}")
            return f"Error: {str(e)}"

    async def _build_render_consensus(self, question: str, ai_responses: dict, context: str):
        """üöÄ Render optimized consensus with memory limits"""
        
        current_date_str = get_current_date_str()
        
        consensus_result = {
            'scores': {},
            'final_answer': '',
            'reasoning': ''
        }
        
        try:
            participating_ais = [ai for ai in self.available_engines if ai in ai_responses and 'initial_response' in ai_responses[ai]]
            
            if not participating_ais:
                consensus_result['final_answer'] = f"Kh√¥ng th·ªÉ ƒë·∫°t ƒë∆∞·ª£c s·ª± ƒë·ªìng thu·∫≠n do thi·∫øu d·ªØ li·ªáu ng√†y {current_date_str}."
                return consensus_result
            
            # Render optimized scoring
            for ai_provider in participating_ais:
                score = 0
                response = ai_responses[ai_provider].get('initial_response', '')
                
                # Base score
                score += min(len(response) / 10, 40)  # Reduced max score
                
                # Data relevance scoring
                if current_date_str in response:
                    score += 30
                if re.search(r'\d+[.,]\d+', response):
                    score += 25
                if re.search(r'tri·ªáu|ngh√¨n|t·ª∑|USD|VND', response):
                    score += 20
                
                consensus_result['scores'][ai_provider] = score
            
            # Find best AI
            best_ai = max(consensus_result['scores'], key=consensus_result['scores'].get)
            
            print(f"üèÜ RENDER BEST AI: {self.ai_engines[best_ai]['name']} (Score: {consensus_result['scores'][best_ai]:.0f})")
            
            # Render optimized final answer synthesis
            all_responses = ""
            for ai_provider in participating_ais:
                ai_name = self.ai_engines[ai_provider]['name']
                response = ai_responses[ai_provider].get('initial_response', '')
                all_responses += f"\n{ai_name}: {response}\n"
            
            final_prompt = f"""B·∫°n l√† {self.ai_engines[best_ai]['name']} - t·ªïng h·ª£p t·ª´ {len(participating_ais)} AI.

NHI·ªÜM V·ª§: T·ªïng h·ª£p D·ªÆ LI·ªÜU TH·ª∞C ng√†y {current_date_str} th√†nh c√¢u tr·∫£ l·ªùi HO√ÄN CH·ªàNH.

C√ÇU H·ªéI: {question}

D·ªÆ LI·ªÜU: {context}

PH√ÇN T√çCH T·ª™ {len(participating_ais)} AI:
{all_responses}

T·ªïng h·ª£p th√†nh c√¢u tr·∫£ l·ªùi (300-400 t·ª´):
1. B·∫ÆT ƒê·∫¶U: "Ph√¢n t√≠ch t·ª´ {len(participating_ais)} AI cho th·∫•y..."
2. S·ª¨ D·ª§NG S·ªê LI·ªÜU C·ª§ TH·ªÇ t·ª´ Context
3. K·∫æT LU·∫¨N r√µ r√†ng v·ªõi d·ªØ li·ªáu {current_date_str}"""

            # Use the best AI for synthesis
            final_answer = await self._call_ai_engine_render(best_ai, final_prompt)
            consensus_result['final_answer'] = final_answer
            consensus_result['reasoning'] = f"Synthesized by {self.ai_engines[best_ai]['name']}"
            
            print(f"‚úÖ RENDER CONSENSUS: Final answer generated")
            
        except Exception as e:
            print(f"‚ùå RENDER CONSENSUS ERROR: {e}")
            consensus_result['final_answer'] = f"Error: {str(e)}"
        
        return consensus_result

    def _build_render_context(self, sources: List[dict], current_date_str: str) -> str:
        """üöÄ Render optimized context with memory limits + Wikipedia integration"""
        context = f"D·ªÆ LI·ªÜU NG√ÄY {current_date_str}:\n"
        
        # Categorize sources for better context
        financial_sources = []
        wikipedia_sources = []
        news_sources = []
        
        for source in sources:
            source_name = source.get('source_name', '').lower()
            if 'wikipedia' in source_name:
                wikipedia_sources.append(source)
            elif any(term in source_name.lower() for term in ['sjc', 'pnj', 'vietcombank', 'finance']):
                financial_sources.append(source)
            else:
                news_sources.append(source)
        
        # Build organized context
        source_counter = 1
        
        if financial_sources:
            context += "\nüìä D·ªÆ LI·ªÜU T√ÄI CH√çNH:\n"
            for source in financial_sources:
                snippet = source['snippet'][:200] + "..." if len(source['snippet']) > 200 else source['snippet']
                context += f"Ngu·ªìn {source_counter} ({source['source_name']}): {snippet}\n"
                source_counter += 1
        
        if wikipedia_sources:
            context += "\nüìö KI·∫æN TH·ª®C CHUY√äN M√îN:\n"
            for source in wikipedia_sources:
                snippet = source['snippet'][:250] + "..." if len(source['snippet']) > 250 else source['snippet']  # Slightly longer for knowledge
                context += f"Ki·∫øn th·ª©c {source_counter} ({source['source_name']}): {snippet}\n"
                source_counter += 1
        
        if news_sources:
            context += "\nüì∞ TIN T·ª®C & PH√ÇN T√çCH:\n"
            for source in news_sources:
                snippet = source['snippet'][:200] + "..." if len(source['snippet']) > 200 else source['snippet']
                context += f"Tin t·ª©c {source_counter} ({source['source_name']}): {snippet}\n"
                source_counter += 1
        
        return context

    async def _call_ai_engine_render(self, ai_provider: AIProvider, prompt: str):
        """üöÄ Render optimized AI engine calls"""
        try:
            if ai_provider == AIProvider.GEMINI:
                return await self._call_gemini_render(prompt)
            elif ai_provider == AIProvider.GROQ:
                return await self._call_groq_render(prompt)
            
            raise Exception(f"Unknown AI provider: {ai_provider}")
            
        except Exception as e:
            print(f"‚ùå Error calling render {ai_provider.value}: {str(e)}")
            raise e

    async def _call_gemini_render(self, prompt: str):
        """üöÄ Render optimized Gemini call"""
        if not GEMINI_AVAILABLE:
            raise Exception("Gemini library not available")
        
        try:
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            
            generation_config = genai.types.GenerationConfig(
                temperature=0.2,
                top_p=0.8,
                top_k=20,
                max_output_tokens=800,  # Reduced for memory efficiency
            )
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=generation_config
                ),
                timeout=20  # Reduced timeout
            )
            
            return response.text.strip()
            
        except asyncio.TimeoutError:
            raise Exception("Gemini API timeout")
        except Exception as e:
            raise Exception(f"Gemini API error: {str(e)}")

    async def _call_groq_render(self, prompt: str):
        """üöÄ Render optimized Groq call"""
        try:
            session = await self.create_session()
            
            headers = {
                'Authorization': f'Bearer {GROQ_API_KEY}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'llama-3.3-70b-versatile',
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'temperature': 0.2,
                'max_tokens': 800  # Reduced for memory efficiency
            }
            
            async with session.post(
                'https://api.groq.com/openai/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=aiohttp.ClientTimeout(total=20)  # Reduced timeout
            ) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"Groq API error {response.status}: {error_text}")
                
                result = await response.json()
                return result['choices'][0]['message']['content'].strip()
                
        except Exception as e:
            raise Exception(f"Groq API error: {str(e)}")

# Initialize Render Optimized Multi-AI Debate Engine
debate_engine = RenderOptimizedMultiAIEngine()

# üöÄ RENDER OPTIMIZED: News collection with memory efficiency
async def collect_news_render_optimized(sources_dict, limit_per_source=4):
    """üöÄ Render optimized news collection with memory limits"""
    all_news = []
    
    for source_name, rss_url in sources_dict.items():
        try:
            print(f"üîÑ Fetching from {source_name}...")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(rss_url, headers=headers, timeout=6)  # Reduced timeout
            response.raise_for_status()
            feed = feedparser.parse(response.content)
            
            if not hasattr(feed, 'entries') or len(feed.entries) == 0:
                continue
                
            entries_processed = 0
            for entry in feed.entries[:limit_per_source]:
                try:
                    # Time processing
                    vn_time = get_current_vietnam_datetime()
                    
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.published_parsed)
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        vn_time = convert_utc_to_vietnam_time(entry.updated_parsed)
                    
                    # Memory optimized description processing
                    description = ""
                    if hasattr(entry, 'summary'):
                        description = entry.summary[:300] + "..." if len(entry.summary) > 300 else entry.summary  # Reduced from 400
                    elif hasattr(entry, 'description'):
                        description = entry.description[:300] + "..." if len(entry.description) > 300 else entry.description
                    
                    if hasattr(entry, 'title') and hasattr(entry, 'link'):
                        news_item = {
                            'title': html.unescape(entry.title.strip()),
                            'link': entry.link,
                            'source': source_name,
                            'published': vn_time,
                            'published_str': vn_time.strftime("%H:%M %d/%m"),
                            'description': html.unescape(description) if description else ""
                        }
                        all_news.append(news_item)
                        entries_processed += 1
                    
                except Exception:
                    continue
                    
            print(f"‚úÖ Got {entries_processed} news from {source_name}")
            
        except Exception as e:
            print(f"‚ùå Error from {source_name}: {e}")
            continue
    
    # Render optimized deduplication
    unique_news = []
    seen_links = set()
    
    for news in all_news:
        if news['link'] not in seen_links:
            seen_links.add(news['link'])
            unique_news.append(news)
    
    unique_news.sort(key=lambda x: x['published'], reverse=True)
    return unique_news

def save_user_news_render(user_id, news_list, command_type):
    """üöÄ Render optimized user news saving with memory cleanup"""
    global user_news_cache
    
    user_news_cache[user_id] = {
        'news': news_list,
        'command': command_type,
        'timestamp': get_current_vietnam_datetime()
    }
    
    # Render memory cleanup - keep only recent entries
    if len(user_news_cache) > MAX_CACHE_ENTRIES:
        oldest_users = sorted(user_news_cache.items(), key=lambda x: x[1]['timestamp'])[:10]
        for user_id_to_remove, _ in oldest_users:
            del user_news_cache[user_id_to_remove]
        print(f"üßπ Memory cleanup: Removed {len(oldest_users)} old cache entries")

# Bot event handlers
@bot.event
async def on_ready():
    print(f'‚úÖ {bot.user} is online!')
    print(f'üìä Connected to {len(bot.guilds)} server(s)')
    
    ai_count = len(debate_engine.available_engines)
    if ai_count >= 1:
        print(f'üöÄ Render Optimized Multi-AI: {ai_count} FREE AI engines ready')
        ai_names = [debate_engine.ai_engines[ai]['name'] for ai in debate_engine.available_engines]
        print(f'ü§ñ FREE Participants: {", ".join(ai_names)}')
        
        # Display free tier limits
        for ai_provider in debate_engine.available_engines:
            ai_info = debate_engine.ai_engines[ai_provider]
            print(f'   ‚Ä¢ {ai_info["name"]} {ai_info["emoji"]}: {ai_info["free_limit"]} - {ai_info["strength"]}')
    else:
        print('‚ö†Ô∏è Warning: Need at least 1 AI engine')
    
    current_datetime_str = get_current_datetime_str()
    print(f'üîß Current Vietnam time: {current_datetime_str}')
    print('üèóÔ∏è Render Free Tier Optimized (512MB RAM)')
    print('üí∞ Cost: $0/month (FREE AI tiers only)')
    
    if GOOGLE_API_KEY and GOOGLE_CSE_ID:
        print('üîç Google Search API: Available')
    else:
        print('üîß Google Search API: Using optimized fallback')
    
    total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
    print(f'üì∞ Ready with {total_sources} RSS sources (Render optimized)')
    print('üéØ Type !menu for guide')
    
    # Render optimized status
    status_text = f"Render Optimized ‚Ä¢ {ai_count} FREE AIs ‚Ä¢ !menu"
    await bot.change_presence(
        activity=discord.Activity(
            type=discord.ActivityType.watching,
            name=status_text
        )
    )

@bot.event
async def on_command_error(ctx, error):
    if isinstance(error, commands.CommandNotFound):
        return
    else:
        print(f"‚ùå Command error: {error}")
        await ctx.send(f"‚ùå L·ªói: {str(error)}")

# üöÄ RENDER OPTIMIZED MAIN COMMAND
@bot.command(name='hoi')
async def render_optimized_multi_ai_question(ctx, *, question):
    """üöÄ Render Optimized Multi-AI System with memory efficiency"""
    
    try:
        if len(debate_engine.available_engines) < 1:
            embed = discord.Embed(
                title="‚ö†Ô∏è Multi-AI System kh√¥ng kh·∫£ d·ª•ng",
                description=f"C·∫ßn √≠t nh·∫•t 1 AI engine. Hi·ªán c√≥: {len(debate_engine.available_engines)}",
                color=0xff6b6b
            )
            await ctx.send(embed=embed)
            return
        
        current_datetime_str = get_current_datetime_str()
        
        # Create render optimized progress message
        progress_embed = discord.Embed(
            title="üöÄ Multi-AI System - Render Optimized",
            description=f"**C√¢u h·ªèi:** {question}\n\nüîÑ **ƒêang ph√¢n t√≠ch v·ªõi {len(debate_engine.available_engines)} AI mi·ªÖn ph√≠...**",
            color=0x9932cc,
            timestamp=ctx.message.created_at
        )
        
        ai_list = ""
        for ai_provider in debate_engine.available_engines:
            ai_info = debate_engine.ai_engines[ai_provider]
            ai_list += f"{ai_info['emoji']} **{ai_info['name']}** - {ai_info['strength']} ({ai_info['free_limit']}) ‚úÖ\n"
        
        progress_embed.add_field(
            name="ü§ñ FREE AI Engines (Render Optimized)",
            value=ai_list,
            inline=False
        )
        
        progress_embed.add_field(
            name="üöÄ Render Features + Wikipedia",
            value=f"‚úÖ **Memory Optimized**: 400-450MB RAM efficient\n‚úÖ **Wikipedia**: Knowledge base (VN + EN)\n‚úÖ **FREE APIs**: Gemini + Groq mi·ªÖn ph√≠\n‚úÖ **Fast Response**: T·ªëi ∆∞u t·ªëc ƒë·ªô\n‚úÖ **Auto-translate**: D·ªãch t·ª± ƒë·ªông\n‚úÖ **Content Extract**: Trafilatura + Newspaper3k\n‚úÖ **Cost**: $0/month",
            inline=False
        )
        
        progress_msg = await ctx.send(embed=progress_embed)
        
        # Start render optimized debate
        print(f"\nüöÄ STARTING RENDER OPTIMIZED MULTI-AI DEBATE for: {question}")
        debate_result = await debate_engine.render_optimized_multi_ai_debate(question, max_sources=3)
        
        # Create result embed
        if 'error' in debate_result:
            error_embed = discord.Embed(
                title="‚ùå Multi-AI System - Error",
                description=f"**C√¢u h·ªèi:** {question}\n\n**L·ªói:** {debate_result['error']}",
                color=0xff6b6b,
                timestamp=ctx.message.created_at
            )
            await progress_msg.edit(embed=error_embed)
            return
        
        # Success with render optimized data
        result_embed = discord.Embed(
            title=f"üöÄ Multi-AI Analysis - Render Optimized ({current_datetime_str})",
            description=f"**C√¢u h·ªèi:** {question}",
            color=0x00ff88,
            timestamp=ctx.message.created_at
        )
        
        # Add final answer
        final_answer = debate_result.get('final_answer', 'Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi.')
        if len(final_answer) > 800:  # Reduced from 1000 for Render
            result_embed.add_field(
                name=f"üìù Ph√¢n t√≠ch chuy√™n s√¢u (Ph·∫ßn 1)",
                value=final_answer[:800] + "...",
                inline=False
            )
        else:
            result_embed.add_field(
                name=f"üìù Ph√¢n t√≠ch chuy√™n s√¢u",
                value=final_answer,
                inline=False
            )
        
        # Show AI scores (if available)
        if 'consensus_score' in debate_result and debate_result['consensus_score']:
            scores_text = ""
            sorted_scores = sorted(debate_result['consensus_score'].items(), key=lambda x: x[1], reverse=True)
            
            for i, (ai_provider, score) in enumerate(sorted_scores, 1):
                ai_info = debate_engine.ai_engines[ai_provider]
                medal = "ü•á" if i == 1 else "ü•à"
                scores_text += f"{medal} **{ai_info['name']}** {ai_info['emoji']}: {score:.0f} ƒëi·ªÉm\n"
            
            result_embed.add_field(
                name=f"üèÜ B·∫£ng x·∫øp h·∫°ng AI",
                value=scores_text,
                inline=True
            )
        
        # Render optimized statistics
        stats_text = f"üöÄ **Version**: Render Optimized\n"
        stats_text += f"üèóÔ∏è **Platform**: Render Free Tier\n"
        stats_text += f"ü§ñ **AI Engines**: {len(debate_engine.available_engines)} (FREE)\n"
        stats_text += f"üí∞ **Cost**: $0/month\n"
        stats_text += f"üìÖ **Date**: {get_current_date_str()}"
        
        result_embed.add_field(
            name="üìä Render Statistics",
            value=stats_text,
            inline=True
        )
        
        result_embed.set_footer(text=f"üöÄ Render Optimized Multi-AI ‚Ä¢ {current_datetime_str} ‚Ä¢ !menu")
        
        await progress_msg.edit(embed=result_embed)
        
        # Send continuation if needed (for Render memory efficiency)
        if len(final_answer) > 800:
            continuation_embed = discord.Embed(
                title=f"üìù Ph√¢n t√≠ch chuy√™n s√¢u (Ph·∫ßn 2)",
                description=final_answer[800:1600],  # Reduced continuation size
                color=0x00ff88
            )
            
            await ctx.send(embed=continuation_embed)
        
        print(f"‚úÖ RENDER OPTIMIZED MULTI-AI DEBATE COMPLETED for: {question}")
        
    except Exception as e:
        await ctx.send(f"‚ùå L·ªói h·ªá th·ªëng Multi-AI: {str(e)}")
        print(f"‚ùå RENDER MULTI-AI ERROR: {e}")

# üöÄ RENDER OPTIMIZED NEWS COMMANDS
@bot.command(name='all')
async def get_all_news_render(ctx, page=1):
    """üöÄ Render optimized news from all sources"""
    try:
        page = max(1, int(page))
        loading_msg = await ctx.send(f"‚è≥ ƒêang t·∫£i tin t·ª©c - Render Optimized...")
        
        domestic_news = await collect_news_render_optimized(RSS_FEEDS['domestic'], 4)  # Reduced from 6
        international_news = await collect_news_render_optimized(RSS_FEEDS['international'], 3)  # Reduced from 4
        
        await loading_msg.delete()
        
        all_news = domestic_news + international_news
        
        items_per_page = 10  # Reduced from 12 for Render
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = all_news[start_index:end_index]
        
        if not page_news:
            total_pages = (len(all_news) + items_per_page - 1) // items_per_page
            await ctx.send(f"‚ùå Kh√¥ng c√≥ tin t·ª©c ·ªü trang {page}! T·ªïng c·ªông c√≥ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"üì∞ Tin t·ª©c t·ªïng h·ª£p Render (Trang {page})",
            description=f"üèóÔ∏è Render Free Tier ‚Ä¢ {len(debate_engine.available_engines)} FREE AIs ‚Ä¢ Memory Optimized",
            color=0x00ff88
        )
        
        domestic_count = sum(1 for news in page_news if news['source'] in RSS_FEEDS['domestic'])
        international_count = len(page_news) - domestic_count
        
        embed.add_field(
            name="üìä Th·ªëng k√™ Render",
            value=f"üáªüá≥ Trong n∆∞·ªõc: {domestic_count} tin\nüåç Qu·ªëc t·∫ø: {international_count} tin (auto-extract)\nüìä T·ªïng: {len(all_news)} tin\nüìÖ C·∫≠p nh·∫≠t: {get_current_date_str()}",
            inline=False
        )
        
        for i, news in enumerate(page_news, 1):
            title = news['title'][:50] + "..." if len(news['title']) > 50 else news['title']  # Reduced title length
            embed.add_field(
                name=f"{i}. {title}",
                value=f"üï∞Ô∏è {news['published_str']} ‚Ä¢ üîó [ƒê·ªçc]({news['link']})",
                inline=False
            )
        
        save_user_news_render(ctx.author.id, page_news, f"all_page_{page}")
        
        total_pages = (len(all_news) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"üöÄ Render Optimized ‚Ä¢ Trang {page}/{total_pages} ‚Ä¢ !chitiet [s·ªë]")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"‚ùå L·ªói: {str(e)}")

@bot.command(name='in')
async def get_domestic_news_render(ctx, page=1):
    """üöÄ Render optimized domestic news"""
    try:
        page = max(1, int(page))
        loading_msg = await ctx.send(f"‚è≥ ƒêang t·∫£i tin t·ª©c trong n∆∞·ªõc - Render Optimized...")
        
        news_list = await collect_news_render_optimized(RSS_FEEDS['domestic'], 5)  # Reduced from 8
        await loading_msg.delete()
        
        items_per_page = 10  # Reduced from 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"‚ùå Kh√¥ng c√≥ tin t·ª©c ·ªü trang {page}! T·ªïng c·ªông c√≥ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"üáªüá≥ Tin kinh t·∫ø trong n∆∞·ªõc Render (Trang {page})",
            description=f"üèóÔ∏è Render Free Tier ‚Ä¢ T·ª´ {len(RSS_FEEDS['domestic'])} ngu·ªìn ‚Ä¢ Memory Optimized",
            color=0xff0000
        )
        
        embed.add_field(
            name="üìä Th√¥ng tin Render",
            value=f"üì∞ T·ªïng tin: {len(news_list)} tin\nüéØ Lƒ©nh v·ª±c: Kinh t·∫ø, CK, BƒêS\nüìÖ C·∫≠p nh·∫≠t: {get_current_date_str()}",
            inline=False
        )
        
        for i, news in enumerate(page_news, 1):
            title = news['title'][:50] + "..." if len(news['title']) > 50 else news['title']
            embed.add_field(
                name=f"{i}. {title}",
                value=f"üï∞Ô∏è {news['published_str']} ‚Ä¢ üîó [ƒê·ªçc]({news['link']})",
                inline=False
            )
        
        save_user_news_render(ctx.author.id, page_news, f"in_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"üöÄ Render Optimized ‚Ä¢ Trang {page}/{total_pages} ‚Ä¢ !chitiet [s·ªë]")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"‚ùå L·ªói: {str(e)}")

@bot.command(name='out')
async def get_international_news_render(ctx, page=1):
    """üöÄ Render optimized international news with auto-translate"""
    try:
        page = max(1, int(page))
        loading_msg = await ctx.send(f"‚è≥ ƒêang t·∫£i tin t·ª©c qu·ªëc t·∫ø - Render Optimized v·ªõi auto-translate...")
        
        news_list = await collect_news_render_optimized(RSS_FEEDS['international'], 4)  # Reduced from 6
        await loading_msg.delete()
        
        items_per_page = 10  # Reduced from 12
        start_index = (page - 1) * items_per_page
        end_index = start_index + items_per_page
        page_news = news_list[start_index:end_index]
        
        if not page_news:
            total_pages = (len(news_list) + items_per_page - 1) // items_per_page
            await ctx.send(f"‚ùå Kh√¥ng c√≥ tin t·ª©c ·ªü trang {page}! T·ªïng c·ªông c√≥ {total_pages} trang.")
            return
        
        embed = discord.Embed(
            title=f"üåç Tin kinh t·∫ø qu·ªëc t·∫ø Render (Trang {page})",
            description=f"üèóÔ∏è Render Free Tier ‚Ä¢ {len(RSS_FEEDS['international'])} ngu·ªìn ‚Ä¢ Auto-translate + Extract",
            color=0x0066ff
        )
        
        embed.add_field(
            name="üìä Th√¥ng tin Render",
            value=f"üì∞ T·ªïng tin: {len(news_list)} tin\nüåê Auto-extract: Bloomberg, Reuters\nüîÑ Auto-translate: Ti·∫øng Anh ‚Üí Ti·∫øng Vi·ªát\nüìÖ C·∫≠p nh·∫≠t: {get_current_date_str()}",
            inline=False
        )
        
        for i, news in enumerate(page_news, 1):
            title = news['title'][:50] + "..." if len(news['title']) > 50 else news['title']
            embed.add_field(
                name=f"{i}. üåê {title}",
                value=f"üï∞Ô∏è {news['published_str']} ‚Ä¢ üîó [ƒê·ªçc]({news['link']})",
                inline=False
            )
        
        save_user_news_render(ctx.author.id, page_news, f"out_page_{page}")
        
        total_pages = (len(news_list) + items_per_page - 1) // items_per_page
        embed.set_footer(text=f"üöÄ Render Optimized ‚Ä¢ Trang {page}/{total_pages} ‚Ä¢ !chitiet [s·ªë] (auto-extract)")
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"‚ùå L·ªói: {str(e)}")

# üöÄ RENDER OPTIMIZED ARTICLE DETAILS
@bot.command(name='chitiet')
async def get_news_detail_render(ctx, news_number: int):
    """üöÄ Render optimized article details with content extraction + auto-translate"""
    try:
        user_id = ctx.author.id
        
        if user_id not in user_news_cache:
            await ctx.send("‚ùå B·∫°n ch∆∞a xem tin t·ª©c! D√πng `!all`, `!in`, ho·∫∑c `!out` tr∆∞·ªõc.")
            return
        
        user_data = user_news_cache[user_id]
        news_list = user_data['news']
        
        if news_number < 1 or news_number > len(news_list):
            await ctx.send(f"‚ùå S·ªë kh√¥ng h·ª£p l·ªá! Ch·ªçn t·ª´ 1 ƒë·∫øn {len(news_list)}")
            return
        
        news = news_list[news_number - 1]
        
        loading_msg = await ctx.send(f"üöÄ ƒêang tr√≠ch xu·∫•t v·ªõi Render optimized system...")
        
        # Render optimized content extraction
        full_content = await fetch_content_render_optimized(news['link'])
        
        # Render optimized auto-translate
        source_name = extract_source_name(news['link'])
        translated_content, is_translated = await detect_and_translate_content_render(full_content, source_name)
        
        await loading_msg.delete()
        
        embed = discord.Embed(
            title="üìñ Chi ti·∫øt b√†i vi·∫øt - Render Optimized",
            color=0x9932cc
        )
        
        # Render extraction info
        extraction_methods = []
        if TRAFILATURA_AVAILABLE:
            extraction_methods.append("üöÄ Trafilatura")
        if NEWSPAPER_AVAILABLE:
            extraction_methods.append("üì∞ Newspaper3k")
        extraction_methods.append("üîÑ Legacy")
        
        extraction_info = " ‚Üí ".join(extraction_methods)
        
        # Translation indicator
        title_suffix = " üåê (ƒê√£ d·ªãch)" if is_translated else ""
        embed.add_field(name=f"üì∞ Ti√™u ƒë·ªÅ{title_suffix}", value=news['title'], inline=False)
        embed.add_field(name="üï∞Ô∏è Th·ªùi gian", value=f"{news['published_str']} ({get_current_date_str()})", inline=True)
        
        source_display = source_name
        if is_translated:
            source_display += " üåê"
        embed.add_field(name="üì∞ Ngu·ªìn", value=source_display, inline=True)
        embed.add_field(name="üöÄ Render Extract", value=extraction_info, inline=True)
        
        # Content with memory optimization
        content_title = "üìÑ N·ªôi dung chi ti·∫øt üåê (Render auto-translate)" if is_translated else "üìÑ N·ªôi dung chi ti·∫øt (Render extract)"
        
        if len(translated_content) > 800:  # Reduced from 1000 for Render
            embed.add_field(
                name=f"{content_title} (Ph·∫ßn 1)",
                value=translated_content[:800] + "...",
                inline=False
            )
            
            await ctx.send(embed=embed)
            
            # Render optimized second embed
            embed2 = discord.Embed(
                title=f"üìñ Chi ti·∫øt b√†i vi·∫øt (ti·∫øp theo){'üåê' if is_translated else ''} - Render",
                color=0x9932cc
            )
            
            embed2.add_field(
                name=f"{content_title} (Ph·∫ßn 2)",
                value=translated_content[800:1400],  # Reduced continuation
                inline=False
            )
            
            if is_translated:
                embed2.add_field(
                    name="üîÑ Render Auto-Translate",
                    value="üìù N·ªôi dung ti·∫øng Anh ƒë√£ ƒë∆∞·ª£c d·ªãch t·ª± ƒë·ªông\nüèóÔ∏è Render Free Tier optimized",
                    inline=False
                )
            
            embed2.add_field(
                name="üîó ƒê·ªçc b√†i vi·∫øt ƒë·∫ßy ƒë·ªß",
                value=f"[Nh·∫•n ƒë·ªÉ ƒë·ªçc to√†n b·ªô b√†i vi·∫øt{'g·ªëc' if is_translated else ''}]({news['link']})",
                inline=False
            )
            
            embed2.set_footer(text=f"üöÄ Render Optimized ‚Ä¢ Content extraction ‚Ä¢ {get_current_datetime_str()}")
            
            await ctx.send(embed=embed2)
            return
        else:
            embed.add_field(
                name=content_title,
                value=translated_content,
                inline=False
            )
        
        if is_translated:
            embed.add_field(
                name="üîÑ Render Auto-Translate",
                value="üìù Advanced detection + translation\nüèóÔ∏è Render Free Tier optimized",
                inline=False
            )
        
        embed.add_field(
            name="üîó ƒê·ªçc b√†i vi·∫øt ƒë·∫ßy ƒë·ªß",
            value=f"[Nh·∫•n ƒë·ªÉ ƒë·ªçc to√†n b·ªô b√†i vi·∫øt{'g·ªëc' if is_translated else ''}]({news['link']})",
            inline=False
        )
        
        embed.set_footer(text=f"üöÄ Render Optimized ‚Ä¢ Tin s·ªë {news_number} ‚Ä¢ !hoi [question]")
        
        await ctx.send(embed=embed)
        
    except ValueError:
        await ctx.send("‚ùå Vui l√≤ng nh·∫≠p s·ªë! V√≠ d·ª•: `!chitiet 5`")
    except Exception as e:
        await ctx.send(f"‚ùå L·ªói: {str(e)}")

@bot.command(name='cuthe')
async def get_news_detail_alias_render(ctx, news_number: int):
    """üöÄ Alias cho l·ªánh !chitiet Render optimized"""
    await get_news_detail_render(ctx, news_number)

@bot.command(name='menu')
async def help_command_render(ctx):
    """üöÄ Render optimized menu guide"""
    current_datetime_str = get_current_datetime_str()
    
    embed = discord.Embed(
        title="üöÄ Multi-AI Discord News Bot - Render Optimized Edition",
        description=f"Bot tin t·ª©c v·ªõi Multi-AI + Render Free Tier - {current_datetime_str}",
        color=0xff9900
    )
    
    ai_count = len(debate_engine.available_engines)
    if ai_count >= 1:
        ai_status = f"üöÄ **{ai_count} FREE AI Engines (Render Optimized)**\n"
        for ai_provider in debate_engine.available_engines:
            ai_info = debate_engine.ai_engines[ai_provider]
            ai_status += f"{ai_info['emoji']} **{ai_info['name']}** - {ai_info['strength']} ({ai_info['free_limit']}) ‚úÖ\n"
    else:
        ai_status = "‚ö†Ô∏è C·∫ßn √≠t nh·∫•t 1 AI engine ƒë·ªÉ ho·∫°t ƒë·ªông"
    
    embed.add_field(name="üöÄ Render Multi-AI Status", value=ai_status, inline=False)
    
    embed.add_field(
        name="ü•ä Multi-AI Commands (Render Optimized)",
        value=f"**!hoi [c√¢u h·ªèi]** - AI v·ªõi d·ªØ li·ªáu th·ªùi gian th·ª±c {get_current_date_str()}\n*VD: !hoi gi√° v√†ng h√¥m nay*\n*VD: !hoi ch·ª©ng kho√°n*",
        inline=False
    )
    
    embed.add_field(
        name="üì∞ News Commands (Render Optimized)",
        value="**!all [trang]** - Tin t·ªïng h·ª£p (10 tin/trang)\n**!in [trang]** - Tin trong n∆∞·ªõc\n**!out [trang]** - Tin qu·ªëc t·∫ø (auto-translate)\n**!chitiet [s·ªë]** - Chi ti·∫øt (üöÄ Trafilatura + auto-translate)",
        inline=False
    )
    
    embed.add_field(
        name="üöÄ Render Features",
        value=f"‚úÖ **Memory Optimized**: 512MB RAM efficient\n‚úÖ **Content Extraction**: Trafilatura + Newspaper3k\n‚úÖ **Auto-translate**: Advanced detection\n‚úÖ **FREE Only**: $0/month\n‚úÖ **Fast Response**: T·ªëi ∆∞u t·ªëc ƒë·ªô Render\n‚úÖ **Auto-cleanup**: Memory management",
        inline=False
    )
    
    embed.add_field(
        name="üéØ V√≠ d·ª• s·ª≠ d·ª•ng Render",
        value=f"**!hoi gi√° v√†ng** - AI t√¨m gi√° v√†ng {get_current_date_str()}\n**!hoi t·ª∑ gi√° usd** - AI t√¨m t·ª∑ gi√° hi·ªán t·∫°i\n**!hoi vn-index** - AI t√¨m ch·ªâ s·ªë ch·ª©ng kho√°n\n**!all** - Xem tin t·ª©c t·ªïng h·ª£p\n**!chitiet 1** - Xem chi ti·∫øt tin s·ªë 1",
        inline=False
    )
    
    # Render status
    search_status = "‚úÖ Render optimized search"
    if GOOGLE_API_KEY and GOOGLE_CSE_ID:
        search_status += " + Google API"
    
    embed.add_field(name="üîç Search (Render)", value=search_status, inline=True)
    embed.add_field(name=f"üèóÔ∏è Render Free Tier", value=f"üöÄ **{ai_count} FREE AI Engines**\n‚ö° **Memory Optimized**\nüß† **Smart Caching**\nüåê **Auto-translate**\nüí∞ **$0/month**", inline=True)
    
    embed.set_footer(text=f"üöÄ Render Optimized Multi-AI ‚Ä¢ {current_datetime_str} ‚Ä¢ !hoi [question]")
    await ctx.send(embed=embed)

# Render optimized cleanup function
async def cleanup_render():
    """Memory-optimized cleanup for Render Free Tier"""
    if debate_engine:
        await debate_engine.close_session()
    
    # Clear user cache periodically for memory efficiency
    global user_news_cache
    if len(user_news_cache) > MAX_CACHE_ENTRIES:
        user_news_cache.clear()
        print("üßπ Render memory cleanup completed")

# Main execution optimized for Render Free Tier
if __name__ == "__main__":
    try:
        keep_alive()
        print("üöÄ Starting Multi-AI Discord News Bot - Render Optimized Edition...")
        print("üèóÔ∏è Render Free Tier Edition - Memory Optimized (512MB RAM)")
        
        ai_count = len(debate_engine.available_engines)
        print(f"ü§ñ Render Multi-AI System: {ai_count} FREE engines initialized")
        
        current_datetime_str = get_current_datetime_str()
        print(f"üîß Current Vietnam time: {current_datetime_str}")
        
        if ai_count >= 1:
            ai_names = [debate_engine.ai_engines[ai]['name'] for ai in debate_engine.available_engines]
            print(f"ü•ä Render debate ready with: {', '.join(ai_names)}")
            print("üí∞ Cost: $0/month (FREE AI tiers only)")
            print("üöÄ Features: News + Content extraction + Auto-translate + Multi-AI")
        else:
            print("‚ö†Ô∏è Warning: Need at least 1 FREE AI engine")
        
        # Render search status
        if GOOGLE_API_KEY and GOOGLE_CSE_ID:
            print("üîç Google Search API: Available with Render optimization")
        else:
            print("üîß Google Search API: Using Render optimized fallback")
        
        # Wikipedia knowledge base status
        if WIKIPEDIA_AVAILABLE:
            print("üìö Wikipedia Knowledge Base: Available (using spare 112MB)")
        else:
            print("‚ö†Ô∏è Wikipedia Knowledge Base: Not available")
        
        total_sources = len(RSS_FEEDS['domestic']) + len(RSS_FEEDS['international'])
        print(f"üìä {total_sources} RSS sources loaded with Render optimization")
        
        # Display Render content extraction capabilities
        print("\nüöÄ RENDER OPTIMIZED CONTENT EXTRACTION:")
        extraction_tiers = []
        if TRAFILATURA_AVAILABLE:
            extraction_tiers.append("Tier 1: Trafilatura (Memory optimized)")
        else:
            print("‚ùå Trafilatura: Not available")
        
        if NEWSPAPER_AVAILABLE:
            extraction_tiers.append("Tier 2: Newspaper3k (Fallback)")
        else:
            print("‚ùå Newspaper3k: Not available")
        
        extraction_tiers.append("Tier 3: Legacy (Always works)")
        
        for tier in extraction_tiers:
            print(f"‚úÖ {tier}")
        
        # Render Free Tier optimization info
        print("\nüèóÔ∏è RENDER FREE TIER OPTIMIZATION:")
        print("‚úÖ Memory usage: ~300-400MB (512MB limit)")
        print("‚úÖ Reduced cache size and timeouts")
        print("‚úÖ Memory cleanup and auto-GC")
        print("‚úÖ Efficient content extraction")
        print("‚úÖ Optimized AI API calls")
        print("‚úÖ Compact RSS parsing")
        
        print("\n‚úÖ Multi-AI Discord News Bot - Render Optimized + Wikipedia ready!")
        print(f"üí° Use !hoi [question] to get AI answers with REAL {get_current_date_str()} data + Wikipedia knowledge")
        print("üí° Use !all, !in, !out for news, !chitiet [number] for details with content extraction")
        print(f"üí° Date and time automatically update: {current_datetime_str}")
        print("üí° Content extraction: Trafilatura ‚Üí Newspaper3k ‚Üí Legacy (memory optimized)")
        print("üí° Knowledge base: Wikipedia (VN + EN) integrated with AI responses")
        print("üí° FREE AI APIs working correctly with rate limiting")
        print("üí° Render Free Tier optimized for maximum performance at $0/month")
        
        # Final startup message
        print("\n" + "="*70)
        print("üöÄ MULTI-AI DISCORD NEWS BOT - RENDER + WIKIPEDIA EDITION")
        print("üí∞ COST: $0/month (100% FREE AI tiers)")
        print("üèóÔ∏è PLATFORM: Render Free Tier (400-450MB RAM used)")
        print("ü§ñ AI ENGINES: Gemini (15 req/min) + Groq (30 req/min)")
        print("üìö KNOWLEDGE: Wikipedia (VN + EN) integration")
        print("üöÄ FEATURES: News + Extract + Translate + Multi-AI + Wikipedia")
        print("üéØ USAGE: !menu for complete guide")
        print("="*70)
        
        bot.run(TOKEN)
        
    except discord.LoginFailure:
        print("‚ùå Discord login error!")
        print("üîß Token may be invalid or reset")
        print("üîß Check DISCORD_TOKEN in Environment Variables")
        
    except Exception as e:
        print(f"‚ùå Bot startup error: {e}")
        print("üîß Check internet connection and Environment Variables")
        
    finally:
        try:
            asyncio.run(cleanup_render())
        except:
            pass
